export default [
  {
    "content": "Imagine this: You're tracking down an issue in your logs. The traditional approach feels like following a recipe - select the request status, choose the method, navigate to the date-time picker, set it to two hours ago, and keep adding more criteria. Click after click, filter after filter.\n\nNow imagine simply typing: \"I need requests with GET methods, success status that happened 2 hours ago.\" That's it. No more menu diving, no more juggling multiple filters - just tell the system what you want, like you're asking a colleague.\n\n## Implementation Journey\n\nWhen this feature was first discussed, we thought implementation would be challenging. However, if you're already using `zod`, it's surprisingly straightforward. OpenAI provides a `zodResponseFormat` helper to generate structured outputs, making the integration super easy.\n\n### Query Parameter Structure\n\nAt the heart of our implementation is a query parameter design that bridges natural language and code. We used a syntax that's both powerful and intuitive:\n\n```bash\noperator:value,operator:value (e.g., \"is:200,is:404\")\n\nExample -> status=is:200,is:400\n           path=startsWith:foo,endsWith:bar\n```\n\nThis pattern allows for incredible flexibility - you can chain multiple conditions while maintaining readability. To handle these parameters in our Unkey dashboard, we implemented a custom parser for [nuqs](\"https://nuqs.47ng.com/\"):\n\n```typescript\nexport const parseAsFilterValueArray: Parser<FilterUrlValue[]> = {\n  parse: (str: string | null) => {\n    if (!str) {\n      return [];\n    }\n    try {\n      // Format: operator:value,operator:value (e.g., \"is:200,is:404\")\n      return str.split(\",\").map((item) => {\n        const [operator, val] = item.split(/:(.+)/);\n        if (![\"is\", \"contains\", \"startsWith\", \"endsWith\"].includes(operator)) {\n          throw new Error(\"Invalid operator\");\n        }\n        return {\n          operator: operator as FilterOperator,\n          value: val,\n        };\n      });\n    } catch {\n      return [];\n    }\n  },\n  // In our app we pass a valid type but for brevity it's omitted\n  serialize: (value: any[]) => {\n    if (!value?.length) {\n      return \"\";\n    }\n    return value.map((v) => `${v.operator}:${v.value}`).join(\",\");\n  },\n};\n\nexport const queryParamsPayload = {\n  requestId: parseAsFilterValueArray,\n  host: parseAsFilterValueArray,\n  methods: parseAsFilterValueArray,\n  paths: parseAsFilterValueArray,\n  status: parseAsFilterValueArray,\n  startTime: parseAsInteger,\n  endTime: parseAsInteger,\n  since: parseAsRelativeTime,\n} as const;\n```\n\nOur parser handles edge cases gracefully - from null inputs to invalid operators - while maintaining a clean, predictable output format. The type-safe payload configuration ensures consistency across different parameter types.\n\n### Defining the Schema\n\nWith our parameter structure in place, we needed a way to ensure the AI's responses would map perfectly to our system. Enter Zod - our schema validation powerhouse:\n\n```typescript\nexport const filterOutputSchema = z.object({\n  filters: z.array(\n    z.object({\n      field: z.enum([\n        \"host\",\n        \"requestId\",\n        \"methods\",\n        \"paths\",\n        \"status\",\n        \"startTime\",\n        \"endTime\",\n        \"since\",\n      ]),\n      filters: z.array(\n        z.object({\n          operator: z.enum([\"is\", \"contains\", \"startsWith\", \"endsWith\"]),\n          value: z.union([z.string(), z.number()]),\n        })\n      ),\n    })\n  ),\n});\n```\n\nThis schema acts as a contract between natural language and our application's expectations. It ensures that every AI response will be structured in a way our system can understand and process. The nested array structure allows for complex queries while maintaining strict type safety.\n\n## System Prompt and OpenAI Integration\n\nThe magic happens in how we instruct the AI. Our system prompt is carefully crafted to ensure consistent, reliable outputs:\n\n```ts\nYou are an expert at converting natural language queries into filters. For queries with multiple conditions, output all relevant filters. We will process them in sequence to build the complete filter. For status codes, always return one for each variant like 200,400 or 500 instead of 200,201, etc... - the application will handle status code grouping internally. Always use this ${usersReferenceMS} timestamp when dealing with time related queries.\n\nQuery: \"path should start with /api/oz and method should be POST\"\nResult: [\n  {\n    \"field\": \"paths\",\n    \"filters\": [\n      {\n        \"operator\": \"startsWith\",\n        \"value\": \"/api/oz\"\n      }\n    ]\n  },\n  {\n    \"field\": \"methods\",\n    \"filters\": [\n      {\n        \"operator\": \"is\",\n        \"value\": \"POST\"\n      }\n    ]\n  }\n]\n```\n\n> In our prompt there are lots of examples for each search variation, but in here it's omitted for brevity. For the best result make sure your prompt is as detailed as possible.\n\n### OpenAI Configuration\n\nTuning the AI's behavior is crucial for reliable results. Here's our optimized configuration:\n\n```typescript\nconst completion = await openai.beta.chat.completions.parse({\n  model: \"gpt-4o-mini\",\n  temperature: 0.2, // Lower temperature for more deterministic outputs\n  top_p: 0.1, // Focus on highest probability tokens\n  frequency_penalty: 0.5, // Maintain natural language variety\n  presence_penalty: 0.5, // Encourage diverse responses\n  n: 1, // Single, confident response\n  messages: [\n    {\n      role: \"system\",\n      content: systemPrompt,\n    },\n    {\n      role: \"user\",\n      content: userQuery,\n    },\n  ],\n  response_format: zodResponseFormat(filterOutputSchema, \"searchQuery\"),\n});\n```\n\nThe low `temperature` and `top_p` values ensure predictable outputs, while the penalty parameters help maintain natural-sounding responses.\n\n## Process Flow\n\nHere's how the entire process works:\n\n```bash\nUser\n  |\n  | \"Show me failed requests from last hour\"\n  v\nFrontend\n  |\n  | {query: \"show me failed requests from last hour\"}\n  v\ntRPC Route\n  |\n  | {model, messages with system prompt, schema}\n  v\nOpenAI\n  |\n  | {structured JSON matching our schema}\n  v\ntRPC Route\n  |\n  | status=is:400,since:1h\n  v\nFrontend\n  |\n  | /logs?status=is:400&since=is:1h\n  v\nURL\n  |\n  | trigger fetch with new params\n  v\nLogs tRPC Query\n  |\n  | return filtered logs\n  v\nFrontend\n  |\n  | display filtered results\n  v\nUser\n```\n\n## Important Considerations\n\nBefore implementing this feature in your own application, here are some crucial factors to consider:\n\n- Integrating LLMs into your application requires robust error handling. The OpenAI API might experience downtime or rate limiting, so implement fallback mechanisms or meaningful error message to show to user.\n- Each query consumes OpenAI API tokens - More AI search burns more money\n- Implement rate limiting - Without ratelimit users can abuse your AI-powered search\n\n## Conclusion\n\nWhile traditional filter-based UIs work well, the ability to express search criteria in plain English makes log exploration more intuitive and efficient.\n\nThe integration with OpenAI's structured output feature and zod makes the implementation surprisingly straightforward. The key to success lies in:\n\n- Crafting a clear system prompt\n- Defining a robust schema for your use case\n- Implementing proper error handling and fallbacks\n\nRemember that while AI-powered features can enhance your application, they should complement rather than completely replace traditional interfaces. This hybrid approach ensures the best experience for all users while maintaining reliability and accessibility.",
    "title": "Building complex UI queries in plain English with AI",
    "description": "Just ask 'Show me logs from yesterday' and AI finds them. No more clicking filters - type what you want, like you're texting a friend. Simple log search that just works.",
    "author": "oz",
    "date": "2025-01-27",
    "tags": [
      "engineering"
    ],
    "image": "/images/blog-images/ai-logs/og-image.png",
    "_meta": {
      "filePath": "ai-search-for-logs.mdx",
      "fileName": "ai-search-for-logs.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "ai-search-for-logs"
    },
    "mdx": "var Component=(()=>{var h=Object.create;var i=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var r in e)i(t,r,{get:e[r],enumerable:!0})},o=(t,e,r,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let a of m(e))!y.call(t,a)&&a!==r&&i(t,a,{get:()=>e[a],enumerable:!(s=d(e,a))||s.enumerable});return t};var b=(t,e,r)=>(r=t!=null?h(g(t)):{},o(e||!t||!t.__esModule?i(r,\"default\",{value:t,enumerable:!0}):r,t)),v=t=>o(i({},\"__esModule\",{value:!0}),t);var u=f((k,l)=>{l.exports=_jsx_runtime});var A={};w(A,{default:()=>p});var n=b(u());function c(t){let e={a:\"a\",blockquote:\"blockquote\",code:\"code\",h2:\"h2\",h3:\"h3\",li:\"li\",p:\"p\",pre:\"pre\",ul:\"ul\",...t.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"Imagine this: You're tracking down an issue in your logs. The traditional approach feels like following a recipe - select the request status, choose the method, navigate to the date-time picker, set it to two hours ago, and keep adding more criteria. Click after click, filter after filter.\"}),`\n`,(0,n.jsx)(e.p,{children:`Now imagine simply typing: \"I need requests with GET methods, success status that happened 2 hours ago.\" That's it. No more menu diving, no more juggling multiple filters - just tell the system what you want, like you're asking a colleague.`}),`\n`,(0,n.jsx)(e.h2,{id:\"implementation-journey\",children:\"Implementation Journey\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"When this feature was first discussed, we thought implementation would be challenging. However, if you're already using \",(0,n.jsx)(e.code,{children:\"zod\"}),\", it's surprisingly straightforward. OpenAI provides a \",(0,n.jsx)(e.code,{children:\"zodResponseFormat\"}),\" helper to generate structured outputs, making the integration super easy.\"]}),`\n`,(0,n.jsx)(e.h3,{id:\"query-parameter-structure\",children:\"Query Parameter Structure\"}),`\n`,(0,n.jsx)(e.p,{children:\"At the heart of our implementation is a query parameter design that bridges natural language and code. We used a syntax that's both powerful and intuitive:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`operator:value,operator:value (e.g., \"is:200,is:404\")\n\nExample -> status=is:200,is:400\n           path=startsWith:foo,endsWith:bar\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"This pattern allows for incredible flexibility - you can chain multiple conditions while maintaining readability. To handle these parameters in our Unkey dashboard, we implemented a custom parser for \",(0,n.jsx)(e.a,{href:\"%22https://nuqs.47ng.com/%22\",children:\"nuqs\"}),\":\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`export const parseAsFilterValueArray: Parser<FilterUrlValue[]> = {\n  parse: (str: string | null) => {\n    if (!str) {\n      return [];\n    }\n    try {\n      // Format: operator:value,operator:value (e.g., \"is:200,is:404\")\n      return str.split(\",\").map((item) => {\n        const [operator, val] = item.split(/:(.+)/);\n        if (![\"is\", \"contains\", \"startsWith\", \"endsWith\"].includes(operator)) {\n          throw new Error(\"Invalid operator\");\n        }\n        return {\n          operator: operator as FilterOperator,\n          value: val,\n        };\n      });\n    } catch {\n      return [];\n    }\n  },\n  // In our app we pass a valid type but for brevity it's omitted\n  serialize: (value: any[]) => {\n    if (!value?.length) {\n      return \"\";\n    }\n    return value.map((v) => \\`\\${v.operator}:\\${v.value}\\`).join(\",\");\n  },\n};\n\nexport const queryParamsPayload = {\n  requestId: parseAsFilterValueArray,\n  host: parseAsFilterValueArray,\n  methods: parseAsFilterValueArray,\n  paths: parseAsFilterValueArray,\n  status: parseAsFilterValueArray,\n  startTime: parseAsInteger,\n  endTime: parseAsInteger,\n  since: parseAsRelativeTime,\n} as const;\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Our parser handles edge cases gracefully - from null inputs to invalid operators - while maintaining a clean, predictable output format. The type-safe payload configuration ensures consistency across different parameter types.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"defining-the-schema\",children:\"Defining the Schema\"}),`\n`,(0,n.jsx)(e.p,{children:\"With our parameter structure in place, we needed a way to ensure the AI's responses would map perfectly to our system. Enter Zod - our schema validation powerhouse:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`export const filterOutputSchema = z.object({\n  filters: z.array(\n    z.object({\n      field: z.enum([\n        \"host\",\n        \"requestId\",\n        \"methods\",\n        \"paths\",\n        \"status\",\n        \"startTime\",\n        \"endTime\",\n        \"since\",\n      ]),\n      filters: z.array(\n        z.object({\n          operator: z.enum([\"is\", \"contains\", \"startsWith\", \"endsWith\"]),\n          value: z.union([z.string(), z.number()]),\n        })\n      ),\n    })\n  ),\n});\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"This schema acts as a contract between natural language and our application's expectations. It ensures that every AI response will be structured in a way our system can understand and process. The nested array structure allows for complex queries while maintaining strict type safety.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"system-prompt-and-openai-integration\",children:\"System Prompt and OpenAI Integration\"}),`\n`,(0,n.jsx)(e.p,{children:\"The magic happens in how we instruct the AI. Our system prompt is carefully crafted to ensure consistent, reliable outputs:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-ts\",children:`You are an expert at converting natural language queries into filters. For queries with multiple conditions, output all relevant filters. We will process them in sequence to build the complete filter. For status codes, always return one for each variant like 200,400 or 500 instead of 200,201, etc... - the application will handle status code grouping internally. Always use this \\${usersReferenceMS} timestamp when dealing with time related queries.\n\nQuery: \"path should start with /api/oz and method should be POST\"\nResult: [\n  {\n    \"field\": \"paths\",\n    \"filters\": [\n      {\n        \"operator\": \"startsWith\",\n        \"value\": \"/api/oz\"\n      }\n    ]\n  },\n  {\n    \"field\": \"methods\",\n    \"filters\": [\n      {\n        \"operator\": \"is\",\n        \"value\": \"POST\"\n      }\n    ]\n  }\n]\n`})}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsx)(e.p,{children:\"In our prompt there are lots of examples for each search variation, but in here it's omitted for brevity. For the best result make sure your prompt is as detailed as possible.\"}),`\n`]}),`\n`,(0,n.jsx)(e.h3,{id:\"openai-configuration\",children:\"OpenAI Configuration\"}),`\n`,(0,n.jsx)(e.p,{children:\"Tuning the AI's behavior is crucial for reliable results. Here's our optimized configuration:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const completion = await openai.beta.chat.completions.parse({\n  model: \"gpt-4o-mini\",\n  temperature: 0.2, // Lower temperature for more deterministic outputs\n  top_p: 0.1, // Focus on highest probability tokens\n  frequency_penalty: 0.5, // Maintain natural language variety\n  presence_penalty: 0.5, // Encourage diverse responses\n  n: 1, // Single, confident response\n  messages: [\n    {\n      role: \"system\",\n      content: systemPrompt,\n    },\n    {\n      role: \"user\",\n      content: userQuery,\n    },\n  ],\n  response_format: zodResponseFormat(filterOutputSchema, \"searchQuery\"),\n});\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"The low \",(0,n.jsx)(e.code,{children:\"temperature\"}),\" and \",(0,n.jsx)(e.code,{children:\"top_p\"}),\" values ensure predictable outputs, while the penalty parameters help maintain natural-sounding responses.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"process-flow\",children:\"Process Flow\"}),`\n`,(0,n.jsx)(e.p,{children:\"Here's how the entire process works:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`User\n  |\n  | \"Show me failed requests from last hour\"\n  v\nFrontend\n  |\n  | {query: \"show me failed requests from last hour\"}\n  v\ntRPC Route\n  |\n  | {model, messages with system prompt, schema}\n  v\nOpenAI\n  |\n  | {structured JSON matching our schema}\n  v\ntRPC Route\n  |\n  | status=is:400,since:1h\n  v\nFrontend\n  |\n  | /logs?status=is:400&since=is:1h\n  v\nURL\n  |\n  | trigger fetch with new params\n  v\nLogs tRPC Query\n  |\n  | return filtered logs\n  v\nFrontend\n  |\n  | display filtered results\n  v\nUser\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"important-considerations\",children:\"Important Considerations\"}),`\n`,(0,n.jsx)(e.p,{children:\"Before implementing this feature in your own application, here are some crucial factors to consider:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Integrating LLMs into your application requires robust error handling. The OpenAI API might experience downtime or rate limiting, so implement fallback mechanisms or meaningful error message to show to user.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Each query consumes OpenAI API tokens - More AI search burns more money\"}),`\n`,(0,n.jsx)(e.li,{children:\"Implement rate limiting - Without ratelimit users can abuse your AI-powered search\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsx)(e.p,{children:\"While traditional filter-based UIs work well, the ability to express search criteria in plain English makes log exploration more intuitive and efficient.\"}),`\n`,(0,n.jsx)(e.p,{children:\"The integration with OpenAI's structured output feature and zod makes the implementation surprisingly straightforward. The key to success lies in:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Crafting a clear system prompt\"}),`\n`,(0,n.jsx)(e.li,{children:\"Defining a robust schema for your use case\"}),`\n`,(0,n.jsx)(e.li,{children:\"Implementing proper error handling and fallbacks\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Remember that while AI-powered features can enhance your application, they should complement rather than completely replace traditional interfaces. This hybrid approach ensures the best experience for all users while maintaining reliability and accessibility.\"})]})}function p(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(c,{...t})}):c(t)}return v(A);})();\n;return Component;",
    "slug": "ai-search-for-logs",
    "url": "/blog/ai-search-for-logs",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Implementation Journey",
        "slug": "implementation-journey"
      },
      {
        "level": 3,
        "text": "Query Parameter Structure",
        "slug": "query-parameter-structure"
      },
      {
        "level": 3,
        "text": "Defining the Schema",
        "slug": "defining-the-schema"
      },
      {
        "level": 2,
        "text": "System Prompt and OpenAI Integration",
        "slug": "system-prompt-and-openai-integration"
      },
      {
        "level": 3,
        "text": "OpenAI Configuration",
        "slug": "openai-configuration"
      },
      {
        "level": 2,
        "text": "Process Flow",
        "slug": "process-flow"
      },
      {
        "level": 2,
        "text": "Important Considerations",
        "slug": "important-considerations"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "We are excited to introduce our latest library, `@unkey/cache`, designed to make caching in serverless applications easy and enjoyable.\n\n## The challenges of caching in Cloudflare Workers\n\nOur journey with caching on Cloudflare Workers highlighted several challenges. The most significant issue was the lack of persistent memory, which meant that each request could start with a cold cache. Additionally, Cloudflare KV, while nice to use, proved to be too slow for our needs: The p99 was 560ms ([source](https://upstash.com/blog/edgecaching-benchmark)).\n\nTo mitigate these issues, we implemented a tiered caching strategy. By utilizing an in-memory store as the first tier and Cloudflare's CDN cache as the fallback, we achieved the best of both worlds, latency and decent hit rate.\n\n<Image src=\"/images/blog-images/announcing-unkey-cache-package/cache-hits.png\" alt=\"Cache hit ratio\" width=\"1920\" height=\"1080\"/>\nThe ~27% memory hit rate might not be the most impressive, but it's free and does not add any latency. Unfortunately there's little we can do to increase it, as Cloudflare may evict a worker instance at any moment. However as traffic grows, the hit rate will increase too.\n\nIf a memory cache miss occurs, the Cloudflare cache will be checked, which adds some latency but is still faster than any other alternative we found.\n<Image src=\"/images/blog-images/announcing-unkey-cache-package/cache-latency.png\" alt=\"Cache latency\" width=\"1920\" height=\"1080\"/>\n\nThis performed well, but the developer experience left something to be desired.\n\n## The problem with existing solutions\n\nCaching is a common requirement in many applications, but traditional approaches often fall short. Here's a typical example of what developers have to deal with:\n\n```typescript\nconst cache = new Some3rdPartyCache(...)\n\ntype User = { email: string };\n\nlet user = await cache.get(\"chronark\") as User | undefined | null;\nif (!user) {\n  user = await db.query.users.findFirst({\n    where: (table, { eq }) => eq(table.id, \"chronark\"),\n  });\n  await cache.set(\"chronark\", user, Date.now() + 60_000)\n}\n\n// use user\n```\n\n`@unkey/cache` abstracts all the boilerplate away and gives you a clean API that is fully type-safe:\n\n```typescript\nconst user = await cache.user.swr(\"chronark\", async (id) => {\n  return await db.query.users.findFirst({\n    where: (table, { eq }) => eq(table.id, id),\n  });\n});\n```\n\n## Key features\n\nThe \"u\" in \"unkey\" stands for \"batteries included\"! _(English may not be my first language)_\n\n- **E2E Typesafe**: Fully type-safe, clean and intuitive API with intellisense autocomplete.\n- **Tiered Cache**: Chain multiple caches together for fast and reliable caching.\n- **Stale-While-Revalidate**: Most 3rd party caches support setting a time-to-live, but you needed to handle SWR yourself, until now. Just configure `fresh` and `stale` times and let the cache handle the rest.\n- **Metrics Collection**: Middleware for gathering metrics to monitor and debug your cache usage.\n- **Encryption**: Middleware for automatic encryption of cache values, protecting your data at rest.\n- **Composable Design**: Mix and match [primitives](https://www.unkey.com/docs/libraries/ts/cache/overview#primitives) to build exactly what you need.\n\n\n## Getting Started\n\nInstall `@unkey/cache`:\n\n```bash\nnpm install @unkey/cache\n```\n\n\n### Basic cache\n\n\n```typescript\nimport { createCache, DefaultStatefulContext, Namespace } from \"@unkey/cache\";\nimport { MemoryStore } from \"@unkey/cache/stores\";\n\n/**\n * Let's say we have two types, `User` and `Project`:\n */\ntype User = { id: string; email: string };\ntype Project = { name: string; description: string };\n\n/**\n * Next we'll be creating a store. A store is really just a small abstraction\n * over a key-value database.\n */\nconst memory = new MemoryStore({ persistentMap: new Map() });\n\n/**\n * We'll create a cache instance with our two types, `User` and `Project`, and\n * configure the cache to use the memory store. We'll also set the `fresh` and\n * `stale` times for each type.\n * The `ctx` object is provided in the request handler and allows us to do some\n * background work without blocking the request.\n */\nconst cache = createCache({\n    user: new Namespace<User>(ctx, {\n      stores: [memory],\n      fresh: 60_000,\n      stale: 300_000,\n    }),\n    project: new Namespace<Project>(ctx, {\n      stores: [memory],\n      fresh: 300_000,\n      stale: 900_000,\n    })\n});\n\n/**\n * That's it! Now we can use the cache like this:\n */\nawait cache.user.set(\"userId\", { id: \"userId\", email: \"user@email.com\" });\nconst user = await cache.user.get(\"userId\");\nconsole.log(user);\n\n\n/**\n * To make full use of the SWR capabilities, we can use the `swr` method, which\n * will automatically handle the cache misses and cache updates for us.\n * This will check all stores for the value, and if it's not found, it will\n * call the provided function to get the value and cache it automatically.\n */\nconst user = await cache.user.swr(\"userId\", async () => {\n  return await database.get(...)\n});\n```\n\n\n### Tiered caching\n\nTiered caching is a powerful feature that allows you to chain multiple caches together. This is useful when you want to use a fast, in-memory cache as the first tier and a slower, more persistent cache as the second tier.\n\n```typescript\nimport { createCache, DefaultStatefulContext, Namespace } from \"@unkey/cache\";\nimport { CloudflareStore, MemoryStore } from \"@unkey/cache/stores\";\n\ntype User = { id: string; email: string };\n\nconst memory = new MemoryStore({ persistentMap: new Map() });\nconst cloudflare = new CloudflareStore({\n  domain: \"cache.unkey.dev\",\n  zoneId: process.env.CLOUDFLARE_ZONE_ID!,\n  cloudflareApiKey: process.env.CLOUDFLARE_API_KEY!,\n});\n\nconst cache = createCache({\n  user: new Namespace<User>(ctx, {\n    // memory is checked first, then cloudflare if memory misses\n    stores: [memory, cloudflare],\n    fresh: 60_000,\n    stale: 300_000,\n  })\n});\n\nawait cache.user.set(\"userId\", { id: \"userId\", email: \"user@email.com\" });\nconst user = await cache.user.get(\"userId\");\nconsole.log(user);\n```\n\n### Middleware\n\nThere are two middlewares available out of the box:\n- **Metrics**: Collects and forwards metrics on cache hits, misses, latency and evictions.\n\n  `import { withMetrics } from \"@unkey/cache/middleware\";`\n- **Encryption**: Automatically encrypts and decrypts cache values.\n\n  `import { withEncryption } from \"@unkey/cache/middleware\";`\n\nPlease refer to the [documentation](https://www.unkey.com/docs/libraries/ts/cache/overview#middlewares) for more information on how to use middlewares.\n\n\n## Conclusion\n\nAt launch we ship with a memory store and a Cloudflare store, but everything is built to be [easily extensible](https://www.unkey.com/docs/libraries/ts/cache/interface/store). We can add more stores and middlewares as needed, let us know what you'd want to see!\nWhether you're dealing with the limitations of serverless functions or simply need a nice caching abstraction, `@unkey/cache` has you covered.\n\nAs usual, everything is open source, check out our [GitHub repository](https://github.com/unkeyed/unkey/tree/main/packages/cache) and our [documentation](https://www.unkey.com/docs/libraries/ts/cache/overview) for more information. We can't wait to see what you build with it!",
    "title": "npm i @unkey/cache",
    "description": "Batteries-included cache SDK for serverless applications.",
    "author": "andreas",
    "date": "2024-06-25",
    "tags": [
      "launchweek",
      "marketing"
    ],
    "image": "/images/blog-images/covers/launchweek-cache.png",
    "_meta": {
      "filePath": "announcing-unkey-cache-package.mdx",
      "fileName": "announcing-unkey-cache-package.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "announcing-unkey-cache-package"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var i=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,w=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),g=(t,e)=>{for(var a in e)i(t,a,{get:e[a],enumerable:!0})},s=(t,e,a,c)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of p(e))!w.call(t,r)&&r!==a&&i(t,r,{get:()=>e[r],enumerable:!(c=m(e,r))||c.enumerable});return t};var b=(t,e,a)=>(a=t!=null?u(y(t)):{},s(e||!t||!t.__esModule?i(a,\"default\",{value:t,enumerable:!0}):a,t)),k=t=>s(i({},\"__esModule\",{value:!0}),t);var l=f((M,o)=>{o.exports=_jsx_runtime});var C={};g(C,{default:()=>d});var n=b(l());function h(t){let e={a:\"a\",code:\"code\",em:\"em\",h2:\"h2\",h3:\"h3\",li:\"li\",p:\"p\",pre:\"pre\",strong:\"strong\",ul:\"ul\",...t.components},{Image:a}=e;return a||v(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\"We are excited to introduce our latest library, \",(0,n.jsx)(e.code,{children:\"@unkey/cache\"}),\", designed to make caching in serverless applications easy and enjoyable.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"the-challenges-of-caching-in-cloudflare-workers\",children:\"The challenges of caching in Cloudflare Workers\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Our journey with caching on Cloudflare Workers highlighted several challenges. The most significant issue was the lack of persistent memory, which meant that each request could start with a cold cache. Additionally, Cloudflare KV, while nice to use, proved to be too slow for our needs: The p99 was 560ms (\",(0,n.jsx)(e.a,{href:\"https://upstash.com/blog/edgecaching-benchmark\",children:\"source\"}),\").\"]}),`\n`,(0,n.jsx)(e.p,{children:\"To mitigate these issues, we implemented a tiered caching strategy. By utilizing an in-memory store as the first tier and Cloudflare's CDN cache as the fallback, we achieved the best of both worlds, latency and decent hit rate.\"}),`\n`,(0,n.jsx)(a,{src:\"/images/blog-images/announcing-unkey-cache-package/cache-hits.png\",alt:\"Cache hit ratio\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"The ~27% memory hit rate might not be the most impressive, but it's free and does not add any latency. Unfortunately there's little we can do to increase it, as Cloudflare may evict a worker instance at any moment. However as traffic grows, the hit rate will increase too.\"}),`\n`,(0,n.jsx)(e.p,{children:\"If a memory cache miss occurs, the Cloudflare cache will be checked, which adds some latency but is still faster than any other alternative we found.\"}),`\n`,(0,n.jsx)(a,{src:\"/images/blog-images/announcing-unkey-cache-package/cache-latency.png\",alt:\"Cache latency\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"This performed well, but the developer experience left something to be desired.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"the-problem-with-existing-solutions\",children:\"The problem with existing solutions\"}),`\n`,(0,n.jsx)(e.p,{children:\"Caching is a common requirement in many applications, but traditional approaches often fall short. Here's a typical example of what developers have to deal with:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const cache = new Some3rdPartyCache(...)\n\ntype User = { email: string };\n\nlet user = await cache.get(\"chronark\") as User | undefined | null;\nif (!user) {\n  user = await db.query.users.findFirst({\n    where: (table, { eq }) => eq(table.id, \"chronark\"),\n  });\n  await cache.set(\"chronark\", user, Date.now() + 60_000)\n}\n\n// use user\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"@unkey/cache\"}),\" abstracts all the boilerplate away and gives you a clean API that is fully type-safe:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const user = await cache.user.swr(\"chronark\", async (id) => {\n  return await db.query.users.findFirst({\n    where: (table, { eq }) => eq(table.id, id),\n  });\n});\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"key-features\",children:\"Key features\"}),`\n`,(0,n.jsxs)(e.p,{children:['The \"u\" in \"unkey\" stands for \"batteries included\"! ',(0,n.jsx)(e.em,{children:\"(English may not be my first language)\"})]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"E2E Typesafe\"}),\": Fully type-safe, clean and intuitive API with intellisense autocomplete.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Tiered Cache\"}),\": Chain multiple caches together for fast and reliable caching.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Stale-While-Revalidate\"}),\": Most 3rd party caches support setting a time-to-live, but you needed to handle SWR yourself, until now. Just configure \",(0,n.jsx)(e.code,{children:\"fresh\"}),\" and \",(0,n.jsx)(e.code,{children:\"stale\"}),\" times and let the cache handle the rest.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Metrics Collection\"}),\": Middleware for gathering metrics to monitor and debug your cache usage.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Encryption\"}),\": Middleware for automatic encryption of cache values, protecting your data at rest.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Composable Design\"}),\": Mix and match \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/libraries/ts/cache/overview#primitives\",children:\"primitives\"}),\" to build exactly what you need.\"]}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"getting-started\",children:\"Getting Started\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Install \",(0,n.jsx)(e.code,{children:\"@unkey/cache\"}),\":\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`npm install @unkey/cache\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"basic-cache\",children:\"Basic cache\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { createCache, DefaultStatefulContext, Namespace } from \"@unkey/cache\";\nimport { MemoryStore } from \"@unkey/cache/stores\";\n\n/**\n * Let's say we have two types, \\`User\\` and \\`Project\\`:\n */\ntype User = { id: string; email: string };\ntype Project = { name: string; description: string };\n\n/**\n * Next we'll be creating a store. A store is really just a small abstraction\n * over a key-value database.\n */\nconst memory = new MemoryStore({ persistentMap: new Map() });\n\n/**\n * We'll create a cache instance with our two types, \\`User\\` and \\`Project\\`, and\n * configure the cache to use the memory store. We'll also set the \\`fresh\\` and\n * \\`stale\\` times for each type.\n * The \\`ctx\\` object is provided in the request handler and allows us to do some\n * background work without blocking the request.\n */\nconst cache = createCache({\n    user: new Namespace<User>(ctx, {\n      stores: [memory],\n      fresh: 60_000,\n      stale: 300_000,\n    }),\n    project: new Namespace<Project>(ctx, {\n      stores: [memory],\n      fresh: 300_000,\n      stale: 900_000,\n    })\n});\n\n/**\n * That's it! Now we can use the cache like this:\n */\nawait cache.user.set(\"userId\", { id: \"userId\", email: \"user@email.com\" });\nconst user = await cache.user.get(\"userId\");\nconsole.log(user);\n\n\n/**\n * To make full use of the SWR capabilities, we can use the \\`swr\\` method, which\n * will automatically handle the cache misses and cache updates for us.\n * This will check all stores for the value, and if it's not found, it will\n * call the provided function to get the value and cache it automatically.\n */\nconst user = await cache.user.swr(\"userId\", async () => {\n  return await database.get(...)\n});\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"tiered-caching\",children:\"Tiered caching\"}),`\n`,(0,n.jsx)(e.p,{children:\"Tiered caching is a powerful feature that allows you to chain multiple caches together. This is useful when you want to use a fast, in-memory cache as the first tier and a slower, more persistent cache as the second tier.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { createCache, DefaultStatefulContext, Namespace } from \"@unkey/cache\";\nimport { CloudflareStore, MemoryStore } from \"@unkey/cache/stores\";\n\ntype User = { id: string; email: string };\n\nconst memory = new MemoryStore({ persistentMap: new Map() });\nconst cloudflare = new CloudflareStore({\n  domain: \"cache.unkey.dev\",\n  zoneId: process.env.CLOUDFLARE_ZONE_ID!,\n  cloudflareApiKey: process.env.CLOUDFLARE_API_KEY!,\n});\n\nconst cache = createCache({\n  user: new Namespace<User>(ctx, {\n    // memory is checked first, then cloudflare if memory misses\n    stores: [memory, cloudflare],\n    fresh: 60_000,\n    stale: 300_000,\n  })\n});\n\nawait cache.user.set(\"userId\", { id: \"userId\", email: \"user@email.com\" });\nconst user = await cache.user.get(\"userId\");\nconsole.log(user);\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"middleware\",children:\"Middleware\"}),`\n`,(0,n.jsx)(e.p,{children:\"There are two middlewares available out of the box:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Metrics\"}),\": Collects and forwards metrics on cache hits, misses, latency and evictions.\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:'import { withMetrics } from \"@unkey/cache/middleware\";'})}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Encryption\"}),\": Automatically encrypts and decrypts cache values.\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:'import { withEncryption } from \"@unkey/cache/middleware\";'})}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Please refer to the \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/libraries/ts/cache/overview#middlewares\",children:\"documentation\"}),\" for more information on how to use middlewares.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"At launch we ship with a memory store and a Cloudflare store, but everything is built to be \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/libraries/ts/cache/interface/store\",children:\"easily extensible\"}),`. We can add more stores and middlewares as needed, let us know what you'd want to see!\nWhether you're dealing with the limitations of serverless functions or simply need a nice caching abstraction, `,(0,n.jsx)(e.code,{children:\"@unkey/cache\"}),\" has you covered.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"As usual, everything is open source, check out our \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/unkey/tree/main/packages/cache\",children:\"GitHub repository\"}),\" and our \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/libraries/ts/cache/overview\",children:\"documentation\"}),\" for more information. We can't wait to see what you build with it!\"]})]})}function d(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(h,{...t})}):h(t)}function v(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return k(C);})();\n;return Component;",
    "slug": "announcing-unkey-cache-package",
    "url": "/blog/announcing-unkey-cache-package",
    "tableOfContents": [
      {
        "level": 2,
        "text": "The challenges of caching in Cloudflare Workers",
        "slug": "the-challenges-of-caching-in-cloudflare-workers"
      },
      {
        "level": 2,
        "text": "The problem with existing solutions",
        "slug": "the-problem-with-existing-solutions"
      },
      {
        "level": 2,
        "text": "Key features",
        "slug": "key-features"
      },
      {
        "level": 2,
        "text": "Getting Started",
        "slug": "getting-started"
      },
      {
        "level": 3,
        "text": "Basic cache",
        "slug": "basic-cache"
      },
      {
        "level": 3,
        "text": "Tiered caching",
        "slug": "tiered-caching"
      },
      {
        "level": 3,
        "text": "Middleware",
        "slug": "middleware"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "Unkey allows users to create an unlimited number of API keys for their applications. Counting these for our dashboard or API has become a growing issue for us.\n\nMost APIs have fewer than a thousand keys, however some of our larger customers have hundreds of thousands. And those customers are also the ones hitting our API the most.\n\n\n## Schema\n\n```sql\n\nCREATE TABLE `key_space` (\n\t`id` varchar(256) NOT NULL,\n\t`workspace_id` varchar(256) NOT NULL,\n\t# ... omitted\n)\n\nCREATE TABLE `keys` (\n\t`id` varchar(256) NOT NULL,\n\t`hash` varchar(256) NOT NULL,\n\t`workspace_id` varchar(256) NOT NULL,\n\t`key_space_id` varchar(256) NOT NULL,\n\t# ... omitted\n)\n```\n\n\nAs you can see, many `keys` belong to a single `key_space` and out query in question is:\n```sql\nSELECT count(*) FROM keys WHERE key_space_id = ?\n```\n\n## Options\n\nWe were looking at a few options how to fix this:\n\n1. Caching the count as part of a larger query\n2. Caching the `count(*)` query separately in our [tiered cache](https://www.unkey.com/blog/announcing-unkey-cache-package) using SWR semantics.\n3. Adding two new columns for storing approximated counts.\n\n\n## Solution\n\nWe went with the 3rd option, mainly because we would never run into a cold cache, where we don't have a value at all, nor does it depend on another component. We can use this in our dashboard just as easily as in our API and it behaves the same.\n\nAdding these two columns, one for storing the approximated count and one for storing a timestamp of when we last updated the count.\n```sql\nALTER TABLE `key_space`\n  ADD COLUMN `size_approx` int NOT NULL DEFAULT '0',\n  ADD COLUMN `size_last_updated_at` bigint NOT NULL DEFAULT '0'\n```\n\nBy storing the count on the `key_space` table, we get the count for free cause we're not doing an extra query.\nTo keep it up to date, we check the `size_last_updated_at` timestamp after every read and if it's too old (60s in our case), we refresh it asynchronously.\n\nHere's how we do it in drizzle:\n```ts\n\n\nconst keySpace = await db.query.keySpace.findFirst({where: ...})\nif (keySpace.sizeLastUpdatedAt < Date.now() - 60_000) {\n  const count = await db\n    .select({ count: sql<string>`count(*)` })\n    .from(schema.keys)\n    .where(and(eq(schema.keys.keySpaceId, keySpace.id), isNull(schema.keys.deletedAtM)));\n\n  keySpace.sizeApprox = Number.parseInt(count?.at(0)?.count ?? \"0\");\n  keySpace.sizeLastUpdatedAt = Date.now();\n\n  c.executionCtx.waitUntil(\n    db.primary\n      .update(schema.keySpace)\n      .set({\n        sizeApprox: keySpace.sizeApprox,\n        sizeLastUpdatedAt: keySpace.sizeLastUpdatedAt,\n      })\n      .where(eq(schema.keySpace.id, keySpace.id)),\n  );\n}\n```\n\nWe first load the `keySpace` and if the data is too old, we kick off a second query to count all keys.\nPotentially this might kick off many queries to refresh if a lot of requests come in at the same time, but that's also the case for our current system, where we always count all rows.\n\nIn the future we might want to run a cron job to refresh counts in the background and remove the manual refresh, but we haven't needed that yet.",
    "title": "Approximating row counts",
    "description": "Caching count(*) queries without a cache",
    "author": "andreas",
    "date": "2024-11-25",
    "tags": [
      "engineering"
    ],
    "image": "/images/blog-images/covers/approximating-row-counts.png",
    "_meta": {
      "filePath": "approximating-row-counts.mdx",
      "fileName": "approximating-row-counts.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "approximating-row-counts"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var r=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,w=Object.prototype.hasOwnProperty;var k=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),f=(t,e)=>{for(var a in e)r(t,a,{get:e[a],enumerable:!0})},i=(t,e,a,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let o of m(e))!w.call(t,o)&&o!==a&&r(t,o,{get:()=>e[o],enumerable:!(s=p(e,o))||s.enumerable});return t};var g=(t,e,a)=>(a=t!=null?u(y(t)):{},i(e||!t||!t.__esModule?r(a,\"default\",{value:t,enumerable:!0}):a,t)),L=t=>i(r({},\"__esModule\",{value:!0}),t);var d=k((N,c)=>{c.exports=_jsx_runtime});var A={};f(A,{default:()=>l});var n=g(d());function h(t){let e={a:\"a\",code:\"code\",h2:\"h2\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",...t.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"Unkey allows users to create an unlimited number of API keys for their applications. Counting these for our dashboard or API has become a growing issue for us.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Most APIs have fewer than a thousand keys, however some of our larger customers have hundreds of thousands. And those customers are also the ones hitting our API the most.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"schema\",children:\"Schema\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sql\",children:\"\\nCREATE TABLE `key_space` (\\n\t`id` varchar(256) NOT NULL,\\n\t`workspace_id` varchar(256) NOT NULL,\\n\t# ... omitted\\n)\\n\\nCREATE TABLE `keys` (\\n\t`id` varchar(256) NOT NULL,\\n\t`hash` varchar(256) NOT NULL,\\n\t`workspace_id` varchar(256) NOT NULL,\\n\t`key_space_id` varchar(256) NOT NULL,\\n\t# ... omitted\\n)\\n\"})}),`\n`,(0,n.jsxs)(e.p,{children:[\"As you can see, many \",(0,n.jsx)(e.code,{children:\"keys\"}),\" belong to a single \",(0,n.jsx)(e.code,{children:\"key_space\"}),\" and out query in question is:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sql\",children:`SELECT count(*) FROM keys WHERE key_space_id = ?\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"options\",children:\"Options\"}),`\n`,(0,n.jsx)(e.p,{children:\"We were looking at a few options how to fix this:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Caching the count as part of a larger query\"}),`\n`,(0,n.jsxs)(e.li,{children:[\"Caching the \",(0,n.jsx)(e.code,{children:\"count(*)\"}),\" query separately in our \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/blog/announcing-unkey-cache-package\",children:\"tiered cache\"}),\" using SWR semantics.\"]}),`\n`,(0,n.jsx)(e.li,{children:\"Adding two new columns for storing approximated counts.\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"solution\",children:\"Solution\"}),`\n`,(0,n.jsx)(e.p,{children:\"We went with the 3rd option, mainly because we would never run into a cold cache, where we don't have a value at all, nor does it depend on another component. We can use this in our dashboard just as easily as in our API and it behaves the same.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Adding these two columns, one for storing the approximated count and one for storing a timestamp of when we last updated the count.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sql\",children:\"ALTER TABLE `key_space`\\n  ADD COLUMN `size_approx` int NOT NULL DEFAULT '0',\\n  ADD COLUMN `size_last_updated_at` bigint NOT NULL DEFAULT '0'\\n\"})}),`\n`,(0,n.jsxs)(e.p,{children:[\"By storing the count on the \",(0,n.jsx)(e.code,{children:\"key_space\"}),` table, we get the count for free cause we're not doing an extra query.\nTo keep it up to date, we check the `,(0,n.jsx)(e.code,{children:\"size_last_updated_at\"}),\" timestamp after every read and if it's too old (60s in our case), we refresh it asynchronously.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Here's how we do it in drizzle:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-ts\",children:`\n\nconst keySpace = await db.query.keySpace.findFirst({where: ...})\nif (keySpace.sizeLastUpdatedAt < Date.now() - 60_000) {\n  const count = await db\n    .select({ count: sql<string>\\`count(*)\\` })\n    .from(schema.keys)\n    .where(and(eq(schema.keys.keySpaceId, keySpace.id), isNull(schema.keys.deletedAtM)));\n\n  keySpace.sizeApprox = Number.parseInt(count?.at(0)?.count ?? \"0\");\n  keySpace.sizeLastUpdatedAt = Date.now();\n\n  c.executionCtx.waitUntil(\n    db.primary\n      .update(schema.keySpace)\n      .set({\n        sizeApprox: keySpace.sizeApprox,\n        sizeLastUpdatedAt: keySpace.sizeLastUpdatedAt,\n      })\n      .where(eq(schema.keySpace.id, keySpace.id)),\n  );\n}\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"We first load the \",(0,n.jsx)(e.code,{children:\"keySpace\"}),` and if the data is too old, we kick off a second query to count all keys.\nPotentially this might kick off many queries to refresh if a lot of requests come in at the same time, but that's also the case for our current system, where we always count all rows.`]}),`\n`,(0,n.jsx)(e.p,{children:\"In the future we might want to run a cron job to refresh counts in the background and remove the manual refresh, but we haven't needed that yet.\"})]})}function l(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(h,{...t})}):h(t)}return L(A);})();\n;return Component;",
    "slug": "approximating-row-counts",
    "url": "/blog/approximating-row-counts",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Schema",
        "slug": "schema"
      },
      {
        "level": 2,
        "text": "Options",
        "slug": "options"
      },
      {
        "level": 2,
        "text": "Solution",
        "slug": "solution"
      }
    ]
  },
  {
    "content": "<Image src=\"/images/blog-images/audit-logs/auditlogsscreen.png\" alt=\"Audit Logs\" width=\"1920\" height=\"1080\"/>\n\n[Earlier this year](https://www.unkey.com/changelog#2024-01-19), we introduced audit logs as a beta feature in the Unkey dashboard, meaning that they were an opt-in\nfeature for beta testers. They're now generally available to all customers.\n\nNavigating to the [audit logs page](https://app.unkey.com/audit/) in the Unkey dashboard, you'll see a live feed of all of the events that have \noccured in your Unkey workspace, from all your customers. \n\nFor example, if you invited a new teammate to your workspace and they proceeded to create a new key, verify it, and \nadd ratelimiting to their account, you'll see that in the audit logs - along with location and timestamp.\n\nThis feature is primarily geared towards our larger customers: several software regulations - for instance, GDPR and SOCII -\nrequire audit logging. So this feature unlocks the ability to use Unkey for our compliance-conscious-customers!\n\nThere are two other primary reasons why audit logs are important:\n\n- **Security**: logging user actions helps to prevent and mitigate security breaches\n- **Debugging**: having a historical record of events in your workspace can be useful for time-travel debugging, just like your git history is\n\nAudit Logs are available to all customers with a 30-day retention period. If you'd like to access audit logs for longer, you can [upgrade\nto Pro](https://app.unkey.com/settings/billing) via the dashboard. The Pro tier comes with a 90-day retention period for\naudit logs.\n\nIf you need an audit log retention period longer than 90 days, you can [contact us](https://www.unkey.com/pricing) to discuss your needs.\n\nSee our [documentation](https://www.unkey.com/docs/audit-log/introduction) for how to get started.",
    "title": "Audit Logs are now generally available",
    "description": "Automatically track every event in your Unkey workspace.",
    "author": "dom",
    "date": "2024-06-29",
    "tags": [
      "launchweek",
      "product"
    ],
    "image": "/images/blog-images/covers/audit-logs.png",
    "_meta": {
      "filePath": "audit-logs-ga.mdx",
      "fileName": "audit-logs-ga.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "audit-logs-ga"
    },
    "mdx": "var Component=(()=>{var h=Object.create;var a=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var f=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),w=(n,e)=>{for(var o in e)a(n,o,{get:e[o],enumerable:!0})},s=(n,e,o,i)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of p(e))!m.call(n,r)&&r!==o&&a(n,r,{get:()=>e[r],enumerable:!(i=g(e,r))||i.enumerable});return n};var k=(n,e,o)=>(o=n!=null?h(y(n)):{},s(e||!n||!n.__esModule?a(o,\"default\",{value:n,enumerable:!0}):o,n)),b=n=>s(a({},\"__esModule\",{value:!0}),n);var c=f((j,l)=>{l.exports=_jsx_runtime});var x={};w(x,{default:()=>u});var t=k(c());function d(n){let e={a:\"a\",li:\"li\",p:\"p\",strong:\"strong\",ul:\"ul\",...n.components},{Image:o}=e;return o||v(\"Image\",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o,{src:\"/images/blog-images/audit-logs/auditlogsscreen.png\",alt:\"Audit Logs\",width:\"1920\",height:\"1080\"}),`\n`,(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.a,{href:\"https://www.unkey.com/changelog#2024-01-19\",children:\"Earlier this year\"}),`, we introduced audit logs as a beta feature in the Unkey dashboard, meaning that they were an opt-in\nfeature for beta testers. They're now generally available to all customers.`]}),`\n`,(0,t.jsxs)(e.p,{children:[\"Navigating to the \",(0,t.jsx)(e.a,{href:\"https://app.unkey.com/audit/\",children:\"audit logs page\"}),` in the Unkey dashboard, you'll see a live feed of all of the events that have\noccured in your Unkey workspace, from all your customers.`]}),`\n`,(0,t.jsx)(e.p,{children:`For example, if you invited a new teammate to your workspace and they proceeded to create a new key, verify it, and\nadd ratelimiting to their account, you'll see that in the audit logs - along with location and timestamp.`}),`\n`,(0,t.jsx)(e.p,{children:`This feature is primarily geared towards our larger customers: several software regulations - for instance, GDPR and SOCII -\nrequire audit logging. So this feature unlocks the ability to use Unkey for our compliance-conscious-customers!`}),`\n`,(0,t.jsx)(e.p,{children:\"There are two other primary reasons why audit logs are important:\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Security\"}),\": logging user actions helps to prevent and mitigate security breaches\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Debugging\"}),\": having a historical record of events in your workspace can be useful for time-travel debugging, just like your git history is\"]}),`\n`]}),`\n`,(0,t.jsxs)(e.p,{children:[\"Audit Logs are available to all customers with a 30-day retention period. If you'd like to access audit logs for longer, you can \",(0,t.jsx)(e.a,{href:\"https://app.unkey.com/settings/billing\",children:`upgrade\nto Pro`}),` via the dashboard. The Pro tier comes with a 90-day retention period for\naudit logs.`]}),`\n`,(0,t.jsxs)(e.p,{children:[\"If you need an audit log retention period longer than 90 days, you can \",(0,t.jsx)(e.a,{href:\"https://www.unkey.com/pricing\",children:\"contact us\"}),\" to discuss your needs.\"]}),`\n`,(0,t.jsxs)(e.p,{children:[\"See our \",(0,t.jsx)(e.a,{href:\"https://www.unkey.com/docs/audit-log/introduction\",children:\"documentation\"}),\" for how to get started.\"]})]})}function u(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}function v(n,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+n+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return b(x);})();\n;return Component;",
    "slug": "audit-logs-ga",
    "url": "/blog/audit-logs-ga",
    "tableOfContents": []
  },
  {
    "content": "Before starting Unkey, I worked at several companies ranging in size from 5 to 5,000 employees, and one of the biggest hurdles a company can face is how to encourage authentic communication.\n\n## What is authentic communication?\n\nAuthentic communication has been covered many times over the years, but the idea has a few core concepts:\n\n- Being able to communicate in the style that fits you\n- Being able to be your genuine self regardless of the interaction you are having\n- Being able to have a difficult conversation and not feel you are being dismissed\n- Listening to other parties to understand their point of view\n\n## How do you build this into a team?\n\nBuilding authentic communication into a team requires a lot of work and understanding, but it pays off in the long run for the health of the team and the company. Here are some steps that can help:\n\n- **Model the behavior:** Leaders in the organization or team should lead by example when communicating with others. They should practice active listening, be open to feedback, and show empathy.\n- **Create a safe environment:** The team should feel safe to express their thoughts and feelings without fear of judgment or retribution.\n- **Encourage feedback:** Regular feedback sessions help team members feel heard and valued. It can also provide opportunities to address any issues or misunderstandings. It also is a great place to come up with new ideas.\n- **Celebrate diversity:** Each team member brings a unique perspective and communication style. Celebrating these differences can encourage more authentic communication.\n\nWhile all of these may seem obvious when the team is smaller, ensuring everyone has an equal opportunity to share their thoughts becomes harder when the team grows.\n\n## How are we attempting this at Unkey?\n\nUnkey lives on being open from the top; Andreas and I ensure everyone understands how Unkey runs, what we expect, and the company's direction. So, for our team to feel empowered to be their authentic self when communicating, we do the following:\n\n- **Updates:** Every update we send out to investors and customers is public and can be accessed by the team; I intentionally send a Slack message every month in the general channel. These updates include our current status for KPIs, the money we have spent, the money we have left, usage, and paying customers.\n- **Open communication:** We communicate in the general channel using threads to keep things tidy, whether it is an idea, direction, or potentially something we are concerned about. This allows the team to provide their feedback, concerns, or excitement.\n- **Meetings are for everyone:** Unkey only runs two meetings as a team; one is planning every Monday, and the other is demo every other Friday. These meetings are open forums and flexible; the team can provide their thoughts about what is up next for us and things they want to work on and provide input on ideas they might have. After anything is demoed, we open the floor for discussions surrounding the feature; we can talk about the code behind it and changes that might improve it, knowing that feedback is welcomed. We also ensure everyone gets time on the floor so no one is left out.\n- **Open door policies:** Andreas and I have an open door policy, albeit more of an open Slack policy, which could lead to a meeting. Our team can come to us with concerns, problems they are facing, feedback, and ideas at any point and communicate them to us however they want.\n- **Dedicated space:** Andreas meets with the developers twice a month, and I meet with them once a month. This time is for them and not for us. They can come with technical questions, business questions, vision questions, or to chat about how they are feeling.\n\nI understand that our current implementation wont scale past 20 or 30 team members; we will tweak this to allow for authenticated communication as we keep this a core value at Unkey.",
    "title": "How to build authentic communication in your team",
    "description": "Authentic communication is the key to building trust and collaboration in your team.",
    "author": "james",
    "date": "2024-02-23",
    "tags": [
      "company"
    ],
    "image": "/images/blog-images/covers/authentic-comms.png",
    "_meta": {
      "filePath": "building-authentic-comms.mdx",
      "fileName": "building-authentic-comms.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "building-authentic-comms"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var a=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var w=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),y=(t,e)=>{for(var i in e)a(t,i,{get:e[i],enumerable:!0})},s=(t,e,i,r)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let o of g(e))!f.call(t,o)&&o!==i&&a(t,o,{get:()=>e[o],enumerable:!(r=m(e,o))||r.enumerable});return t};var b=(t,e,i)=>(i=t!=null?u(p(t)):{},s(e||!t||!t.__esModule?a(i,\"default\",{value:t,enumerable:!0}):i,t)),v=t=>s(a({},\"__esModule\",{value:!0}),t);var c=w((I,h)=>{h.exports=_jsx_runtime});var k={};y(k,{default:()=>l});var n=b(c());function d(t){let e={h2:\"h2\",li:\"li\",p:\"p\",strong:\"strong\",ul:\"ul\",...t.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"Before starting Unkey, I worked at several companies ranging in size from 5 to 5,000 employees, and one of the biggest hurdles a company can face is how to encourage authentic communication.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"what-is-authentic-communication\",children:\"What is authentic communication?\"}),`\n`,(0,n.jsx)(e.p,{children:\"Authentic communication has been covered many times over the years, but the idea has a few core concepts:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Being able to communicate in the style that fits you\"}),`\n`,(0,n.jsx)(e.li,{children:\"Being able to be your genuine self regardless of the interaction you are having\"}),`\n`,(0,n.jsx)(e.li,{children:\"Being able to have a difficult conversation and not feel you are being dismissed\"}),`\n`,(0,n.jsx)(e.li,{children:\"Listening to other parties to understand their point of view\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"how-do-you-build-this-into-a-team\",children:\"How do you build this into a team?\"}),`\n`,(0,n.jsx)(e.p,{children:\"Building authentic communication into a team requires a lot of work and understanding, but it pays off in the long run for the health of the team and the company. Here are some steps that can help:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Model the behavior:\"}),\" Leaders in the organization or team should lead by example when communicating with others. They should practice active listening, be open to feedback, and show empathy.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Create a safe environment:\"}),\" The team should feel safe to express their thoughts and feelings without fear of judgment or retribution.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Encourage feedback:\"}),\" Regular feedback sessions help team members feel heard and valued. It can also provide opportunities to address any issues or misunderstandings. It also is a great place to come up with new ideas.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Celebrate diversity:\"}),\" Each team member brings a unique perspective and communication style. Celebrating these differences can encourage more authentic communication.\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"While all of these may seem obvious when the team is smaller, ensuring everyone has an equal opportunity to share their thoughts becomes harder when the team grows.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"how-are-we-attempting-this-at-unkey\",children:\"How are we attempting this at Unkey?\"}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey lives on being open from the top; Andreas and I ensure everyone understands how Unkey runs, what we expect, and the company's direction. So, for our team to feel empowered to be their authentic self when communicating, we do the following:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Updates:\"}),\" Every update we send out to investors and customers is public and can be accessed by the team; I intentionally send a Slack message every month in the general channel. These updates include our current status for KPIs, the money we have spent, the money we have left, usage, and paying customers.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Open communication:\"}),\" We communicate in the general channel using threads to keep things tidy, whether it is an idea, direction, or potentially something we are concerned about. This allows the team to provide their feedback, concerns, or excitement.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Meetings are for everyone:\"}),\" Unkey only runs two meetings as a team; one is planning every Monday, and the other is demo every other Friday. These meetings are open forums and flexible; the team can provide their thoughts about what is up next for us and things they want to work on and provide input on ideas they might have. After anything is demoed, we open the floor for discussions surrounding the feature; we can talk about the code behind it and changes that might improve it, knowing that feedback is welcomed. We also ensure everyone gets time on the floor so no one is left out.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Open door policies:\"}),\" Andreas and I have an open door policy, albeit more of an open Slack policy, which could lead to a meeting. Our team can come to us with concerns, problems they are facing, feedback, and ideas at any point and communicate them to us however they want.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Dedicated space:\"}),\" Andreas meets with the developers twice a month, and I meet with them once a month. This time is for them and not for us. They can come with technical questions, business questions, vision questions, or to chat about how they are feeling.\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"I understand that our current implementation won\\u2019t scale past 20 or 30 team members; we will tweak this to allow for authenticated communication as we keep this a core value at Unkey.\"})]})}function l(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(d,{...t})}):d(t)}return v(k);})();\n;return Component;",
    "slug": "building-authentic-comms",
    "url": "/blog/building-authentic-comms",
    "tableOfContents": [
      {
        "level": 2,
        "text": "What is authentic communication?",
        "slug": "what-is-authentic-communication"
      },
      {
        "level": 2,
        "text": "How do you build this into a team?",
        "slug": "how-do-you-build-this-into-a-team"
      },
      {
        "level": 2,
        "text": "How are we attempting this at Unkey?",
        "slug": "how-are-we-attempting-this-at-unkey"
      }
    ]
  },
  {
    "content": "In the world of remote work, information is currency. Being an async, remote team means we don't have the luxury of hallway conversations or quick desk drop-bys. We had to find another way to maintain momentum and clarity.\n\n## The Silent Killer of Remote Teams: Information Silos\n\nWhen we first launched Unkey in 2023, we fell into a common trap. Important conversations happened in direct messages. Critical decisions were made in calls with only a few participants. Knowledge became trapped in private channels, invisible to the wider team.\n\nIt's easier send a quick unstructured DM than to think about where a conversation should live. Yet this convenience comes with hidden costs that compound over time:\n\n- Team members waste time asking questions that have already been answered elsewhere\n- Context is constantly lost and needs to be re-explained\n- New hires take longer to become productive\n- Decisions lack diverse input\n\nAfter a few months of this, we noticed something concerning. We were building silos in a company of fewer than ten people. If we couldn't solve this problem while small, how would we manage as we grew?\n\n## Our Public-By-Default Approach\n\nAt Unkey, \"working in public\" means shifting conversations from private direct messages to public Slack channels where everyone can benefit. This approach ensures that knowledge, decisions, and context are accessible to the entire team.\n\nThis doesn't mean eliminating private conversations entirely. Some personal or sensitive topics should not be in public, but the vast majority of communication isn't like that.\n\nBy defaulting to transparency, we create an environment where information flows freely, context is preserved, and everyone has the opportunity to contribute.\n\n## The Unexpected Benefits of Public Communication\n\nWhat started as an experiment has become central to how we operate. Here are the benefits:\n\n### Ambient Knowledge Sharing\n\nWhen conversations happen in public, everyone has the opportunity to absorb information passively.\n\nThis ambient awareness creates a team that's more informed and connected to the wider business than would otherwise be possible.\nWe're hiring really smart people, but that's useless if they don't have the information necessary to make smart decisions.\n\n### Better, More Inclusive Decisions\n\nSome of our best insights have come from unexpected sources. When we discuss infrastructure architectures in public rather than private channels, our engineers might offer a technical perspective we hadn't considered.\n\nBy making discussions visible, we tap into the collective intelligence of our entire team. People can choose to contribute or simply observe, but the opportunity to participate is always there.\n\n### Stronger Remote Culture\n\nPerhaps most surprisingly, public communication has strengthened our company culture. In an office, culture develops through shared experiences  overhearing conversations, noticing how people interact, absorbing the environment. Remote work removes these opportunities for passive cultural transmission.\n\nPublic channels recreate some of this ambient exposure. New team members can observe how we communicate, what we prioritize, and how we solve problems simply by watching public discussions. This accelerates their onboarding in a way that private communications never could.\n\n## How We Implement Public Communication at Unkey\n\nThere is only one rule:\n\n> Default to public\n\nThe challenges we found are mostly around making everyone aware and defaulting to public messages. It's natural to use DMs, we just have to rewrire our brains a little.\n\nWhen someone DMs me with a question, I'll often respond: \"ask in #general\". Then they will copy the question to the appropriate channel and I will answer it there.\n\nBy now we're pretty consistent about asking in public channels in the first place, but a gentle redirect like that goes a long way. Nobody is trying to go against the system, most tools (slack in this case) just aren't designed to encourage you to talk publicly.\n\n## Challenges and How We Address Them\n\nWorking in public isn't without challenges:\n\n### Information Overload\n\nWith more visible conversations, notification fatigue is real. We're nowhere near that problem yet, but there are some simple ways to help:\n\n- Encouraging liberal use of Slack's \"mute channel\" feature\n- Setting clear expectations that no one needs to read everything\n- Using thread replies to keep discussions organized\n\n### Psychological Safety\n\nSome team members may worry about asking \"dumb questions\" in public. We actively work to create psychological safety by:\n\n- Leading by example (I regularly ask basic questions in public channels)\n- Celebrating questions as contributions to our shared knowledge\n- Responding thoughtfully to every question, regardless of complexity\n- Never making people feel inadequate for not knowing something\n\n## Getting Started with Public Communication\n\nIf you want to give it a try with your team, here's what I would do:\n\n1. **Start with intention**: Explain the \"why\" behind public communication to your team\n2. **Lead by example**: Move your own conversations to public channels first. Why should anyone do it if you don't do it?\n4. **Redirect gently**: When private messages occur, kindly suggest moving to public channels\n5. **Be patient**: Behavioral changes take time and consistent reinforcement\n\n## The Competitive Advantage of Transparency\n\nThis approach has influenced not just how we work internally, but also how we build our product. Unkey's API management tools are designed with the same principles of visibility and transparency that guide our internal communication. We believe teams work better when they have clear insight into what's happening  whether that's company communication or API usage.\n\nFor small, remote startups, information flow is everything. By making transparency our default, we've created an environment where knowledge flows freely, decisions are visible, and everyone has the context they need to do their best work.\n\nIf you'd like to work like this, just give it a shot, or visit [unkey.com/careers](https://unkey.com/careers).",
    "title": "Building In Public",
    "description": "How we embrace transparency in a remote and async team",
    "author": "andreas",
    "date": "2025-02-27",
    "tags": [
      "company"
    ],
    "image": "/images/blog-images/covers/building-in-public.png",
    "_meta": {
      "filePath": "building-in-public.mdx",
      "fileName": "building-in-public.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "building-in-public"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var r=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var w=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var y=(i,e)=>()=>(e||i((e={exports:{}}).exports,e),e.exports),b=(i,e)=>{for(var t in e)r(i,t,{get:e[t],enumerable:!0})},s=(i,e,t,a)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let o of p(e))!g.call(i,o)&&o!==t&&r(i,o,{get:()=>e[o],enumerable:!(a=m(e,o))||a.enumerable});return i};var f=(i,e,t)=>(t=i!=null?u(w(i)):{},s(e||!i||!i.__esModule?r(t,\"default\",{value:i,enumerable:!0}):t,i)),v=i=>s(r({},\"__esModule\",{value:!0}),i);var c=y((I,l)=>{l.exports=_jsx_runtime});var k={};b(k,{default:()=>d});var n=f(c());function h(i){let e={a:\"a\",blockquote:\"blockquote\",h2:\"h2\",h3:\"h3\",li:\"li\",ol:\"ol\",p:\"p\",strong:\"strong\",ul:\"ul\",...i.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"In the world of remote work, information is currency. Being an async, remote team means we don't have the luxury of hallway conversations or quick desk drop-bys. We had to find another way to maintain momentum and clarity.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"the-silent-killer-of-remote-teams-information-silos\",children:\"The Silent Killer of Remote Teams: Information Silos\"}),`\n`,(0,n.jsx)(e.p,{children:\"When we first launched Unkey in 2023, we fell into a common trap. Important conversations happened in direct messages. Critical decisions were made in calls with only a few participants. Knowledge became trapped in private channels, invisible to the wider team.\"}),`\n`,(0,n.jsx)(e.p,{children:\"It's easier send a quick unstructured DM than to think about where a conversation should live. Yet this convenience comes with hidden costs that compound over time:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Team members waste time asking questions that have already been answered elsewhere\"}),`\n`,(0,n.jsx)(e.li,{children:\"Context is constantly lost and needs to be re-explained\"}),`\n`,(0,n.jsx)(e.li,{children:\"New hires take longer to become productive\"}),`\n`,(0,n.jsx)(e.li,{children:\"Decisions lack diverse input\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"After a few months of this, we noticed something concerning. We were building silos in a company of fewer than ten people. If we couldn't solve this problem while small, how would we manage as we grew?\"}),`\n`,(0,n.jsx)(e.h2,{id:\"our-public-by-default-approach\",children:\"Our Public-By-Default Approach\"}),`\n`,(0,n.jsx)(e.p,{children:'At Unkey, \"working in public\" means shifting conversations from private direct messages to public Slack channels where everyone can benefit. This approach ensures that knowledge, decisions, and context are accessible to the entire team.'}),`\n`,(0,n.jsx)(e.p,{children:\"This doesn't mean eliminating private conversations entirely. Some personal or sensitive topics should not be in public, but the vast majority of communication isn't like that.\"}),`\n`,(0,n.jsx)(e.p,{children:\"By defaulting to transparency, we create an environment where information flows freely, context is preserved, and everyone has the opportunity to contribute.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"the-unexpected-benefits-of-public-communication\",children:\"The Unexpected Benefits of Public Communication\"}),`\n`,(0,n.jsx)(e.p,{children:\"What started as an experiment has become central to how we operate. Here are the benefits:\"}),`\n`,(0,n.jsx)(e.h3,{id:\"ambient-knowledge-sharing\",children:\"Ambient Knowledge Sharing\"}),`\n`,(0,n.jsx)(e.p,{children:\"When conversations happen in public, everyone has the opportunity to absorb information passively.\"}),`\n`,(0,n.jsx)(e.p,{children:`This ambient awareness creates a team that's more informed and connected to the wider business than would otherwise be possible.\nWe're hiring really smart people, but that's useless if they don't have the information necessary to make smart decisions.`}),`\n`,(0,n.jsx)(e.h3,{id:\"better-more-inclusive-decisions\",children:\"Better, More Inclusive Decisions\"}),`\n`,(0,n.jsx)(e.p,{children:\"Some of our best insights have come from unexpected sources. When we discuss infrastructure architectures in public rather than private channels, our engineers might offer a technical perspective we hadn't considered.\"}),`\n`,(0,n.jsx)(e.p,{children:\"By making discussions visible, we tap into the collective intelligence of our entire team. People can choose to contribute or simply observe, but the opportunity to participate is always there.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"stronger-remote-culture\",children:\"Stronger Remote Culture\"}),`\n`,(0,n.jsx)(e.p,{children:\"Perhaps most surprisingly, public communication has strengthened our company culture. In an office, culture develops through shared experiences \\u2013 overhearing conversations, noticing how people interact, absorbing the environment. Remote work removes these opportunities for passive cultural transmission.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Public channels recreate some of this ambient exposure. New team members can observe how we communicate, what we prioritize, and how we solve problems simply by watching public discussions. This accelerates their onboarding in a way that private communications never could.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"how-we-implement-public-communication-at-unkey\",children:\"How We Implement Public Communication at Unkey\"}),`\n`,(0,n.jsx)(e.p,{children:\"There is only one rule:\"}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsx)(e.p,{children:\"Default to public\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"The challenges we found are mostly around making everyone aware and defaulting to public messages. It's natural to use DMs, we just have to rewrire our brains a little.\"}),`\n`,(0,n.jsx)(e.p,{children:`When someone DMs me with a question, I'll often respond: \"ask in #general\". Then they will copy the question to the appropriate channel and I will answer it there.`}),`\n`,(0,n.jsx)(e.p,{children:\"By now we're pretty consistent about asking in public channels in the first place, but a gentle redirect like that goes a long way. Nobody is trying to go against the system, most tools (slack in this case) just aren't designed to encourage you to talk publicly.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"challenges-and-how-we-address-them\",children:\"Challenges and How We Address Them\"}),`\n`,(0,n.jsx)(e.p,{children:\"Working in public isn't without challenges:\"}),`\n`,(0,n.jsx)(e.h3,{id:\"information-overload\",children:\"Information Overload\"}),`\n`,(0,n.jsx)(e.p,{children:\"With more visible conversations, notification fatigue is real. We're nowhere near that problem yet, but there are some simple ways to help:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:`Encouraging liberal use of Slack's \"mute channel\" feature`}),`\n`,(0,n.jsx)(e.li,{children:\"Setting clear expectations that no one needs to read everything\"}),`\n`,(0,n.jsx)(e.li,{children:\"Using thread replies to keep discussions organized\"}),`\n`]}),`\n`,(0,n.jsx)(e.h3,{id:\"psychological-safety\",children:\"Psychological Safety\"}),`\n`,(0,n.jsx)(e.p,{children:'Some team members may worry about asking \"dumb questions\" in public. We actively work to create psychological safety by:'}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Leading by example (I regularly ask basic questions in public channels)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Celebrating questions as contributions to our shared knowledge\"}),`\n`,(0,n.jsx)(e.li,{children:\"Responding thoughtfully to every question, regardless of complexity\"}),`\n`,(0,n.jsx)(e.li,{children:\"Never making people feel inadequate for not knowing something\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"getting-started-with-public-communication\",children:\"Getting Started with Public Communication\"}),`\n`,(0,n.jsx)(e.p,{children:\"If you want to give it a try with your team, here's what I would do:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Start with intention\"}),': Explain the \"why\" behind public communication to your team']}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Lead by example\"}),\": Move your own conversations to public channels first. Why should anyone do it if you don't do it?\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Redirect gently\"}),\": When private messages occur, kindly suggest moving to public channels\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Be patient\"}),\": Behavioral changes take time and consistent reinforcement\"]}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"the-competitive-advantage-of-transparency\",children:\"The Competitive Advantage of Transparency\"}),`\n`,(0,n.jsx)(e.p,{children:\"This approach has influenced not just how we work internally, but also how we build our product. Unkey's API management tools are designed with the same principles of visibility and transparency that guide our internal communication. We believe teams work better when they have clear insight into what's happening \\u2013 whether that's company communication or API usage.\"}),`\n`,(0,n.jsx)(e.p,{children:\"For small, remote startups, information flow is everything. By making transparency our default, we've created an environment where knowledge flows freely, decisions are visible, and everyone has the context they need to do their best work.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"If you'd like to work like this, just give it a shot, or visit \",(0,n.jsx)(e.a,{href:\"https://unkey.com/careers\",children:\"unkey.com/careers\"}),\".\"]})]})}function d(i={}){let{wrapper:e}=i.components||{};return e?(0,n.jsx)(e,{...i,children:(0,n.jsx)(h,{...i})}):h(i)}return v(k);})();\n;return Component;",
    "slug": "building-in-public",
    "url": "/blog/building-in-public",
    "tableOfContents": [
      {
        "level": 2,
        "text": "The Silent Killer of Remote Teams: Information Silos",
        "slug": "the-silent-killer-of-remote-teams-information-silos"
      },
      {
        "level": 2,
        "text": "Our Public-By-Default Approach",
        "slug": "our-public-by-default-approach"
      },
      {
        "level": 2,
        "text": "The Unexpected Benefits of Public Communication",
        "slug": "the-unexpected-benefits-of-public-communication"
      },
      {
        "level": 3,
        "text": "Ambient Knowledge Sharing",
        "slug": "ambient-knowledge-sharing"
      },
      {
        "level": 3,
        "text": "Better, More Inclusive Decisions",
        "slug": "better-more-inclusive-decisions"
      },
      {
        "level": 3,
        "text": "Stronger Remote Culture",
        "slug": "stronger-remote-culture"
      },
      {
        "level": 2,
        "text": "How We Implement Public Communication at Unkey",
        "slug": "how-we-implement-public-communication-at-unkey"
      },
      {
        "level": 2,
        "text": "Challenges and How We Address Them",
        "slug": "challenges-and-how-we-address-them"
      },
      {
        "level": 3,
        "text": "Information Overload",
        "slug": "information-overload"
      },
      {
        "level": 3,
        "text": "Psychological Safety",
        "slug": "psychological-safety"
      },
      {
        "level": 2,
        "text": "Getting Started with Public Communication",
        "slug": "getting-started-with-public-communication"
      },
      {
        "level": 2,
        "text": "The Competitive Advantage of Transparency",
        "slug": "the-competitive-advantage-of-transparency"
      }
    ]
  },
  {
    "content": "Command Line Interfaces (CLI) have become integral tools for developers looking to streamline their workflow. Some of the biggest names in tech, including Vercel, GitHub, Netlify, and Planetscale, offer CLIs that provide a powerful way to interact with their services.\n\nThe question then comes up: How does CLI authentication work? How does a developer link this separate service with their authentication provider of choice? Let's delve into the world of CLI auth.\n\nSuppose you are getting ready to authenticate with a CLIyou might use a command like `npx vercel login`. But what exactly happens under the hood?\n\n> Check out the demo used in this blog post [here](https://unkey.com/templates/cli-auth)\n\n## CLI Auth Overview\n\nBefore we look at any code, let us look at a diagram that explains the process.\n\n<Image src=\"/images/blog-images/cli-auth/cli-auth-overview.png\" alt=\"CLI AUTH\" width=\"1920\" height=\"1080\"/>\n\nThe process begins when a user invokes the CLI, which starts a server on a free port that listens for an incoming request. This will also result in the user's web browser opening up to a specific URL for CLI authentication, let's say `unkey.com/cli-auth`, and it will include a unique code that the user will need to confirm the authentication process.\n\nOnce the web application has launched, the user is prompted to log in using their authentication method of choice. This could be a username, password, social login, or two-factor authentication (2FA) method. After the user has successfully authenticated, the web application will display a unique code that the CLI generated to the user. The user must then confirm the authentication process by entering the unique code into the web application.\n\nThe web application will then generate a new API key or token and return it to the CLI. The CLI will then store the token securely on the user's machine and use it for future requests to the service. The user will then be shown a message that the authentication process was successful, and they can return to the CLI.\n\n> User ---> CLI ---> Auth Web Page ---> Auth Confirmation ---> Token Generation ---> CLI token storage\n\nThe token is now securely stored on the user's machine, and each future CLI request will use this token to authenticate with the service without the user needing to re-authenticate each time.\n\n## From Terminal to API Key\n\nTo better understand the process, let's walk through a real-world example. We'll use the `@unkey/cli-demo` package, a simple CLI demonstrating the authentication process. The package is available on npm, and you can use it by running the following command:\n\n```bash\nnpx @unkey/cli-demo login\n```\n\nExecuting the command will create the local server and open a browser window that asks you to log in using Clerk. At the same time, the CLI will display a unique code that you will need to enter into the web application. Once you have entered the code, the web application will generate a new API key and send it back to the CLI. The CLI will then store the token securely on your machine and use it for future requests for a service.\n\nTo see the file that was created, you can run the following command:\n\n```bash\nls -a ~/\n```\n\nYou'll find `.unkey`, which holds your API key.\n\n## The Code Behind the Demo\n\nWe can break down the code into the CLI and the web application. The CLI is a simple Node server that creates a file named `.unkey` and stores your freshly created API key. The web application is a simple Next app that interacts with Unkey to generate a new API key.\n\n#### CLI Code\n\nThe CLI code has some boilerplate code that sets up a server and has a command named `login` that will start the server and open a browser window to the web application. The server will listen for a request from the web application and store the API key in a file.\n\nBelow is a promise waiting to be resolved when the server is started. The promise will resolve when the user has confirmed the authentication process and the API key has been generated and returned from the web, or the user cancels the request.\n\n```typescript title=\"/src/index.ts\"\n// set up HTTP server that waits for a request containing an API key\n// as the only query parameter\nconst authPromise = new Promise<ParsedUrlQuery>((resolve, reject) => {\n  server.on(\"request\", (req, res) => {\n    // Set CORS headers for all responses\n    res.setHeader(\"Access-Control-Allow-Origin\", \"*\");\n    res.setHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS\");\n    res.setHeader(\n      \"Access-Control-Allow-Headers\",\n      \"Content-Type, Authorization\",\n    );\n\n    if (req.method === \"OPTIONS\") {\n      res.writeHead(200);\n      res.end();\n    } else if (req.method === \"GET\") {\n      const parsedUrl = url.parse(req.url as string, true);\n      const queryParams = parsedUrl.query;\n      if (queryParams.cancelled) {\n        res.writeHead(200);\n        res.end();\n        reject(new UserCancellationError(\"Login process cancelled by user.\"));\n      } else {\n        res.writeHead(200);\n        res.end();\n        resolve(queryParams);\n      }\n    } else {\n      res.writeHead(405);\n      res.end();\n    }\n  });\n});\n```\n\n#### Web Application Code\n\nThe web application code is a Next.js application that uses Clerk to authenticate the user, generate a new API key, and send it back to the CLI. When the user successfully confirms the code in the web application, it will make a request to Unkey to generate a new API key associated with the user's account and send it back to the CLI.\n\nBelow is the verification function that is called when the user confirms the code in the web application. The function will request an endpoint called `/api/unkey` to generate a new API key.\n\n```typescript title=\"/web/app/auth/devices/page.tsx\"\nasync function verify(opts: { code: string | null; redirect: string | null }) {\n  setLoading(true);\n  try {\n    const req = await fetch(\"/api/unkey\", {\n      method: \"POST\",\n      body: JSON.stringify(opts),\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n    });\n\n    if (!req.ok) {\n      throw new Error(`HTTP error! status: ${req.status}`);\n    }\n\n    const res = await req.json();\n\n    try {\n      const redirectUrl = new URL(res.redirect);\n      redirectUrl.searchParams.append(\"code\", res.code);\n      redirectUrl.searchParams.append(\"key\", res.key);\n\n      await fetch(redirectUrl.toString());\n\n      setLoading(false);\n      setSuccess(true);\n    } catch (_error) {\n      console.error(_error);\n      setLoading(false);\n      toast.error(\"Error redirecting back to local CLI. Is your CLI running?\");\n    }\n  } catch (_error) {\n    setLoading(false);\n    toast.error(\"Error creating Unkey API key.\");\n  }\n}\n```\n\nThe `/api/unkey` endpoint will generate a new API key, which is associated with the user's account. Below is the code for the endpoint.\n\n```typescript title=\"/web/app/api/unkey/route.ts\"\nimport { Unkey } from \"@unkey/api\";\nimport { NextResponse } from \"next/server\";\n\nexport async function POST(request: Request) {\n  const { id, redirect, code } = await request.json();\n  if (!process.env.UNKEY_ROOT_KEY || !process.env.UNKEY_API_ID) {\n    return NextResponse.json({\n      statusCode: 500,\n      message: \"Unkey root key and API ID must be provided.\",\n    });\n  }\n  const unkey = new Unkey({ rootKey: process.env.UNKEY_ROOT_KEY });\n\n  const { result, error } = await unkey.keys.create({\n    apiId: process.env.UNKEY_API_ID,\n    prefix: \"cli_demo\",\n    ownerId: id,\n  });\n\n  if (error) {\n    return NextResponse.json({\n      statusCode: 500,\n      message: \"Error creating key  please ensure apiId is valid.\",\n    });\n  }\n\n  return NextResponse.json({ ...result, code, redirect });\n}\n```\n\nAs you can see, we are using Unkey's owner to associate the end user with the new API key, which makes it easy to find and revoke the key if needed.\n\n## Conclusion\n\nYou can dive deeper into the CLI demo code in our [GitHub repository](https://github.com/unkeyed/examples/tree/main/unkey-cli) and see how the CLI and web application work together to authenticate a user and generate a new API key. The CLI and web application are simple examples of how to authenticate a user and generate a new API key using Unkey. You can use the same principles to create your CLI with minimal effort.",
    "title": "Decoding CLI Authentication",
    "description": "Command Line Interfaces (CLI) have become integral tools for developers looking to streamline their workflow, but how does it actually work?",
    "author": "james",
    "date": "2024-02-07",
    "tags": [
      "tutorials"
    ],
    "image": "/images/blog-images/covers/cli-auth.png",
    "_meta": {
      "filePath": "cli-auth.mdx",
      "fileName": "cli-auth.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "cli-auth"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var a=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var w=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var g=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),f=(t,e)=>{for(var r in e)a(t,r,{get:e[r],enumerable:!0})},s=(t,e,r,i)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let o of w(e))!y.call(t,o)&&o!==r&&a(t,o,{get:()=>e[o],enumerable:!(i=p(e,o))||i.enumerable});return t};var k=(t,e,r)=>(r=t!=null?u(m(t)):{},s(e||!t||!t.__esModule?a(r,\"default\",{value:t,enumerable:!0}):r,t)),I=t=>s(a({},\"__esModule\",{value:!0}),t);var h=g((L,c)=>{c.exports=_jsx_runtime});var C={};f(C,{default:()=>d});var n=k(h());function l(t){let e={a:\"a\",blockquote:\"blockquote\",code:\"code\",h2:\"h2\",h4:\"h4\",p:\"p\",pre:\"pre\",...t.components},{Image:r}=e;return r||b(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"Command Line Interfaces (CLI) have become integral tools for developers looking to streamline their workflow. Some of the biggest names in tech, including Vercel, GitHub, Netlify, and Planetscale, offer CLIs that provide a powerful way to interact with their services.\"}),`\n`,(0,n.jsx)(e.p,{children:\"The question then comes up: How does CLI authentication work? How does a developer link this separate service with their authentication provider of choice? Let's delve into the world of CLI auth.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Suppose you are getting ready to authenticate with a CLI\\u2014you might use a command like \",(0,n.jsx)(e.code,{children:\"npx vercel login\"}),\". But what exactly happens under the hood?\"]}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsxs)(e.p,{children:[\"Check out the demo used in this blog post \",(0,n.jsx)(e.a,{href:\"https://unkey.com/templates/cli-auth\",children:\"here\"})]}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"cli-auth-overview\",children:\"CLI Auth Overview\"}),`\n`,(0,n.jsx)(e.p,{children:\"Before we look at any code, let us look at a diagram that explains the process.\"}),`\n`,(0,n.jsx)(r,{src:\"/images/blog-images/cli-auth/cli-auth-overview.png\",alt:\"CLI AUTH\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The process begins when a user invokes the CLI, which starts a server on a free port that listens for an incoming request. This will also result in the user's web browser opening up to a specific URL for CLI authentication, let's say \",(0,n.jsx)(e.code,{children:\"unkey.com/cli-auth\"}),\", and it will include a unique code that the user will need to confirm the authentication process.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Once the web application has launched, the user is prompted to log in using their authentication method of choice. This could be a username, password, social login, or two-factor authentication (2FA) method. After the user has successfully authenticated, the web application will display a unique code that the CLI generated to the user. The user must then confirm the authentication process by entering the unique code into the web application.\"}),`\n`,(0,n.jsx)(e.p,{children:\"The web application will then generate a new API key or token and return it to the CLI. The CLI will then store the token securely on the user's machine and use it for future requests to the service. The user will then be shown a message that the authentication process was successful, and they can return to the CLI.\"}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsx)(e.p,{children:\"User ---> CLI ---> Auth Web Page ---> Auth Confirmation ---> Token Generation ---> CLI token storage\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"The token is now securely stored on the user's machine, and each future CLI request will use this token to authenticate with the service without the user needing to re-authenticate each time.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"from-terminal-to-api-key\",children:\"From Terminal to API Key\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"To better understand the process, let's walk through a real-world example. We'll use the \",(0,n.jsx)(e.code,{children:\"@unkey/cli-demo\"}),\" package, a simple CLI demonstrating the authentication process. The package is available on npm, and you can use it by running the following command:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`npx @unkey/cli-demo login\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Executing the command will create the local server and open a browser window that asks you to log in using Clerk. At the same time, the CLI will display a unique code that you will need to enter into the web application. Once you have entered the code, the web application will generate a new API key and send it back to the CLI. The CLI will then store the token securely on your machine and use it for future requests for a service.\"}),`\n`,(0,n.jsx)(e.p,{children:\"To see the file that was created, you can run the following command:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`ls -a ~/\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"You'll find \",(0,n.jsx)(e.code,{children:\".unkey\"}),\", which holds your API key.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"the-code-behind-the-demo\",children:\"The Code Behind the Demo\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"We can break down the code into the CLI and the web application. The CLI is a simple Node server that creates a file named \",(0,n.jsx)(e.code,{children:\".unkey\"}),\" and stores your freshly created API key. The web application is a simple Next app that interacts with Unkey to generate a new API key.\"]}),`\n`,(0,n.jsx)(e.h4,{id:\"cli-code\",children:\"CLI Code\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The CLI code has some boilerplate code that sets up a server and has a command named \",(0,n.jsx)(e.code,{children:\"login\"}),\" that will start the server and open a browser window to the web application. The server will listen for a request from the web application and store the API key in a file.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Below is a promise waiting to be resolved when the server is started. The promise will resolve when the user has confirmed the authentication process and the API key has been generated and returned from the web, or the user cancels the request.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`// set up HTTP server that waits for a request containing an API key\n// as the only query parameter\nconst authPromise = new Promise<ParsedUrlQuery>((resolve, reject) => {\n  server.on(\"request\", (req, res) => {\n    // Set CORS headers for all responses\n    res.setHeader(\"Access-Control-Allow-Origin\", \"*\");\n    res.setHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS\");\n    res.setHeader(\n      \"Access-Control-Allow-Headers\",\n      \"Content-Type, Authorization\",\n    );\n\n    if (req.method === \"OPTIONS\") {\n      res.writeHead(200);\n      res.end();\n    } else if (req.method === \"GET\") {\n      const parsedUrl = url.parse(req.url as string, true);\n      const queryParams = parsedUrl.query;\n      if (queryParams.cancelled) {\n        res.writeHead(200);\n        res.end();\n        reject(new UserCancellationError(\"Login process cancelled by user.\"));\n      } else {\n        res.writeHead(200);\n        res.end();\n        resolve(queryParams);\n      }\n    } else {\n      res.writeHead(405);\n      res.end();\n    }\n  });\n});\n`})}),`\n`,(0,n.jsx)(e.h4,{id:\"web-application-code\",children:\"Web Application Code\"}),`\n`,(0,n.jsx)(e.p,{children:\"The web application code is a Next.js application that uses Clerk to authenticate the user, generate a new API key, and send it back to the CLI. When the user successfully confirms the code in the web application, it will make a request to Unkey to generate a new API key associated with the user's account and send it back to the CLI.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Below is the verification function that is called when the user confirms the code in the web application. The function will request an endpoint called \",(0,n.jsx)(e.code,{children:\"/api/unkey\"}),\" to generate a new API key.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`async function verify(opts: { code: string | null; redirect: string | null }) {\n  setLoading(true);\n  try {\n    const req = await fetch(\"/api/unkey\", {\n      method: \"POST\",\n      body: JSON.stringify(opts),\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n    });\n\n    if (!req.ok) {\n      throw new Error(\\`HTTP error! status: \\${req.status}\\`);\n    }\n\n    const res = await req.json();\n\n    try {\n      const redirectUrl = new URL(res.redirect);\n      redirectUrl.searchParams.append(\"code\", res.code);\n      redirectUrl.searchParams.append(\"key\", res.key);\n\n      await fetch(redirectUrl.toString());\n\n      setLoading(false);\n      setSuccess(true);\n    } catch (_error) {\n      console.error(_error);\n      setLoading(false);\n      toast.error(\"Error redirecting back to local CLI. Is your CLI running?\");\n    }\n  } catch (_error) {\n    setLoading(false);\n    toast.error(\"Error creating Unkey API key.\");\n  }\n}\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"The \",(0,n.jsx)(e.code,{children:\"/api/unkey\"}),\" endpoint will generate a new API key, which is associated with the user's account. Below is the code for the endpoint.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { Unkey } from \"@unkey/api\";\nimport { NextResponse } from \"next/server\";\n\nexport async function POST(request: Request) {\n  const { id, redirect, code } = await request.json();\n  if (!process.env.UNKEY_ROOT_KEY || !process.env.UNKEY_API_ID) {\n    return NextResponse.json({\n      statusCode: 500,\n      message: \"Unkey root key and API ID must be provided.\",\n    });\n  }\n  const unkey = new Unkey({ rootKey: process.env.UNKEY_ROOT_KEY });\n\n  const { result, error } = await unkey.keys.create({\n    apiId: process.env.UNKEY_API_ID,\n    prefix: \"cli_demo\",\n    ownerId: id,\n  });\n\n  if (error) {\n    return NextResponse.json({\n      statusCode: 500,\n      message: \"Error creating key \\u2013 please ensure apiId is valid.\",\n    });\n  }\n\n  return NextResponse.json({ ...result, code, redirect });\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"As you can see, we are using Unkey's owner to associate the end user with the new API key, which makes it easy to find and revoke the key if needed.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"You can dive deeper into the CLI demo code in our \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/examples/tree/main/unkey-cli\",children:\"GitHub repository\"}),\" and see how the CLI and web application work together to authenticate a user and generate a new API key. The CLI and web application are simple examples of how to authenticate a user and generate a new API key using Unkey. You can use the same principles to create your CLI with minimal effort.\"]})]})}function d(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(l,{...t})}):l(t)}function b(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return I(C);})();\n;return Component;",
    "slug": "cli-auth",
    "url": "/blog/cli-auth",
    "tableOfContents": [
      {
        "level": 2,
        "text": "CLI Auth Overview",
        "slug": "cli-auth-overview"
      },
      {
        "level": 2,
        "text": "From Terminal to API Key",
        "slug": "from-terminal-to-api-key"
      },
      {
        "level": 2,
        "text": "The Code Behind the Demo",
        "slug": "the-code-behind-the-demo"
      },
      {
        "level": 4,
        "text": "CLI Code",
        "slug": "cli-code"
      },
      {
        "level": 4,
        "text": "Web Application Code",
        "slug": "web-application-code"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "We all know API endpoints aren't created equal; some are more expensive than others. They can be more expensive due to compute cycles, or they could be financially more expensive because you are using a different AI model. When selling access to an API based upon usage with endpoints that could be very expensive, you need to be able to charge credits based on what endpoint a user is requesting data from. Below is an example of two routes: a cheap route and a more expensive one.\n\n<Image src=\"/images/blog-images/api-costs/routes-cost.png\" alt=\"Overrides example\" width=\"1920\" height=\"1080\"/>\n\n## How to implement cost based API usage\n\nBelow is an oversimplified version of tracking usage based upon an API key this doesn't include:\n\n- API key creation\n- Setting the credit amount for a user\n- Safe way to look up an API key to get the usage base.\n\nHowever, the idea is the following:\n\n1. User requests one of the endpoints\n2. We retrieve the key from the header\n3. We get their remaining credits. If they have zero, we return an error\n4. We reduce the credit amount based on the endpoint used\n5. We update our Redis storage with the new value\n6. We finally return the data from our endpoint\n\n\n```typescript\nimport { serve } from '@hono/node-server'\nimport { Hono } from 'hono'\nimport { createClient } from 'redis'\nimport { createMiddleware } from 'hono/factory'\n\nconst app = new Hono()\n\n\nconst client = createClient();\n\nconst verifyKeyWithCost = (cost: number) => createMiddleware(async (c, next) => {\n  const key = c.req.header('X-API-Key');\n  if (!key) {\n    return c.json({ error: \"No API key provided\" }, 401);\n  }\n\n  const credits = await client.get(key);\n  if (credits === null) {\n    c.json({ error: \"Internal server error\" }, 500);\n  }\n\n  const remainingCredits = parseInt(credits) - cost;\n  if (remainingCredits < 0) {\n    c.json({ error: \"API key usage exceeded\" }, 429);\n  }\n\n  await client.set(key, remainingCredits.toString());\n  await next();\n});\n\n// Cheap endpoint (costs 1 credit)\napp.get('/cheap-endpoint', verifyKeyWithCost(1), (c) => {\n  return c.json({\n    message: \"Accessed cheap endpoint\",\n    cost: 1,\n  });\n});\n\n// Expensive endpoint (costs 5 credits)\napp.get('/expensive-endpoint', verifyKeyWithCost(5), (c) => {\n  return c.json({\n    message: \"Accessed expensive endpoint\",\n    cost: 5,\n  });\n});\n\nserve(app)\n\n```\n\nThere are a lot of issues we need to consider with the implementation above:\n\n- What happens if a user makes multiple requests? How can we ensure accuracy and speed?\n- We don't have rate-limiting requests, so we need to implement them to ensure there isn't an abuse vector.\n- What happens if a user gets a new key? How do we ensure everything is accurate?\n\n## How to simplify your implementation using Unkey\n\nUnkey is an open-source API developer platform that allows developers to simplify the implementation of scalable and secure APIs.\n\nWith Unkey, with just a few lines of code, you can protect your API; the key holds all the information, so there isn't a requirement to look at another system to find this information. API keys can be created programmatically or through our dashboard.\n\n```typescript\nconst { result, error } = await verifyKey({\n  key,\n  remaining: {\n    cost,\n  },\n  apiId: \"API_ID_FROM_UNKEY\",\n});\n```\n\nBelow, we took the above implementation and removed the need for:\n\n- Implementing API key creation (Our example doesn't show this)\n- Setting the credit amount for a user (Our example doesn't show this)\n- Safe way to look up an API key to get the usage base\n- Redis\n\n```typescript\nimport { Hono } from \"hono\";\nimport { serve } from '@hono/node-server'\nimport { createMiddleware } from \"hono/factory\";\nimport { verifyKey } from \"@unkey/api\";\n\nconst app = new Hono();\n\ntype UnkeyResult = Awaited<ReturnType<typeof verifyKey>>[\"result\"];\n\ndeclare module \"hono\" {\n  interface ContextVariableMap {\n    unkey: UnkeyResult;\n  }\n}\n\n// Middleware to verify API key with specified cost\nconst verifyKeyWithCost = (cost: number) => createMiddleware(async (c, next) => {\n  const key = c.req.header(\"X-API-Key\");\n  if (!key) {\n    return c.json({ error: \"No API key provided\" }, 401);\n  }\n\n  const { result, error } = await verifyKey({\n    key,\n    remaining: {\n      cost,\n    },\n    apiId: \"API_ID_FROM_UNKEY\",\n  });\n\n  /**\n  * Handle Unkey Errors\n  * We have others but not important for this example\n  */\n  if (error) {\n    switch (error.code) {\n      case \"TOO_MANY_REQUESTS\":\n        return c.json({ error: \"Rate limit exceeded\" }, 429);\n      case \"BAD_REQUEST\":\n        return c.json({ error: \"Bad request\" }, 400);\n      case \"INTERNAL_SERVER_ERROR\":\n        return c.json({ error: \"Internal server error\" }, 500);\n      default:\n        return c.json({ error: \"Internal server error\" }, 500);\n    }\n  }\n  /** Handle Unkey Result if it's not valid such as\n  * Ratelimited, disabled, expired or no remaining credits\n  * There are other errors but they're not needed for this example\n  **/\n  if (!result.valid) {\n    switch (result.code) {\n      case \"DISABLED\":\n        return c.json({ error: \"API key is disabled\" }, 401);\n      case \"USAGE_EXCEEDED\":\n        return c.json({ error: \"API key usage exceeded\" }, 429);\n      case \"NOT_FOUND\":\n        return c.json({ error: \"API key not found\" }, 404);\n      default:\n        return c.json({ error: \"Internal server error\" }, 500);\n    }\n  }\n  /** Add verification result to context for this example to show how Unkey works\n  * This can also be used in a route handler for additional business logic\n  **/\n  c.set(\"unkey\", result);\n  await next();\n});\n\n// Cheap endpoint - costs 1 credit\napp.get(\"/cheap-endpoint\", verifyKeyWithCost(1), (c) => {\n  return c.json({\n    message: \"Accessed cheap endpoint\",\n    cost: 1,\n    verificationResult: c.get(\"unkey\")\n  });\n});\n\n// Expensive endpoint - costs 5 credits\napp.get(\"/expensive-endpoint\", verifyKeyWithCost(5), (c) => {\n  return c.json({\n    message: \"Accessed expensive endpoint\",\n    cost: 5,\n    verificationResult: c.get(\"unkey\")\n  });\n});\n\nserve(app)\n```\n\nAs you can see we really simplified the code and removed additional lookups via databases, allowing your API to be performant and scalable. You can get started for [free today](https://app.unkey.com)!",
    "title": "Implementing Variable API Route Costs with Unkey",
    "description": "Learn how to efficiently implement variable costs for API routes using Unkey, an open-source API developer platform.",
    "author": "james",
    "date": "2025-01-22",
    "tags": [
      "tutorial"
    ],
    "image": "/images/blog-images/covers/cost-og-image.png",
    "_meta": {
      "filePath": "cost-per-api-route.mdx",
      "fileName": "cost-per-api-route.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "cost-per-api-route"
    },
    "mdx": "var Component=(()=>{var p=Object.create;var i=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var g=(r,e)=>()=>(e||r((e={exports:{}}).exports,e),e.exports),v=(r,e)=>{for(var t in e)i(r,t,{get:e[t],enumerable:!0})},a=(r,e,t,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let o of m(e))!f.call(r,o)&&o!==t&&i(r,o,{get:()=>e[o],enumerable:!(s=u(e,o))||s.enumerable});return r};var w=(r,e,t)=>(t=r!=null?p(y(r)):{},a(e||!r||!r.__esModule?i(t,\"default\",{value:r,enumerable:!0}):t,r)),k=r=>a(i({},\"__esModule\",{value:!0}),r);var d=g((b,c)=>{c.exports=_jsx_runtime});var x={};v(x,{default:()=>h});var n=w(d());function l(r){let e={a:\"a\",code:\"code\",h2:\"h2\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",ul:\"ul\",...r.components},{Image:t}=e;return t||I(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"We all know API endpoints aren't created equal; some are more expensive than others. They can be more expensive due to compute cycles, or they could be financially more expensive because you are using a different AI model. When selling access to an API based upon usage with endpoints that could be very expensive, you need to be able to charge credits based on what endpoint a user is requesting data from. Below is an example of two routes: a cheap route and a more expensive one.\"}),`\n`,(0,n.jsx)(t,{src:\"/images/blog-images/api-costs/routes-cost.png\",alt:\"Overrides example\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.h2,{id:\"how-to-implement-cost-based-api-usage\",children:\"How to implement cost based API usage\"}),`\n`,(0,n.jsx)(e.p,{children:\"Below is an oversimplified version of tracking usage based upon an API key this doesn't include:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"API key creation\"}),`\n`,(0,n.jsx)(e.li,{children:\"Setting the credit amount for a user\"}),`\n`,(0,n.jsx)(e.li,{children:\"Safe way to look up an API key to get the usage base.\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"However, the idea is the following:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:\"User requests one of the endpoints\"}),`\n`,(0,n.jsx)(e.li,{children:\"We retrieve the key from the header\"}),`\n`,(0,n.jsx)(e.li,{children:\"We get their remaining credits. If they have zero, we return an error\"}),`\n`,(0,n.jsx)(e.li,{children:\"We reduce the credit amount based on the endpoint used\"}),`\n`,(0,n.jsx)(e.li,{children:\"We update our Redis storage with the new value\"}),`\n`,(0,n.jsx)(e.li,{children:\"We finally return the data from our endpoint\"}),`\n`]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { serve } from '@hono/node-server'\nimport { Hono } from 'hono'\nimport { createClient } from 'redis'\nimport { createMiddleware } from 'hono/factory'\n\nconst app = new Hono()\n\n\nconst client = createClient();\n\nconst verifyKeyWithCost = (cost: number) => createMiddleware(async (c, next) => {\n  const key = c.req.header('X-API-Key');\n  if (!key) {\n    return c.json({ error: \"No API key provided\" }, 401);\n  }\n\n  const credits = await client.get(key);\n  if (credits === null) {\n    c.json({ error: \"Internal server error\" }, 500);\n  }\n\n  const remainingCredits = parseInt(credits) - cost;\n  if (remainingCredits < 0) {\n    c.json({ error: \"API key usage exceeded\" }, 429);\n  }\n\n  await client.set(key, remainingCredits.toString());\n  await next();\n});\n\n// Cheap endpoint (costs 1 credit)\napp.get('/cheap-endpoint', verifyKeyWithCost(1), (c) => {\n  return c.json({\n    message: \"Accessed cheap endpoint\",\n    cost: 1,\n  });\n});\n\n// Expensive endpoint (costs 5 credits)\napp.get('/expensive-endpoint', verifyKeyWithCost(5), (c) => {\n  return c.json({\n    message: \"Accessed expensive endpoint\",\n    cost: 5,\n  });\n});\n\nserve(app)\n\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"There are a lot of issues we need to consider with the implementation above:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"What happens if a user makes multiple requests? How can we ensure accuracy and speed?\"}),`\n`,(0,n.jsx)(e.li,{children:\"We don't have rate-limiting requests, so we need to implement them to ensure there isn't an abuse vector.\"}),`\n`,(0,n.jsx)(e.li,{children:\"What happens if a user gets a new key? How do we ensure everything is accurate?\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"how-to-simplify-your-implementation-using-unkey\",children:\"How to simplify your implementation using Unkey\"}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey is an open-source API developer platform that allows developers to simplify the implementation of scalable and secure APIs.\"}),`\n`,(0,n.jsx)(e.p,{children:\"With Unkey, with just a few lines of code, you can protect your API; the key holds all the information, so there isn't a requirement to look at another system to find this information. API keys can be created programmatically or through our dashboard.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const { result, error } = await verifyKey({\n  key,\n  remaining: {\n    cost,\n  },\n  apiId: \"API_ID_FROM_UNKEY\",\n});\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Below, we took the above implementation and removed the need for:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Implementing API key creation (Our example doesn't show this)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Setting the credit amount for a user (Our example doesn't show this)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Safe way to look up an API key to get the usage base\"}),`\n`,(0,n.jsx)(e.li,{children:\"Redis\"}),`\n`]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { Hono } from \"hono\";\nimport { serve } from '@hono/node-server'\nimport { createMiddleware } from \"hono/factory\";\nimport { verifyKey } from \"@unkey/api\";\n\nconst app = new Hono();\n\ntype UnkeyResult = Awaited<ReturnType<typeof verifyKey>>[\"result\"];\n\ndeclare module \"hono\" {\n  interface ContextVariableMap {\n    unkey: UnkeyResult;\n  }\n}\n\n// Middleware to verify API key with specified cost\nconst verifyKeyWithCost = (cost: number) => createMiddleware(async (c, next) => {\n  const key = c.req.header(\"X-API-Key\");\n  if (!key) {\n    return c.json({ error: \"No API key provided\" }, 401);\n  }\n\n  const { result, error } = await verifyKey({\n    key,\n    remaining: {\n      cost,\n    },\n    apiId: \"API_ID_FROM_UNKEY\",\n  });\n\n  /**\n  * Handle Unkey Errors\n  * We have others but not important for this example\n  */\n  if (error) {\n    switch (error.code) {\n      case \"TOO_MANY_REQUESTS\":\n        return c.json({ error: \"Rate limit exceeded\" }, 429);\n      case \"BAD_REQUEST\":\n        return c.json({ error: \"Bad request\" }, 400);\n      case \"INTERNAL_SERVER_ERROR\":\n        return c.json({ error: \"Internal server error\" }, 500);\n      default:\n        return c.json({ error: \"Internal server error\" }, 500);\n    }\n  }\n  /** Handle Unkey Result if it's not valid such as\n  * Ratelimited, disabled, expired or no remaining credits\n  * There are other errors but they're not needed for this example\n  **/\n  if (!result.valid) {\n    switch (result.code) {\n      case \"DISABLED\":\n        return c.json({ error: \"API key is disabled\" }, 401);\n      case \"USAGE_EXCEEDED\":\n        return c.json({ error: \"API key usage exceeded\" }, 429);\n      case \"NOT_FOUND\":\n        return c.json({ error: \"API key not found\" }, 404);\n      default:\n        return c.json({ error: \"Internal server error\" }, 500);\n    }\n  }\n  /** Add verification result to context for this example to show how Unkey works\n  * This can also be used in a route handler for additional business logic\n  **/\n  c.set(\"unkey\", result);\n  await next();\n});\n\n// Cheap endpoint - costs 1 credit\napp.get(\"/cheap-endpoint\", verifyKeyWithCost(1), (c) => {\n  return c.json({\n    message: \"Accessed cheap endpoint\",\n    cost: 1,\n    verificationResult: c.get(\"unkey\")\n  });\n});\n\n// Expensive endpoint - costs 5 credits\napp.get(\"/expensive-endpoint\", verifyKeyWithCost(5), (c) => {\n  return c.json({\n    message: \"Accessed expensive endpoint\",\n    cost: 5,\n    verificationResult: c.get(\"unkey\")\n  });\n});\n\nserve(app)\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"As you can see we really simplified the code and removed additional lookups via databases, allowing your API to be performant and scalable. You can get started for \",(0,n.jsx)(e.a,{href:\"https://app.unkey.com\",children:\"free today\"}),\"!\"]})]})}function h(r={}){let{wrapper:e}=r.components||{};return e?(0,n.jsx)(e,{...r,children:(0,n.jsx)(l,{...r})}):l(r)}function I(r,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+r+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return k(x);})();\n;return Component;",
    "slug": "cost-per-api-route",
    "url": "/blog/cost-per-api-route",
    "tableOfContents": [
      {
        "level": 2,
        "text": "How to implement cost based API usage",
        "slug": "how-to-implement-cost-based-api-usage"
      },
      {
        "level": 2,
        "text": "How to simplify your implementation using Unkey",
        "slug": "how-to-simplify-your-implementation-using-unkey"
      }
    ]
  },
  {
    "content": "## What Is an API Gateway?\n\nAn API Gateway is like a gatekeeper for your microservices. Think of it as a gatekeeper in a busy city, checking each visitor, ensuring they have the proper permissions, and guiding them to where they need to go. Similarly, an API Gateway is at the front of your microservices system, managing requests, ensuring security, and providing a single access point for users.\n\n## Why Do We Need an API Gateway?\n\n1. **Single Entry Point**: Instead of a client needing to have multiple routes to connect to a service, a gateway allows the client to make all calls to a single endpoint. The gateway takes care of routing to the appropriate service.\n2. **Authentication**: A Gateway takes care of authenticating access to the client, and to what services the client is allowed access to.\n3. **Load Balancing**: Sharing the load across multiple services prevents any single service from becoming overloaded, ensuring steady and continuous operation.\n4. **Logging and Monitoring**: Monitors the traffic, logging requests, overseeing performance, and promptly sending notifications of any irregularities.\n5. **Access**: The Gateway, crucial for managing incomming requests, inspects incoming requests and permits or denies these based on a predefined policy, maintaining server security.\n\n\n\n## Gateway Features\n\n\n<Image src=\"/images/blog-images/gateways/diagram.png\" alt=\"gateway diagram\" width=\"1920\" height=\"1080\"/>\n\n- **Routing**: The Gateway primary role is to determine which service is needed to manage and respond to the request. Routing incoming requests to where they need to go and sending the response back to the user.\n- **Authentication and Authorization**: Acting as a security checkpoint, the Gateway takes the tokens from users and validates them as needed. If the user's token is valid, the Gateway then checks what permissions are associated with that token. If the token does not match the permissions, the request is denied, ensuring that only authenticated users are allowed to proceed further into the system. If you have ever gone through an airport security checkpoint, this might sound familiar. If you do not have a first-class ticket, you are not getting into first class. Gateways can manage multiple authentication methods, which are normalized and then sent to the requested microservices.\n- **Request Transformation**: Considering the variety of programming languages used on the web, each with its own structure and syntax, Gateways play an integral role. They have the ability to transform user/client requests  into the language required by the service. This translation of client requests into a format understood by the services ensures smooth and efficient communication, regardless of the language used by the client. This capability enhances the overall performance of the system. This also allows for backwards compatibility, eliminating the need to modify other systems that might be challenging to change.\n- **Response Aggregation**: Gateways allow for accessing multiple services through a single API request. The user sends a request via the Gateway, the Gateway executes all the necessary calls required to retrieve the desired data from various services. This streamlined process not only makes the user's life simpler but also significantly reduces frustration, as it eliminates the need for them to make multiple API requests for different services. Instead, they can now access all the information they need through a single, efficient API request.\n- **Rate Limiting and Throttling**: In order to maintain a high level of service and prevent any potential overload, the Gateway can implement rate limiting and throttling. The Gateway enforces these measures to maintain service quality and prevent overuse. These limits ensure steady resource allocation, prevent excessive usage by any user or service, and guarantee consistent performance for all users.\n- **Analytics**: Gateways offer insight into API requests. They act as a single endpoint that provides valuable data for all microservices. This is particularly useful for pinpointing heavily used APIs that might need optimization due to poor latency. This is also crucial when contemplating the deprecation of an API and needing to evaluate its present usage.\n\n## Challenges and Considerations\n\n- **Security**: The Gateway must be security first. Any breach could compromise the entire system.\n- **Performance**: A slow Gateway means delayed responses. Optimize wisely.\n- **Service Discovery**: How does the Gateway determine the location of services? Through service registries or DNS mechanisms!\n\n## Conclusion\n\nIn summary, API Gateways play a significant role in the realm of microservices. They facilitate communication, enhance security, and boost performance. Serving as a single point of entry, they manage authentication, balance load, monitor traffic, and oversee resource sharing. They also have the ability to direct requests, modify requests, group responses, and limit excessive usage. This makes them an integral component of any efficient system. However, it's crucial to prioritize security and performance. For developers, understanding these gateways and continuously striving to improve and secure our APIs is essential.",
    "title": "Understanding API Gateways",
    "description": "A beginners guide to API Gateways",
    "author": "michael",
    "date": "2024-05-23",
    "tags": [
      "tutorials"
    ],
    "image": "/images/blog-images/covers/gatewayCover.png",
    "_meta": {
      "filePath": "exploring-api-gateways.mdx",
      "fileName": "exploring-api-gateways.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "exploring-api-gateways"
    },
    "mdx": "var Component=(()=>{var g=Object.create;var s=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,p=Object.prototype.hasOwnProperty;var f=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),v=(n,e)=>{for(var i in e)s(n,i,{get:e[i],enumerable:!0})},o=(n,e,i,r)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let a of m(e))!p.call(n,a)&&a!==i&&s(n,a,{get:()=>e[a],enumerable:!(r=u(e,a))||r.enumerable});return n};var w=(n,e,i)=>(i=n!=null?g(y(n)):{},o(e||!n||!n.__esModule?s(i,\"default\",{value:n,enumerable:!0}):i,n)),b=n=>o(s({},\"__esModule\",{value:!0}),n);var l=f((G,c)=>{c.exports=_jsx_runtime});var A={};v(A,{default:()=>d});var t=w(l());function h(n){let e={h2:\"h2\",li:\"li\",ol:\"ol\",p:\"p\",strong:\"strong\",ul:\"ul\",...n.components},{Image:i}=e;return i||k(\"Image\",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h2,{id:\"what-is-an-api-gateway\",children:\"What Is an API Gateway?\"}),`\n`,(0,t.jsx)(e.p,{children:\"An API Gateway is like a gatekeeper for your microservices. Think of it as a gatekeeper in a busy city, checking each visitor, ensuring they have the proper permissions, and guiding them to where they need to go. Similarly, an API Gateway is at the front of your microservices system, managing requests, ensuring security, and providing a single access point for users.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"why-do-we-need-an-api-gateway\",children:\"Why Do We Need an API Gateway?\"}),`\n`,(0,t.jsxs)(e.ol,{children:[`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Single Entry Point\"}),\": Instead of a client needing to have multiple routes to connect to a service, a gateway allows the client to make all calls to a single endpoint. The gateway takes care of routing to the appropriate service.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Authentication\"}),\": A Gateway takes care of authenticating access to the client, and to what services the client is allowed access to.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Load Balancing\"}),\": Sharing the load across multiple services prevents any single service from becoming overloaded, ensuring steady and continuous operation.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Logging and Monitoring\"}),\": Monitors the traffic, logging requests, overseeing performance, and promptly sending notifications of any irregularities.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Access\"}),\": The Gateway, crucial for managing incomming requests, inspects incoming requests and permits or denies these based on a predefined policy, maintaining server security.\"]}),`\n`]}),`\n`,(0,t.jsx)(e.h2,{id:\"gateway-features\",children:\"Gateway Features\"}),`\n`,(0,t.jsx)(i,{src:\"/images/blog-images/gateways/diagram.png\",alt:\"gateway diagram\",width:\"1920\",height:\"1080\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Routing\"}),\": The Gateway primary role is to determine which service is needed to manage and respond to the request. Routing incoming requests to where they need to go and sending the response back to the user.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Authentication and Authorization\"}),\": Acting as a security checkpoint, the Gateway takes the tokens from users and validates them as needed. If the user's token is valid, the Gateway then checks what permissions are associated with that token. If the token does not match the permissions, the request is denied, ensuring that only authenticated users are allowed to proceed further into the system. If you have ever gone through an airport security checkpoint, this might sound familiar. If you do not have a first-class ticket, you are not getting into first class. Gateways can manage multiple authentication methods, which are normalized and then sent to the requested microservices.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Request Transformation\"}),\": Considering the variety of programming languages used on the web, each with its own structure and syntax, Gateways play an integral role. They have the ability to transform user/client requests  into the language required by the service. This translation of client requests into a format understood by the services ensures smooth and efficient communication, regardless of the language used by the client. This capability enhances the overall performance of the system. This also allows for backwards compatibility, eliminating the need to modify other systems that might be challenging to change.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Response Aggregation\"}),\": Gateways allow for accessing multiple services through a single API request. The user sends a request via the Gateway, the Gateway executes all the necessary calls required to retrieve the desired data from various services. This streamlined process not only makes the user's life simpler but also significantly reduces frustration, as it eliminates the need for them to make multiple API requests for different services. Instead, they can now access all the information they need through a single, efficient API request.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Rate Limiting and Throttling\"}),\": In order to maintain a high level of service and prevent any potential overload, the Gateway can implement rate limiting and throttling. The Gateway enforces these measures to maintain service quality and prevent overuse. These limits ensure steady resource allocation, prevent excessive usage by any user or service, and guarantee consistent performance for all users.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Analytics\"}),\": Gateways offer insight into API requests. They act as a single endpoint that provides valuable data for all microservices. This is particularly useful for pinpointing heavily used APIs that might need optimization due to poor latency. This is also crucial when contemplating the deprecation of an API and needing to evaluate its present usage.\"]}),`\n`]}),`\n`,(0,t.jsx)(e.h2,{id:\"challenges-and-considerations\",children:\"Challenges and Considerations\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Security\"}),\": The Gateway must be security first. Any breach could compromise the entire system.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Performance\"}),\": A slow Gateway means delayed responses. Optimize wisely.\"]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Service Discovery\"}),\": How does the Gateway determine the location of services? Through service registries or DNS mechanisms!\"]}),`\n`]}),`\n`,(0,t.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,t.jsx)(e.p,{children:\"In summary, API Gateways play a significant role in the realm of microservices. They facilitate communication, enhance security, and boost performance. Serving as a single point of entry, they manage authentication, balance load, monitor traffic, and oversee resource sharing. They also have the ability to direct requests, modify requests, group responses, and limit excessive usage. This makes them an integral component of any efficient system. However, it's crucial to prioritize security and performance. For developers, understanding these gateways and continuously striving to improve and secure our APIs is essential.\"})]})}function d(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(h,{...n})}):h(n)}function k(n,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+n+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return b(A);})();\n;return Component;",
    "slug": "exploring-api-gateways",
    "url": "/blog/exploring-api-gateways",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Why Do We Need an API Gateway?",
        "slug": "why-do-we-need-an-api-gateway"
      },
      {
        "level": 2,
        "text": "Gateway Features",
        "slug": "gateway-features"
      },
      {
        "level": 2,
        "text": "Challenges and Considerations",
        "slug": "challenges-and-considerations"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "Serverless solved many issues and created many more. It's a great way to build applications that scale, but it can only scale as far as your other services can. For example, if you're using a serverless function to process data, and that data is coming from a database that can only handle 100 requests per second, then your serverless function is effectively capped at 100 requests per second as well.\n\nSo why do we use serverless if it's limited by servers? Well in our case, we use Cloudflare workers for our API for their global low latency. That's it, everything else we build around it, is just to make it work.\n\n\n## The problem\n\nOur API emits multiple different events, such as the outcome of a verification, or a rate-limit being hit. We use Tinybird for all of our analytics, and we were sending each event individually to Tinybird. This is easy on the worker's side because you just fire and forget.\n\n```typescript\nexecutionContext.waitUntil(tinybird.ingestKeyVerification({ ... }))\n```\n\n\nThe problem is that Tinybird has a 1k requests per second ingest limit, and we were hitting that limit regularly. The obvious solution is to batch the events and send them in a single request\n\nThat's where the rabbit hole started...\n\n### Batching in Cloudflare workers\n\nCloudflare workers are great, but they are not designed for batching. You can't just wait for a few seconds and then send a batch of events to Tinybird. You have to send the events as they come in, or you risk losing the event as the underlying worker can be recycled at any time after the execution ended.\n\nLet's look at the options I explored:\n\n- Cloudflare Queues, D1 or Durable Objects\n- Cloudflare Logpush\n- Cloudflare Analytics Engine\n- Clickhouse Cloud\n- Kafka\n- Tinybird Enterprise\n- VPS\n\n\n### Cloudflare Queues, D1 or Durable Objects\n\nI group these 3, cause they all solve the problem pretty well, but are just too expensive for our use case.\nHere's some napkin math to illustrate my point:\n\nWorker invocations are charged at $0,30 per million, there's also a charge for CPU time, so let's just say we're paying around 40 cents per million requests.\nCloudflare queues are $1.20 per million messages (assuming you don't need to retry), D1 and Durable Objects are similarly priced.\n\nEach worker invocation produces on average 2 events, but inside the worker, we can batch them and send a single message through the queue.\nSo for 1 million API requests, we'd be paying $0.40 for the worker invocations, and $1.20 for the queue, for a total of $1.60. Queues are just too expensive relative to the cost of the worker invocations.\n\nNow $1.60 per million requests doesn't sound like a lot, but we need to have good margins and then our customers would have to add more margin on top of that. We want to make building APIs more accessible to everyone, so we need to keep our costs low.\n\n### Cloudflare Logpush\n\nCloudflare Logpush is pretty nice for sending logs to your sink. The problem is that it's pretty slow, we're seeing around 2-3 min of delay between logging something and it appearing in our sink. This is not acceptable for our real-time analytics.\n\nThere are also some other limitations that make it hard to use:\n- **Message size**: Maximum of 2056 characters per log line *(That's not really that much data if you encode it in JSON)*\n- **Array limit**: 20 elements *(I still don't know what this refers to)*\n- **Log message array**: A nested array with a limit of three elements\n\n[Source](https://developers.cloudflare.com/workers/observability/logging/logpush/#limits)\n\nWe do use Logpush for other internal metrics to aggregate and send them to [Axiom.co](https://axiom.co), where the latency doesn't matter as much and we'd be fine to drop some events if we exceed some limits.\nLet us know if you'd like to see a blog post about that implementation.\n\n\n### Clickhouse Cloud\n\nI was surprised how good clickhouse cloud was, I expected an AWS-like experience but they made it pretty nice and easy to use. The problem for us is that it didn't work so well with thousands of small requests per second. Clickhouse really likes receiving large batches of 10k-100k rows in a single request, so it can optimize the writes to disk, and we need to do the opposite.\n[Source](https://clickhouse.com/docs/en/optimize/bulk-inserts)\n\n\n### Cloudflare Analytics Engine\n\nWhen I first heard about the Analytics Engine, I thought it was the solution to all of our problems. Clickhouse natively on Cloudflare sounds like a dream come true. The reality is far from that though.\nAt Cloudflare's scale both in terms of usage but also in terms of the number of different customer needs, it's hard to build a product that fits everyone. They made some harsh tradeoffs to make it work for everyone, and in doing that made it only work for a few. At least in its current state.\nI'm happy to look past the API design and just write a wrapper around it, but I was just bouncing from one undocumented problem to the next.\n\nAnyways, Analytics Engine would have been a pretty nice solution due to its pricing. It's $0.25 per million rows ingested and $1 per million queries (regardless of the number of rows returned). This is a pretty good deal, and my idea was to use it as a buffer. I'd ingest the events into the Analytics Engine and then run a `SELECT *` query every few seconds to get the events and send them to Tinybird. The problem with that is: how do I know which events I've already processed without having to keep track of every single row?\nI tried a few different approaches, but they all came down to the fact that there is no guarantee of how quickly Cloudflare commits rows to the Analytics Engine. It could take a few seconds, or even a minute, making it hard to build a reliable system to get the events out of it.\n\n### Kafka\n\nKafka would be pretty good for this use case, but sending many small messages to Kafka over HTTP is not really what it's designed for. We're back to the same problem of not being able to batch the events in the worker.\nI've heard from teams who run Cloudflare workers + Kafka in production right now, and they're not happy with the solution as they scale up. I have not done my own research on this but instead trusted their judgment.\n\n### Tinybird Enterprise\n\nPerhaps the most obvious solution would be to just ask Tinybird to raise the limit for us. So we did. They were very helpful and offered a custom solution, albeit at a price point that is not commercially viable for us yet. We don't need the full Tinybird enterprise experience, we just need a higher request limit. All other metrics are well within the current limits.\n\n## The solution\n\nIf we can't batch the events in a serverless function, then let's do it on a server instead. We've created a simple Go application that is api-compatible with Tinybird's `/v0/events` API. It accepts `NDJSON` events, buffers them, and then sends a batch to Tinybird in a single request.\nBecause it's compatible, we don't need to change anything in our worker code, we just use a different `TINYBIRD_URL` and `TINYBIRD_TOKEN` and we're good to go.\n\n\n<img src=\"/images/blog-images/tinybird-proxy/tinybird-proxy.png\"/>\n\n### Deployment\n\nWe chose to deploy this proxy on [Koyeb](https://koyeb.com) because it's super easy and they have autoscaling. I know others do too, but we were already familiar with Koyeb. We just push our code to GitHub, and Koyeb takes care of the rest.\n\nIf you want to run this yourself, just choose a VPS provider you're comfortable with, and run the docker container.\n\n### Quickstart\n\nAll you need is docker and your Tinybird token. You can run it like this:\n\n```bash\ndocker run -p 8000:8000 -e TINYBIRD_TOKEN=\"abc\" ghcr.io/unkeyed/tinybird-proxy:latest\n```\n\n\n### Config\n\nSee the [readme](https://github.com/unkeyed/unkey/tree/main/apps/agent#config) for all available options.\n\nBy default, the proxy will try to send batches of max 100k rows or every second, whichever happens first.\nThe buffer size is 1 million events,  to minimize data loss in case of a machine failure. If the buffer is full, the proxy will not accept more data until it's flushed.\n\n\n### Performance\n\nWe've tested this with over 8k RPS and it barely broke a sweat. We're currently running this on 1-4 autoscaling instances with 2 vCPUs and 2GB of RAM.\n\n\n## Conclusion\n\nUsing a proxy solved all of our problems:\n\n- Supports our current and expected load for the foreseeable future\n- Low latency for our real-time analytics\n- Cheap (less than $50 per month)\n- Easy to scale\n\nWe're still using serverless where it makes sense and Cloudflare workers play a critical role in ensuring our API is fast and reliable, but some of the supporting infrastructure can be run on servers for a fraction of the cost.",
    "title": "Fixing serverless with a $5 VPS",
    "description": "How we are supporting our serverless API with servers to scale beyond the limits of serverless.",
    "author": "andreas",
    "date": "2024-04-24",
    "tags": [
      "engineering"
    ],
    "image": "/images/blog-images/covers/fixing-serverless.png",
    "_meta": {
      "filePath": "fixing-serverless-with-a-vps.mdx",
      "fileName": "fixing-serverless-with-a-vps.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "fixing-serverless-with-a-vps"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var i=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var f=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var g=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),b=(n,e)=>{for(var r in e)i(n,r,{get:e[r],enumerable:!0})},a=(n,e,r,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let o of f(e))!y.call(n,o)&&o!==r&&i(n,o,{get:()=>e[o],enumerable:!(s=p(e,o))||s.enumerable});return n};var w=(n,e,r)=>(r=n!=null?u(m(n)):{},a(e||!n||!n.__esModule?i(r,\"default\",{value:n,enumerable:!0}):r,n)),k=n=>a(i({},\"__esModule\",{value:!0}),n);var d=g((I,l)=>{l.exports=_jsx_runtime});var v={};b(v,{default:()=>c});var t=w(d());function h(n){let e={a:\"a\",code:\"code\",em:\"em\",h2:\"h2\",h3:\"h3\",li:\"li\",p:\"p\",pre:\"pre\",strong:\"strong\",ul:\"ul\",...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.p,{children:\"Serverless solved many issues and created many more. It's a great way to build applications that scale, but it can only scale as far as your other services can. For example, if you're using a serverless function to process data, and that data is coming from a database that can only handle 100 requests per second, then your serverless function is effectively capped at 100 requests per second as well.\"}),`\n`,(0,t.jsx)(e.p,{children:\"So why do we use serverless if it's limited by servers? Well in our case, we use Cloudflare workers for our API for their global low latency. That's it, everything else we build around it, is just to make it work.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"the-problem\",children:\"The problem\"}),`\n`,(0,t.jsx)(e.p,{children:\"Our API emits multiple different events, such as the outcome of a verification, or a rate-limit being hit. We use Tinybird for all of our analytics, and we were sending each event individually to Tinybird. This is easy on the worker's side because you just fire and forget.\"}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-typescript\",children:`executionContext.waitUntil(tinybird.ingestKeyVerification({ ... }))\n`})}),`\n`,(0,t.jsx)(e.p,{children:\"The problem is that Tinybird has a 1k requests per second ingest limit, and we were hitting that limit regularly. The obvious solution is to batch the events and send them in a single request\"}),`\n`,(0,t.jsx)(e.p,{children:\"That's where the rabbit hole started...\"}),`\n`,(0,t.jsx)(e.h3,{id:\"batching-in-cloudflare-workers\",children:\"Batching in Cloudflare workers\"}),`\n`,(0,t.jsx)(e.p,{children:\"Cloudflare workers are great, but they are not designed for batching. You can't just wait for a few seconds and then send a batch of events to Tinybird. You have to send the events as they come in, or you risk losing the event as the underlying worker can be recycled at any time after the execution ended.\"}),`\n`,(0,t.jsx)(e.p,{children:\"Let's look at the options I explored:\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsx)(e.li,{children:\"Cloudflare Queues, D1 or Durable Objects\"}),`\n`,(0,t.jsx)(e.li,{children:\"Cloudflare Logpush\"}),`\n`,(0,t.jsx)(e.li,{children:\"Cloudflare Analytics Engine\"}),`\n`,(0,t.jsx)(e.li,{children:\"Clickhouse Cloud\"}),`\n`,(0,t.jsx)(e.li,{children:\"Kafka\"}),`\n`,(0,t.jsx)(e.li,{children:\"Tinybird Enterprise\"}),`\n`,(0,t.jsx)(e.li,{children:\"VPS\"}),`\n`]}),`\n`,(0,t.jsx)(e.h3,{id:\"cloudflare-queues-d1-or-durable-objects\",children:\"Cloudflare Queues, D1 or Durable Objects\"}),`\n`,(0,t.jsx)(e.p,{children:`I group these 3, cause they all solve the problem pretty well, but are just too expensive for our use case.\nHere's some napkin math to illustrate my point:`}),`\n`,(0,t.jsx)(e.p,{children:`Worker invocations are charged at $0,30 per million, there's also a charge for CPU time, so let's just say we're paying around 40 cents per million requests.\nCloudflare queues are $1.20 per million messages (assuming you don't need to retry), D1 and Durable Objects are similarly priced.`}),`\n`,(0,t.jsx)(e.p,{children:`Each worker invocation produces on average 2 events, but inside the worker, we can batch them and send a single message through the queue.\nSo for 1 million API requests, we'd be paying $0.40 for the worker invocations, and $1.20 for the queue, for a total of $1.60. Queues are just too expensive relative to the cost of the worker invocations.`}),`\n`,(0,t.jsx)(e.p,{children:\"Now $1.60 per million requests doesn't sound like a lot, but we need to have good margins and then our customers would have to add more margin on top of that. We want to make building APIs more accessible to everyone, so we need to keep our costs low.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"cloudflare-logpush\",children:\"Cloudflare Logpush\"}),`\n`,(0,t.jsx)(e.p,{children:\"Cloudflare Logpush is pretty nice for sending logs to your sink. The problem is that it's pretty slow, we're seeing around 2-3 min of delay between logging something and it appearing in our sink. This is not acceptable for our real-time analytics.\"}),`\n`,(0,t.jsx)(e.p,{children:\"There are also some other limitations that make it hard to use:\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Message size\"}),\": Maximum of 2056 characters per log line \",(0,t.jsx)(e.em,{children:\"(That's not really that much data if you encode it in JSON)\"})]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Array limit\"}),\": 20 elements \",(0,t.jsx)(e.em,{children:\"(I still don't know what this refers to)\"})]}),`\n`,(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:\"Log message array\"}),\": A nested array with a limit of three elements\"]}),`\n`]}),`\n`,(0,t.jsx)(e.p,{children:(0,t.jsx)(e.a,{href:\"https://developers.cloudflare.com/workers/observability/logging/logpush/#limits\",children:\"Source\"})}),`\n`,(0,t.jsxs)(e.p,{children:[\"We do use Logpush for other internal metrics to aggregate and send them to \",(0,t.jsx)(e.a,{href:\"https://axiom.co\",children:\"Axiom.co\"}),`, where the latency doesn't matter as much and we'd be fine to drop some events if we exceed some limits.\nLet us know if you'd like to see a blog post about that implementation.`]}),`\n`,(0,t.jsx)(e.h3,{id:\"clickhouse-cloud\",children:\"Clickhouse Cloud\"}),`\n`,(0,t.jsxs)(e.p,{children:[`I was surprised how good clickhouse cloud was, I expected an AWS-like experience but they made it pretty nice and easy to use. The problem for us is that it didn't work so well with thousands of small requests per second. Clickhouse really likes receiving large batches of 10k-100k rows in a single request, so it can optimize the writes to disk, and we need to do the opposite.\n`,(0,t.jsx)(e.a,{href:\"https://clickhouse.com/docs/en/optimize/bulk-inserts\",children:\"Source\"})]}),`\n`,(0,t.jsx)(e.h3,{id:\"cloudflare-analytics-engine\",children:\"Cloudflare Analytics Engine\"}),`\n`,(0,t.jsx)(e.p,{children:`When I first heard about the Analytics Engine, I thought it was the solution to all of our problems. Clickhouse natively on Cloudflare sounds like a dream come true. The reality is far from that though.\nAt Cloudflare's scale both in terms of usage but also in terms of the number of different customer needs, it's hard to build a product that fits everyone. They made some harsh tradeoffs to make it work for everyone, and in doing that made it only work for a few. At least in its current state.\nI'm happy to look past the API design and just write a wrapper around it, but I was just bouncing from one undocumented problem to the next.`}),`\n`,(0,t.jsxs)(e.p,{children:[\"Anyways, Analytics Engine would have been a pretty nice solution due to its pricing. It's $0.25 per million rows ingested and $1 per million queries (regardless of the number of rows returned). This is a pretty good deal, and my idea was to use it as a buffer. I'd ingest the events into the Analytics Engine and then run a \",(0,t.jsx)(e.code,{children:\"SELECT *\"}),` query every few seconds to get the events and send them to Tinybird. The problem with that is: how do I know which events I've already processed without having to keep track of every single row?\nI tried a few different approaches, but they all came down to the fact that there is no guarantee of how quickly Cloudflare commits rows to the Analytics Engine. It could take a few seconds, or even a minute, making it hard to build a reliable system to get the events out of it.`]}),`\n`,(0,t.jsx)(e.h3,{id:\"kafka\",children:\"Kafka\"}),`\n`,(0,t.jsx)(e.p,{children:`Kafka would be pretty good for this use case, but sending many small messages to Kafka over HTTP is not really what it's designed for. We're back to the same problem of not being able to batch the events in the worker.\nI've heard from teams who run Cloudflare workers + Kafka in production right now, and they're not happy with the solution as they scale up. I have not done my own research on this but instead trusted their judgment.`}),`\n`,(0,t.jsx)(e.h3,{id:\"tinybird-enterprise\",children:\"Tinybird Enterprise\"}),`\n`,(0,t.jsx)(e.p,{children:\"Perhaps the most obvious solution would be to just ask Tinybird to raise the limit for us. So we did. They were very helpful and offered a custom solution, albeit at a price point that is not commercially viable for us yet. We don't need the full Tinybird enterprise experience, we just need a higher request limit. All other metrics are well within the current limits.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"the-solution\",children:\"The solution\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"If we can't batch the events in a serverless function, then let's do it on a server instead. We've created a simple Go application that is api-compatible with Tinybird's \",(0,t.jsx)(e.code,{children:\"/v0/events\"}),\" API. It accepts \",(0,t.jsx)(e.code,{children:\"NDJSON\"}),` events, buffers them, and then sends a batch to Tinybird in a single request.\nBecause it's compatible, we don't need to change anything in our worker code, we just use a different `,(0,t.jsx)(e.code,{children:\"TINYBIRD_URL\"}),\" and \",(0,t.jsx)(e.code,{children:\"TINYBIRD_TOKEN\"}),\" and we're good to go.\"]}),`\n`,(0,t.jsx)(\"img\",{src:\"/images/blog-images/tinybird-proxy/tinybird-proxy.png\"}),`\n`,(0,t.jsx)(e.h3,{id:\"deployment\",children:\"Deployment\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"We chose to deploy this proxy on \",(0,t.jsx)(e.a,{href:\"https://koyeb.com\",children:\"Koyeb\"}),\" because it's super easy and they have autoscaling. I know others do too, but we were already familiar with Koyeb. We just push our code to GitHub, and Koyeb takes care of the rest.\"]}),`\n`,(0,t.jsx)(e.p,{children:\"If you want to run this yourself, just choose a VPS provider you're comfortable with, and run the docker container.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"quickstart\",children:\"Quickstart\"}),`\n`,(0,t.jsx)(e.p,{children:\"All you need is docker and your Tinybird token. You can run it like this:\"}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-bash\",children:`docker run -p 8000:8000 -e TINYBIRD_TOKEN=\"abc\" ghcr.io/unkeyed/tinybird-proxy:latest\n`})}),`\n`,(0,t.jsx)(e.h3,{id:\"config\",children:\"Config\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"See the \",(0,t.jsx)(e.a,{href:\"https://github.com/unkeyed/unkey/tree/main/apps/agent#config\",children:\"readme\"}),\" for all available options.\"]}),`\n`,(0,t.jsx)(e.p,{children:`By default, the proxy will try to send batches of max 100k rows or every second, whichever happens first.\nThe buffer size is 1 million events,  to minimize data loss in case of a machine failure. If the buffer is full, the proxy will not accept more data until it's flushed.`}),`\n`,(0,t.jsx)(e.h3,{id:\"performance\",children:\"Performance\"}),`\n`,(0,t.jsx)(e.p,{children:\"We've tested this with over 8k RPS and it barely broke a sweat. We're currently running this on 1-4 autoscaling instances with 2 vCPUs and 2GB of RAM.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,t.jsx)(e.p,{children:\"Using a proxy solved all of our problems:\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsx)(e.li,{children:\"Supports our current and expected load for the foreseeable future\"}),`\n`,(0,t.jsx)(e.li,{children:\"Low latency for our real-time analytics\"}),`\n`,(0,t.jsx)(e.li,{children:\"Cheap (less than $50 per month)\"}),`\n`,(0,t.jsx)(e.li,{children:\"Easy to scale\"}),`\n`]}),`\n`,(0,t.jsx)(e.p,{children:\"We're still using serverless where it makes sense and Cloudflare workers play a critical role in ensuring our API is fast and reliable, but some of the supporting infrastructure can be run on servers for a fraction of the cost.\"})]})}function c(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(h,{...n})}):h(n)}return k(v);})();\n;return Component;",
    "slug": "fixing-serverless-with-a-vps",
    "url": "/blog/fixing-serverless-with-a-vps",
    "tableOfContents": [
      {
        "level": 2,
        "text": "The problem",
        "slug": "the-problem"
      },
      {
        "level": 3,
        "text": "Batching in Cloudflare workers",
        "slug": "batching-in-cloudflare-workers"
      },
      {
        "level": 3,
        "text": "Cloudflare Queues, D1 or Durable Objects",
        "slug": "cloudflare-queues-d1-or-durable-objects"
      },
      {
        "level": 3,
        "text": "Cloudflare Logpush",
        "slug": "cloudflare-logpush"
      },
      {
        "level": 3,
        "text": "Clickhouse Cloud",
        "slug": "clickhouse-cloud"
      },
      {
        "level": 3,
        "text": "Cloudflare Analytics Engine",
        "slug": "cloudflare-analytics-engine"
      },
      {
        "level": 3,
        "text": "Kafka",
        "slug": "kafka"
      },
      {
        "level": 3,
        "text": "Tinybird Enterprise",
        "slug": "tinybird-enterprise"
      },
      {
        "level": 2,
        "text": "The solution",
        "slug": "the-solution"
      },
      {
        "level": 3,
        "text": "Deployment",
        "slug": "deployment"
      },
      {
        "level": 3,
        "text": "Quickstart",
        "slug": "quickstart"
      },
      {
        "level": 3,
        "text": "Config",
        "slug": "config"
      },
      {
        "level": 3,
        "text": "Performance",
        "slug": "performance"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "Usage billing is nothing new anymore. A lot of developers don't want to spend a large fixed amount\nof money each month regardless of what they actually use. Especially when building out new unproven projects, it's essential to meet the developer where they are at: **zero users**\n\nAs long as your customer is too small to generate revenue, they don't want to pay for your service and that's okay. \nGenerous free tiers are a good solution to attract users, but even after they upgrade, you shouldn't send them an enormous bill for resources they're not even using. Pricing that scales with usage is preferrable for many, but not all, products.\n\nSome companies have different billing tiers, where you'd pay for example: $10 for 10k, $20 for 30k, $50 for 100k. The issue with that is paying the next higher tier just because you have exceeded the previous tier by a small margin, ie: paying $50 for 31k.\nThis system is very easy to implement, but at Unkey we do prorated usaged based billing, which means you pay for your exact usage, not whatever billing tier your usage fits in.\n\n\n## Challenges\n\n### Tracking usage\n\nBefore charging your customers, you obviously need to know how much and what they used. Tracking this data is the easy part, but where do you store it?\nIf you only produce \\<100/s billing events and use Stripe, then you could just use subscriptions and update the usage through their API directly. Depending on what you charge for, this can be enough for a long long time. Other billing providers might have similar systems and higher limits, but they probably have a limit too, so we needed to look elsewhere.\n\nIf we can't directly ingest the usage to our billing provider, we need to store it somewhere first and there are a lot of options, depending on your requirements.\n\n- **Redis:**\nIf you just need to count usage per month, redis would be a great way and can be as simple a using `INCR {user}:{year}:{month}`\n- **Your database:**\nI don't know how far you can scale increments in your database of choice, but it might get you far enough.\n- **Time series database:**\nIf you care about more than just the total value, a database optimized for storing time series would be ideal. \nThere are a ton available for many platforms, or you can selfhost them.\n- **Dedicated usage-billing SaaS:**\nThese days there are even some SaaS, that focus on this problem specifically and allow you to ingest usage records at any rate.\n\n### Sending usage to our billing provider\n\nInitially we were using Stripe subscriptions and updating usage in Stripe every hour for every workspace.\nThis worked pretty well and Stripe takes care of a lot of things, such as proration when subscriptions change.\nHowever we also ran into a few issues because Stripe's `billing_anchor` would not line up perfectly with our own data aggregations, resulting in some missed usage records.\n\nThis could be fixed in theory and Stripe subscriptions are great overall, but we decided to build a more agnostic system, in case we ever want to move off of stripe.\n\n## Using Tinybird for analytics\n\nWe are building all of our analytics and metrics on top of [Tinybird](https://tinybird.co), a modern real-time data platform, so we reused the existing data to power our billing.\nEvery event is ingested into Tinybird and we can run aggregations against that data later or in real time.\n\nA vertification event at Unkey looks like this, I'll omit unnecessary fields:\n```json title=\"Verification Event\"\n{\n    /**\n    * The workspace that gets billed later\n    */\n    \"workspaceId\": \"ws_123\",\n\n    /**\n    * A unique identifier for the key being verified\n    */\n    \"keyId\": \"key_123\",\n\n    /**\n    * When the verification happened\n    */\n    \"time\": 1709119218743,\n\n    /**\n    * If the verification was denied, we log the reason why\n    * when a key is denied for any reason, we will not charge the customer\n    */\n    \"deniedReason\": null | \"RATE_LIMITED\" | \"USAGE_EXCEEDED\"\n    \n    ... more\n}\n```\n\nDuring operation, whenever a key is getting verified, we emit one of these events straight to Tinybird.\nThese events are used throughout our dashboard to power analytics charts, and we also make it available to our customers, to build their own dashboards or charge their users.\n\n## Implementation details\n\nFor billing we'll look at extracting two different values for a specific timeframe:\n1. **Total usage:**  How many events per workspace?\n2. **Distinct usage:**  How many distinct ids in all the events?\nThis is quite common in the auth space where you charge for \"unique active users\" but is not limited to authentication.\nI've seen some SaaS move from traditional seat-based pricing to active-seat-based, where they only charge you if a user was actually active, rather than just having access.\n\n\n### Total successful verifications\n\n<Image src=\"/images/blog-images/usage-based-billing/monthly_verifications.png\" alt=\"monthly verifications pipes\" width=\"1920\" height=\"1080\"/>\n\nTo figure out the total usage per workspace, per month, we can simply query the original datasource and write the aggregated data to a materilized view:\nWe filter out all verifications that were denied and then count all verifications per workspace and per month. \n\n```sql title=\"aggregate_verifications_monthly.pipe\"\nSELECT\n    workspaceId,\n    apiId,\n    keyId,\n    countState(*) AS total,\n    toStartOfMonth(fromUnixTimestamp64Milli(time)) AS time\nFROM key_verifications__v2\nWHERE deniedReason IS NULL\nGROUP BY\n    workspaceId,\n    apiId,\n    keyId,\n    time\n    ```\n\n\nThen we can write a second pipe that reads data from the materialized view. The beauty of Tinybird is that they expose an HTTP endpoint for you to query this pipe.\nYou can even define query parameters like this: `{{ String(workspaceId, required=True) }}` \n\n```sql title=\"endpoint_verifications_by_workspace.pipe\"\nSELECT\n    countMerge(total) as total\nFROM mv__monthly_verifications__v2\nWHERE\n    workspaceId = {{ String(workspaceId, required=True) }}\n    AND time = makeDate({{ Int64(year) }}, {{ Int64(month) }}, 1)\nGROUP BY time\n```\n\nWe can now query this endpoint like this:\n```bash\ncurl .../endpoint?workspaceId=ws_123&year=2024&month=2\n```\nAnd we will get back the total number of successful verifications for workspace `ws_123` in february 2024.\n\n### Active keys\n\n<Image src=\"/images/blog-images/usage-based-billing/monthly_active_keys.png\" alt=\"monthly active keys pipes\" width=\"1920\" height=\"1080\"/>\n\n\nAgain we create an intermediate materialized view first. We could've reused the previous one, but it's nice to have them separated in case we want to change things later.\nThis results in a materialized view, where there's at most one row per keyId and month, making it super cheap to query later.\n\n```sql title=\"aggregate_active_keys_monthly_by_workspace_id.pipe\"\nSELECT\n    workspaceId,\n    apiId,\n    keyId,\n    toStartOfMonth(fromUnixTimestamp64Milli(time)) AS time\nFROM key_verifications__v2\nGROUP BY\n    workspaceId,\n    apiId,\n    keyId,\n    time\n```\n\nThe query uses `count(DISTINCT keyId)` to return how many unique keyIds have been observed in the given month.\n\n```sql title=\"endpoint__active_keys_by_workspace_id.pipe\"\nSELECT count(DISTINCT keyId) as keys\nFROM mv__monthly_active_keys__v1\nWHERE\n    workspaceId = {{ String(workspaceId, required=True) }}\n    AND time = makeDate({{ Int64(year) }}, {{ Int64(month) }}, 1)\nGROUP BY time\n```\n\nWhen querying the endpoint, we'll get back how many keys had at least 1 verification in a specific workspace and month.\n\n### Invoicing\n\nNow that we know how to find out what to charge, let's figure out how to charge our customers.\nWe're still using Stripe to create the invoice and [trigger.dev](https://trigger.dev) for durable workflow execution.\nOnce a month, a workflow starts to load all billable workspaces, load their usage and create an invoice.\n\nWe simply store a `stripeCustomerId` and `subscription`column in our database and can query all workspaces easily:\n\n```typescript title=\"query billable workspaces\"\nconst workspaces = await io.runTask(\"list workspaces\", async () =>\n    db.query.workspaces.findMany({\n    where: (table, { isNotNull, isNull, not, eq, and }) =>\n        and(\n            isNotNull(table.stripeCustomerId),\n            isNotNull(table.subscriptions),\n            not(eq(table.plan, \"free\")),\n            isNull(table.deletedAtM),\n        ),\n    }),\n);\n```\n\nAfterwards we fetch the usage for both keys and verifications and finalize the invoice. The code is all open source, if you're interested: [create-invoice.ts](https://github.com/unkeyed/unkey/blob/main/apps/workflows/jobs/create-invoice.ts)\n\n## Results\n\nDoing invoicing ourselves made it easier to customize its behaviour. That being said, it definitely took longer to implement than sitting down and fixing subscription timing issues properly. \nEspecially prorations are pretty annoying to handle.\n\nWe're still happy with the result, as it allows us to edit and tweak things as we go, whereas Stripe makes a ton of options non-editable. We can also switch providers at any time as we own the entire billing flow.",
    "title": "High frequency real-time usage based billing",
    "description": "Building a real-time billing pipeline for millions of daily events",
    "author": "andreas",
    "date": "2024-03-01",
    "tags": [
      "engineering"
    ],
    "image": "/images/blog-images/covers/usage-based-billing.png",
    "_meta": {
      "filePath": "high-frequency-usage-billing.mdx",
      "fileName": "high-frequency-usage-billing.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "high-frequency-usage-billing"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var r=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var w=(i,e)=>()=>(e||i((e={exports:{}}).exports,e),e.exports),f=(i,e)=>{for(var t in e)r(i,t,{get:e[t],enumerable:!0})},s=(i,e,t,o)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let a of p(e))!y.call(i,a)&&a!==t&&r(i,a,{get:()=>e[a],enumerable:!(o=g(e,a))||o.enumerable});return i};var b=(i,e,t)=>(t=i!=null?u(m(i)):{},s(e||!i||!i.__esModule?r(t,\"default\",{value:i,enumerable:!0}):t,i)),v=i=>s(r({},\"__esModule\",{value:!0}),i);var d=w((_,l)=>{l.exports=_jsx_runtime});var I={};f(I,{default:()=>h});var n=b(d());function c(i){let e={a:\"a\",code:\"code\",h2:\"h2\",h3:\"h3\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",strong:\"strong\",ul:\"ul\",...i.components},{Image:t}=e;return t||k(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[`Usage billing is nothing new anymore. A lot of developers don't want to spend a large fixed amount\nof money each month regardless of what they actually use. Especially when building out new unproven projects, it's essential to meet the developer where they are at: `,(0,n.jsx)(e.strong,{children:\"zero users\"})]}),`\n`,(0,n.jsx)(e.p,{children:`As long as your customer is too small to generate revenue, they don't want to pay for your service and that's okay.\nGenerous free tiers are a good solution to attract users, but even after they upgrade, you shouldn't send them an enormous bill for resources they're not even using. Pricing that scales with usage is preferrable for many, but not all, products.`}),`\n`,(0,n.jsx)(e.p,{children:`Some companies have different billing tiers, where you'd pay for example: $10 for 10k, $20 for 30k, $50 for 100k. The issue with that is paying the next higher tier just because you have exceeded the previous tier by a small margin, ie: paying $50 for 31k.\nThis system is very easy to implement, but at Unkey we do prorated usaged based billing, which means you pay for your exact usage, not whatever billing tier your usage fits in.`}),`\n`,(0,n.jsx)(e.h2,{id:\"challenges\",children:\"Challenges\"}),`\n`,(0,n.jsx)(e.h3,{id:\"tracking-usage\",children:\"Tracking usage\"}),`\n`,(0,n.jsx)(e.p,{children:`Before charging your customers, you obviously need to know how much and what they used. Tracking this data is the easy part, but where do you store it?\nIf you only produce <100/s billing events and use Stripe, then you could just use subscriptions and update the usage through their API directly. Depending on what you charge for, this can be enough for a long long time. Other billing providers might have similar systems and higher limits, but they probably have a limit too, so we needed to look elsewhere.`}),`\n`,(0,n.jsx)(e.p,{children:\"If we can't directly ingest the usage to our billing provider, we need to store it somewhere first and there are a lot of options, depending on your requirements.\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Redis:\"}),`\nIf you just need to count usage per month, redis would be a great way and can be as simple a using `,(0,n.jsx)(e.code,{children:\"INCR {user}:{year}:{month}\"})]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Your database:\"}),`\nI don't know how far you can scale increments in your database of choice, but it might get you far enough.`]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Time series database:\"}),`\nIf you care about more than just the total value, a database optimized for storing time series would be ideal.\nThere are a ton available for many platforms, or you can selfhost them.`]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Dedicated usage-billing SaaS:\"}),`\nThese days there are even some SaaS, that focus on this problem specifically and allow you to ingest usage records at any rate.`]}),`\n`]}),`\n`,(0,n.jsx)(e.h3,{id:\"sending-usage-to-our-billing-provider\",children:\"Sending usage to our billing provider\"}),`\n`,(0,n.jsxs)(e.p,{children:[`Initially we were using Stripe subscriptions and updating usage in Stripe every hour for every workspace.\nThis worked pretty well and Stripe takes care of a lot of things, such as proration when subscriptions change.\nHowever we also ran into a few issues because Stripe's `,(0,n.jsx)(e.code,{children:\"billing_anchor\"}),\" would not line up perfectly with our own data aggregations, resulting in some missed usage records.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"This could be fixed in theory and Stripe subscriptions are great overall, but we decided to build a more agnostic system, in case we ever want to move off of stripe.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"using-tinybird-for-analytics\",children:\"Using Tinybird for analytics\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"We are building all of our analytics and metrics on top of \",(0,n.jsx)(e.a,{href:\"https://tinybird.co\",children:\"Tinybird\"}),`, a modern real-time data platform, so we reused the existing data to power our billing.\nEvery event is ingested into Tinybird and we can run aggregations against that data later or in real time.`]}),`\n`,(0,n.jsx)(e.p,{children:\"A vertification event at Unkey looks like this, I'll omit unnecessary fields:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-json\",children:`{\n    /**\n    * The workspace that gets billed later\n    */\n    \"workspaceId\": \"ws_123\",\n\n    /**\n    * A unique identifier for the key being verified\n    */\n    \"keyId\": \"key_123\",\n\n    /**\n    * When the verification happened\n    */\n    \"time\": 1709119218743,\n\n    /**\n    * If the verification was denied, we log the reason why\n    * when a key is denied for any reason, we will not charge the customer\n    */\n    \"deniedReason\": null | \"RATE_LIMITED\" | \"USAGE_EXCEEDED\"\n    \n    ... more\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:`During operation, whenever a key is getting verified, we emit one of these events straight to Tinybird.\nThese events are used throughout our dashboard to power analytics charts, and we also make it available to our customers, to build their own dashboards or charge their users.`}),`\n`,(0,n.jsx)(e.h2,{id:\"implementation-details\",children:\"Implementation details\"}),`\n`,(0,n.jsx)(e.p,{children:\"For billing we'll look at extracting two different values for a specific timeframe:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Total usage:\"}),\"  How many events per workspace?\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Distinct usage:\"}),`  How many distinct ids in all the events?\nThis is quite common in the auth space where you charge for \"unique active users\" but is not limited to authentication.\nI've seen some SaaS move from traditional seat-based pricing to active-seat-based, where they only charge you if a user was actually active, rather than just having access.`]}),`\n`]}),`\n`,(0,n.jsx)(e.h3,{id:\"total-successful-verifications\",children:\"Total successful verifications\"}),`\n`,(0,n.jsx)(t,{src:\"/images/blog-images/usage-based-billing/monthly_verifications.png\",alt:\"monthly verifications pipes\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:`To figure out the total usage per workspace, per month, we can simply query the original datasource and write the aggregated data to a materilized view:\nWe filter out all verifications that were denied and then count all verifications per workspace and per month.`}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sql\",children:`SELECT\n    workspaceId,\n    apiId,\n    keyId,\n    countState(*) AS total,\n    toStartOfMonth(fromUnixTimestamp64Milli(time)) AS time\nFROM key_verifications__v2\nWHERE deniedReason IS NULL\nGROUP BY\n    workspaceId,\n    apiId,\n    keyId,\n    time\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[`Then we can write a second pipe that reads data from the materialized view. The beauty of Tinybird is that they expose an HTTP endpoint for you to query this pipe.\nYou can even define query parameters like this: `,(0,n.jsx)(e.code,{children:\"{{ String(workspaceId, required=True) }}\"})]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sql\",children:`SELECT\n    countMerge(total) as total\nFROM mv__monthly_verifications__v2\nWHERE\n    workspaceId = {{ String(workspaceId, required=True) }}\n    AND time = makeDate({{ Int64(year) }}, {{ Int64(month) }}, 1)\nGROUP BY time\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"We can now query this endpoint like this:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`curl .../endpoint?workspaceId=ws_123&year=2024&month=2\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"And we will get back the total number of successful verifications for workspace \",(0,n.jsx)(e.code,{children:\"ws_123\"}),\" in february 2024.\"]}),`\n`,(0,n.jsx)(e.h3,{id:\"active-keys\",children:\"Active keys\"}),`\n`,(0,n.jsx)(t,{src:\"/images/blog-images/usage-based-billing/monthly_active_keys.png\",alt:\"monthly active keys pipes\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:`Again we create an intermediate materialized view first. We could've reused the previous one, but it's nice to have them separated in case we want to change things later.\nThis results in a materialized view, where there's at most one row per keyId and month, making it super cheap to query later.`}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sql\",children:`SELECT\n    workspaceId,\n    apiId,\n    keyId,\n    toStartOfMonth(fromUnixTimestamp64Milli(time)) AS time\nFROM key_verifications__v2\nGROUP BY\n    workspaceId,\n    apiId,\n    keyId,\n    time\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"The query uses \",(0,n.jsx)(e.code,{children:\"count(DISTINCT keyId)\"}),\" to return how many unique keyIds have been observed in the given month.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sql\",children:`SELECT count(DISTINCT keyId) as keys\nFROM mv__monthly_active_keys__v1\nWHERE\n    workspaceId = {{ String(workspaceId, required=True) }}\n    AND time = makeDate({{ Int64(year) }}, {{ Int64(month) }}, 1)\nGROUP BY time\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"When querying the endpoint, we'll get back how many keys had at least 1 verification in a specific workspace and month.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"invoicing\",children:\"Invoicing\"}),`\n`,(0,n.jsxs)(e.p,{children:[`Now that we know how to find out what to charge, let's figure out how to charge our customers.\nWe're still using Stripe to create the invoice and `,(0,n.jsx)(e.a,{href:\"https://trigger.dev\",children:\"trigger.dev\"}),` for durable workflow execution.\nOnce a month, a workflow starts to load all billable workspaces, load their usage and create an invoice.`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"We simply store a \",(0,n.jsx)(e.code,{children:\"stripeCustomerId\"}),\" and \",(0,n.jsx)(e.code,{children:\"subscription\"}),\"column in our database and can query all workspaces easily:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const workspaces = await io.runTask(\"list workspaces\", async () =>\n    db.query.workspaces.findMany({\n    where: (table, { isNotNull, isNull, not, eq, and }) =>\n        and(\n            isNotNull(table.stripeCustomerId),\n            isNotNull(table.subscriptions),\n            not(eq(table.plan, \"free\")),\n            isNull(table.deletedAtM),\n        ),\n    }),\n);\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Afterwards we fetch the usage for both keys and verifications and finalize the invoice. The code is all open source, if you're interested: \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/unkey/blob/main/apps/workflows/jobs/create-invoice.ts\",children:\"create-invoice.ts\"})]}),`\n`,(0,n.jsx)(e.h2,{id:\"results\",children:\"Results\"}),`\n`,(0,n.jsx)(e.p,{children:`Doing invoicing ourselves made it easier to customize its behaviour. That being said, it definitely took longer to implement than sitting down and fixing subscription timing issues properly.\nEspecially prorations are pretty annoying to handle.`}),`\n`,(0,n.jsx)(e.p,{children:\"We're still happy with the result, as it allows us to edit and tweak things as we go, whereas Stripe makes a ton of options non-editable. We can also switch providers at any time as we own the entire billing flow.\"})]})}function h(i={}){let{wrapper:e}=i.components||{};return e?(0,n.jsx)(e,{...i,children:(0,n.jsx)(c,{...i})}):c(i)}function k(i,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+i+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return v(I);})();\n;return Component;",
    "slug": "high-frequency-usage-billing",
    "url": "/blog/high-frequency-usage-billing",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Challenges",
        "slug": "challenges"
      },
      {
        "level": 3,
        "text": "Tracking usage",
        "slug": "tracking-usage"
      },
      {
        "level": 3,
        "text": "Sending usage to our billing provider",
        "slug": "sending-usage-to-our-billing-provider"
      },
      {
        "level": 2,
        "text": "Using Tinybird for analytics",
        "slug": "using-tinybird-for-analytics"
      },
      {
        "level": 2,
        "text": "Implementation details",
        "slug": "implementation-details"
      },
      {
        "level": 3,
        "text": "Total successful verifications",
        "slug": "total-successful-verifications"
      },
      {
        "level": 3,
        "text": "Active keys",
        "slug": "active-keys"
      },
      {
        "level": 3,
        "text": "Invoicing",
        "slug": "invoicing"
      },
      {
        "level": 2,
        "text": "Results",
        "slug": "results"
      }
    ]
  },
  {
    "content": "I have always been opinionated about marketing and how it doesn't work for developer tools. Similarly, I believe that 95% of companies doing developer relations are doing it wrong, and most of it comes down to the following:\n\n> I saw X company doing it, and they were successful. I did the same, and it didn't work.\n\nThe reason you see company X succeeding is that when they started doing whatever marketing strategy, the world was different. If you are a startup trying to gain traction, you look at marketing from an enterprise perspective. Let's talk about how Unkey does marketing and why it spills a little into developer relations.\n\n## TLDR\n\n### Free\n\nFor YouTube:\n\n- People won't subscribe to a business channel, so use a personal channel if you have one.\n- If you want a business channel, expect the views-to-subscriber ratio to be weird.\n- Content of any form is good content (short form, long form, live streaming)\n\nStreaming:\n\n- If you are new. Find people in the industry to stream on their channel as a guest.\n- Stream on all platforms you can (YT, Twitch) to find the platform that works for you and your potential audience.\n- Expect that streaming will produce poor results initially (discovery could be better). If you don't see any growth after 3-6 months, stop (it's not a medium that works for you)\n\nTweeting:\n\n- Tweet from your account and tag your business account.\n- Have fun on the business account (memes, GIFs, etc)\n- Tweet from the business account when you have a following of 1k but only impactful stuff.\n\n### If you have money to spend\n\n- Influencers are your friend\n- Find five \"influencers\" in the niche, and build a relationship with them, then once you have a relationship, you can work together. They should be champions of your product, not just you paying them.\n- Sponsor community projects\n- YT videos that are sponsored. The outcome is not the \"views\"; the outcome is if someone searches for you, you aren't the only person talking about it. Even people with 2k subscribers have more reach than you do, for the most part.\n\n### Product Led growth\n\nThree key places to talk to a customer\n\n- Onboarding (send an email when they sign up offering up a way to get in touch)\n- Users who are using the product consistently\n- Offboarding (Why are you leaving)\n\n## YouTube & Streaming\n\nYouTube has unlimited marketing potential; it's why influencers in 2023 are making products. Looking at the space now, you have influencers in industries you'd never have imagined 20 years ago; let's look at Logan Paul and KSI. Both have huge followings across almost all platforms, but mostly YouTube. They now both have:\n\n- Boxing careers\n- A multi-billion dollar drink company\n- Music careers\n- Alcohol brand, food brands\n\nPrime spends almost zero dollars on marketing because they have free marketing from two influences. This means they can then spend money on sponsoring massive sporting clubs or athletes to move the brand forward. Their product could be better for what it is for, but their marketing train is incredible. What does this have to do with developer tools? I hear you ask!\n\n> YouTube is free marketing with unlimited potential.\n\n### Personal Channels vs Business Channels\n\nOpen your YouTube subscriber feed; how many companies are you subscribed to? The answer is probably close to zero if not zero, and this is where the problem for a new company starts. How do you market if people don't subscribe to your channel?\n\n#### Personal Channel\n\nIf you have a personal channel, you can get back into your channel... Assuming that one falls into your niche and your audience can roll with the content from your company. If you don't have a personal channel, the next question is, \"Do you have time\"? Right now, the answer will be yes. You are a scrappy startup, and you can make time. YouTube is a garden. It needs a lot of work to be successful. If you are interested in content creation, then go for it. Otherwise, a business channel is for you, but I still believe personal channels rule.\n\n#### Business Channel\n\nSo you want a channel that only deals with X company and things related to X company? Great! Let me break down what you'd expect from having a business channel:\n\n- People aren't going to subscribe as quickly as a personal channel\n- The content needs to be focused on things people search for.\n- Build for search in an intelligent way.\n\nIf your devtool is \"API Authentication\", please don't make a \"Getting Started with API Authentication video\". Your docs already cover this. Make videos that focus on aspects of integrating your product somewhere, \"How to secure Supabase functions using X\" is something some will search for.\n\n#### Content\n\nAll content forms are suitable content forms as long as you put the effort in:\n\n- YT Shorts / TikToks\n- YT longer form (3-20 mins)\n- YT Crash courses (30+ mins)\n- Livestreaming\n\nAll of these are searchable, all of these provide reusable content, and all of them can be embedded in the future.\n\n### Streaming\n\nSo, you want to stream? Don't. Almost every company that tries streaming gives up because a streamer is an exceptional kind of person. The amount of time spent sitting in front of an audience or no audience for hours is demanding. If you decide you are up for a challenge:\n\n- Start by testing the water with people who stream and have guests.\n- A personal channel is best\n- Expect traction to be slow\n- Give up at 3-5 months if you aren't seeing growth... Your efforts are better elsewhere.\n\n## Tweeting / Social Media\n\nIs it still called tweeting? Xing? Either way, Social Media can bring in a large amount of traffic if used correctly. To put it in perspective, our launch of Unkey was a single tweet on my account which had at the time around 4,000 followers. This brought over 700 users in the first week.\n\n<Image src=\"/images/blog-images/how-to-market/tweet-example.png\" alt=\"Example launch tweet\" width=\"1920\" height=\"1080\" />\n\n### Use your account\n\nYou should tweet a lot from your account and tag your startup. Why? People trust a face, not a business. They'd rather follow you as a person and interact than a company that is just a logo. The human brain is weird, but it's true.\n\n### When to use the business account\n\nUse the business account to quote, repost a tag, and have fun with it. Companies are too serious because they think that is what people want to see. Instead, we want to see the opposite:\n\n- memes\n- GIFs\n- making fun of yourself\n\nFinally, once your business account grows a following of around 1,000 people, you can start posting updates of the product... But don't stop Memeing and quote posting/retweeting.\n\n## Got Money?\n\nSo you have money? Congrats! Let me save you some money in your marketing budget because, again, traditional marketing is dead for startups.\n\n### Find your people.\n\nThe first thing you want to do is identify five people, five developers, who have opinions and also an audience. Please don't reach out to them directly. Join their communities figure out their pain points and their needs.\n\n- Join Discords\n- Read blog posts\n- Watch their videos\n- Help in the communities\n\nThis should be obvious, but when you have blinders on and want growth and results, you can't see it. Then, you will build a reputation with the communities where you wish to use your product. DO NOT SELL. IF YOU SELL, your reputation is ruined.\n\n### Work with your people\n\nOnce you are helping communities and being part of the world you are trying to help, working with your people becomes more straightforward. You have a relationship. When you make the first piece of content, it should be about the problem you are solving. We didn't have to show any code when I worked at Clerk, and we worked with Theo for the first time. The video was four minutes long. Theo didn't show any tech behind the open-source project. Theo didn't show any actual code. Theo just talked about the problem and how we solved it. Theo talked about the pain points that we had and how we solved them. Theo talked about the challenges that we had and how we solved them. Theo showed 15 seconds of the application.\n\nThis was intentional; we wanted people to see the problem and how we finally solved it, and then we wanted them to go and try it out for themselves. We didn't want to show them how to do it, we wanted them to figure it out themselves. We wanted them to see the problem and then go and try it out for themselves. I also wanted to do my video on the same topic, this time showing the tech behind it all and how it worked.\n\nThis single content piece increased our daily sign-ups and our daily active users by a magnitude of almost 10.\n\n### Double down? Triple down? Quadruple down?\n\nThe problem with most companies is that they need to double down on what's working. They need to triple down on what's working. They don't quadruple down on what's working. They keep doing the same thing over and over again, with different people, different audiences, and different target methods, hoping that it will work.\n\nDo the opposite, double down on what is working. Triple down on what is working. Quadruple down on what is working. If you find the right person, they should be hyped about your product, and you should be promoted about their success. Working together should be easy! If it's not, you are working with the wrong person.\n\n### Sponsor community projects\n\nHave you ever tuned in to some of those events that bring minimal educational value but bring massive community value? I am talking about:\n\n- Gameshows\n- Charity events\n- Hackathons\n- Community meetups\n- Swag giveaways\n\nSPONSOR THEM. If you are a developer tool, you should be sponsoring these events. You should be sponsoring the prizes, you should be sponsoring the swag, you should be sponsoring the food. You should be sponsoring the drinks. You should be sponsoring the venue. You should be sponsoring the speakers. You should be sponsoring the creators.\n\nBefore you get upset, the community needs these events. They are the lifeblood of what keeps the community together. When, as Clerk, I sponsored the:\n\n- Frontend Horse Christmas Spectacular\n- Github projects\n- Twitter Guesser game show... Which was hilarious.\n- Colby Fayock's site launch giveaways\n\nSome of those events had no real value to Clerk, but they had value to the community. Which means they had value to Clerk.\n\n### Sponsor YT videos\n\nI've talked a lot about YouTube during this blog post, but I want to make sure you are looking at YouTube in two ways as you grow:\n\n1. Increased discoverability/brand awareness\n2. Increased usage of your product\n\n### Increased discoverability/brand awareness\n\nWhen you think about the results of a video. Views aren't everything, while yes, if you manage to work with large influencers, the views will be a byproduct. You want to think about the following:\n\n- How many people are searching for your product?\n- How many people are searching for your competitor's product?\n- How many people are searching for the problem you solve?\n- How many people are talking about the problem you solve, your product, or competitors' products?\n\nThe bottom one is increased by having more videos that aren't talking about your product. If you are the only person talking about it, why would anyone trust that your product is excellent?\n\n### Increased usage of your product\n\nThis part comes with time. You will see spikes in usage as sponsor videos go out. They are following along, but retention is the key. If you see a spike in usage and then a drop-off, you must figure out why. It's more complicated when you start because the %s are out of wack, but you can still see the trends.\n\n## Product led growth\n\nProduct led growth is super significant, and I like to do the following three things:\n\n- Onboarding (send an email when they sign up offering up a way to get in touch)\n- Users who are using the product consistently\n- Offboarding (Why you leaving)\n\n### Onboarding\n\nWhen a user onboards to your product, the first thing we do is send you an email. With three key points in it:\n\n- Quickstart\n- Security\n- Discord Community\n\n<Image src=\"/images/blog-images/how-to-market/welcome-unkey.png\" width=\"1920\" height=\"1080\" alt =\"Example onboarding email\"/>\n\nOn top of this, they can respond to the email with feedback or questions. This is a great way to get feedback from users who are just getting started.\n\n### Users who are using the product consistently\n\nWhen users use the product consistently, we send them an email asking what they are building and how we can help. This email should be handwritten and should be from a natural person. This is a great way to get feedback from users using the product and build a relationship with them.\n\n### Offboarding\n\nWhen a user offboards, we send them an email asking them why they are leaving. This email should also handwritten and should be from a real person. We can find out what was lacking, what they didn't like, and what we can do better.\n\nYou will notice everything is related to feedback and building relationships. This is the key to product-led growth.\n\n## Conclusion\n\nTraditional marketing is dead from Unkey's perspective, and I hope this blog post has helped you understand how we think about marketing and developer relations. If you have any questions, feel free to reach out to me on [X(Twitter)](https://x.com/james_r_perkins).",
    "title": "How Unkey Treats Marketing",
    "description": "Traditional marketing is dead, so lets talk about how to market and using product led growth.",
    "author": "james",
    "date": "2023-11-02",
    "tags": [
      "marketing"
    ],
    "image": "/images/blog-images/covers/unkey-marketing.png",
    "_meta": {
      "filePath": "how-unkey-treats-marketing.mdx",
      "fileName": "how-unkey-treats-marketing.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "how-unkey-treats-marketing"
    },
    "mdx": "var Component=(()=>{var c=Object.create;var r=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var w=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var g=(o,e)=>()=>(e||o((e={exports:{}}).exports,e),e.exports),f=(o,e)=>{for(var t in e)r(o,t,{get:e[t],enumerable:!0})},s=(o,e,t,a)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let i of w(e))!m.call(o,i)&&i!==t&&r(o,i,{get:()=>e[i],enumerable:!(a=p(e,i))||a.enumerable});return o};var b=(o,e,t)=>(t=o!=null?c(y(o)):{},s(e||!o||!o.__esModule?r(t,\"default\",{value:o,enumerable:!0}):t,o)),v=o=>s(r({},\"__esModule\",{value:!0}),o);var l=g((Y,h)=>{h.exports=_jsx_runtime});var T={};f(T,{default:()=>u});var n=b(l());function d(o){let e={a:\"a\",blockquote:\"blockquote\",h2:\"h2\",h3:\"h3\",h4:\"h4\",li:\"li\",ol:\"ol\",p:\"p\",ul:\"ul\",...o.components},{Image:t}=e;return t||k(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"I have always been opinionated about marketing and how it doesn't work for developer tools. Similarly, I believe that 95% of companies doing developer relations are doing it wrong, and most of it comes down to the following:\"}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsx)(e.p,{children:\"I saw X company doing it, and they were successful. I did the same, and it didn't work.\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"The reason you see company X succeeding is that when they started doing whatever marketing strategy, the world was different. If you are a startup trying to gain traction, you look at marketing from an enterprise perspective. Let's talk about how Unkey does marketing and why it spills a little into developer relations.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"tldr\",children:\"TLDR\"}),`\n`,(0,n.jsx)(e.h3,{id:\"free\",children:\"Free\"}),`\n`,(0,n.jsx)(e.p,{children:\"For YouTube:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"People won't subscribe to a business channel, so use a personal channel if you have one.\"}),`\n`,(0,n.jsx)(e.li,{children:\"If you want a business channel, expect the views-to-subscriber ratio to be weird.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Content of any form is good content (short form, long form, live streaming)\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Streaming:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"If you are new. Find people in the industry to stream on their channel as a guest.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Stream on all platforms you can (YT, Twitch) to find the platform that works for you and your potential audience.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Expect that streaming will produce poor results initially (discovery could be better). If you don't see any growth after 3-6 months, stop (it's not a medium that works for you)\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Tweeting:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Tweet from your account and tag your business account.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Have fun on the business account (memes, GIFs, etc)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Tweet from the business account when you have a following of 1k but only impactful stuff.\"}),`\n`]}),`\n`,(0,n.jsx)(e.h3,{id:\"if-you-have-money-to-spend\",children:\"If you have money to spend\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Influencers are your friend\"}),`\n`,(0,n.jsx)(e.li,{children:'Find five \"influencers\" in the niche, and build a relationship with them, then once you have a relationship, you can work together. They should be champions of your product, not just you paying them.'}),`\n`,(0,n.jsx)(e.li,{children:\"Sponsor community projects\"}),`\n`,(0,n.jsx)(e.li,{children:`YT videos that are sponsored. The outcome is not the \"views\"; the outcome is if someone searches for you, you aren't the only person talking about it. Even people with 2k subscribers have more reach than you do, for the most part.`}),`\n`]}),`\n`,(0,n.jsx)(e.h3,{id:\"product-led-growth\",children:\"Product Led growth\"}),`\n`,(0,n.jsx)(e.p,{children:\"Three key places to talk to a customer\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Onboarding (send an email when they sign up offering up a way to get in touch)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Users who are using the product consistently\"}),`\n`,(0,n.jsx)(e.li,{children:\"Offboarding (Why are you leaving)\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"youtube--streaming\",children:\"YouTube & Streaming\"}),`\n`,(0,n.jsx)(e.p,{children:\"YouTube has unlimited marketing potential; it's why influencers in 2023 are making products. Looking at the space now, you have influencers in industries you'd never have imagined 20 years ago; let's look at Logan Paul and KSI. Both have huge followings across almost all platforms, but mostly YouTube. They now both have:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Boxing careers\"}),`\n`,(0,n.jsx)(e.li,{children:\"A multi-billion dollar drink company\"}),`\n`,(0,n.jsx)(e.li,{children:\"Music careers\"}),`\n`,(0,n.jsx)(e.li,{children:\"Alcohol brand, food brands\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Prime spends almost zero dollars on marketing because they have free marketing from two influences. This means they can then spend money on sponsoring massive sporting clubs or athletes to move the brand forward. Their product could be better for what it is for, but their marketing train is incredible. What does this have to do with developer tools? I hear you ask!\"}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsx)(e.p,{children:\"YouTube is free marketing with unlimited potential.\"}),`\n`]}),`\n`,(0,n.jsx)(e.h3,{id:\"personal-channels-vs-business-channels\",children:\"Personal Channels vs Business Channels\"}),`\n`,(0,n.jsx)(e.p,{children:\"Open your YouTube subscriber feed; how many companies are you subscribed to? The answer is probably close to zero if not zero, and this is where the problem for a new company starts. How do you market if people don't subscribe to your channel?\"}),`\n`,(0,n.jsx)(e.h4,{id:\"personal-channel\",children:\"Personal Channel\"}),`\n`,(0,n.jsx)(e.p,{children:`If you have a personal channel, you can get back into your channel... Assuming that one falls into your niche and your audience can roll with the content from your company. If you don't have a personal channel, the next question is, \"Do you have time\"? Right now, the answer will be yes. You are a scrappy startup, and you can make time. YouTube is a garden. It needs a lot of work to be successful. If you are interested in content creation, then go for it. Otherwise, a business channel is for you, but I still believe personal channels rule.`}),`\n`,(0,n.jsx)(e.h4,{id:\"business-channel\",children:\"Business Channel\"}),`\n`,(0,n.jsx)(e.p,{children:\"So you want a channel that only deals with X company and things related to X company? Great! Let me break down what you'd expect from having a business channel:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"People aren't going to subscribe as quickly as a personal channel\"}),`\n`,(0,n.jsx)(e.li,{children:\"The content needs to be focused on things people search for.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Build for search in an intelligent way.\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:`If your devtool is \"API Authentication\", please don't make a \"Getting Started with API Authentication video\". Your docs already cover this. Make videos that focus on aspects of integrating your product somewhere, \"How to secure Supabase functions using X\" is something some will search for.`}),`\n`,(0,n.jsx)(e.h4,{id:\"content\",children:\"Content\"}),`\n`,(0,n.jsx)(e.p,{children:\"All content forms are suitable content forms as long as you put the effort in:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"YT Shorts / TikToks\"}),`\n`,(0,n.jsx)(e.li,{children:\"YT longer form (3-20 mins)\"}),`\n`,(0,n.jsx)(e.li,{children:\"YT Crash courses (30+ mins)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Livestreaming\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"All of these are searchable, all of these provide reusable content, and all of them can be embedded in the future.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"streaming\",children:\"Streaming\"}),`\n`,(0,n.jsx)(e.p,{children:\"So, you want to stream? Don't. Almost every company that tries streaming gives up because a streamer is an exceptional kind of person. The amount of time spent sitting in front of an audience or no audience for hours is demanding. If you decide you are up for a challenge:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Start by testing the water with people who stream and have guests.\"}),`\n`,(0,n.jsx)(e.li,{children:\"A personal channel is best\"}),`\n`,(0,n.jsx)(e.li,{children:\"Expect traction to be slow\"}),`\n`,(0,n.jsx)(e.li,{children:\"Give up at 3-5 months if you aren't seeing growth... Your efforts are better elsewhere.\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"tweeting--social-media\",children:\"Tweeting / Social Media\"}),`\n`,(0,n.jsx)(e.p,{children:\"Is it still called tweeting? Xing? Either way, Social Media can bring in a large amount of traffic if used correctly. To put it in perspective, our launch of Unkey was a single tweet on my account which had at the time around 4,000 followers. This brought over 700 users in the first week.\"}),`\n`,(0,n.jsx)(t,{src:\"/images/blog-images/how-to-market/tweet-example.png\",alt:\"Example launch tweet\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.h3,{id:\"use-your-account\",children:\"Use your account\"}),`\n`,(0,n.jsx)(e.p,{children:\"You should tweet a lot from your account and tag your startup. Why? People trust a face, not a business. They'd rather follow you as a person and interact than a company that is just a logo. The human brain is weird, but it's true.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"when-to-use-the-business-account\",children:\"When to use the business account\"}),`\n`,(0,n.jsx)(e.p,{children:\"Use the business account to quote, repost a tag, and have fun with it. Companies are too serious because they think that is what people want to see. Instead, we want to see the opposite:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"memes\"}),`\n`,(0,n.jsx)(e.li,{children:\"GIFs\"}),`\n`,(0,n.jsx)(e.li,{children:\"making fun of yourself\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Finally, once your business account grows a following of around 1,000 people, you can start posting updates of the product... But don't stop Memeing and quote posting/retweeting.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"got-money\",children:\"Got Money?\"}),`\n`,(0,n.jsx)(e.p,{children:\"So you have money? Congrats! Let me save you some money in your marketing budget because, again, traditional marketing is dead for startups.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"find-your-people\",children:\"Find your people.\"}),`\n`,(0,n.jsx)(e.p,{children:\"The first thing you want to do is identify five people, five developers, who have opinions and also an audience. Please don't reach out to them directly. Join their communities figure out their pain points and their needs.\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Join Discords\"}),`\n`,(0,n.jsx)(e.li,{children:\"Read blog posts\"}),`\n`,(0,n.jsx)(e.li,{children:\"Watch their videos\"}),`\n`,(0,n.jsx)(e.li,{children:\"Help in the communities\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"This should be obvious, but when you have blinders on and want growth and results, you can't see it. Then, you will build a reputation with the communities where you wish to use your product. DO NOT SELL. IF YOU SELL, your reputation is ruined.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"work-with-your-people\",children:\"Work with your people\"}),`\n`,(0,n.jsx)(e.p,{children:\"Once you are helping communities and being part of the world you are trying to help, working with your people becomes more straightforward. You have a relationship. When you make the first piece of content, it should be about the problem you are solving. We didn't have to show any code when I worked at Clerk, and we worked with Theo for the first time. The video was four minutes long. Theo didn't show any tech behind the open-source project. Theo didn't show any actual code. Theo just talked about the problem and how we solved it. Theo talked about the pain points that we had and how we solved them. Theo talked about the challenges that we had and how we solved them. Theo showed 15 seconds of the application.\"}),`\n`,(0,n.jsx)(e.p,{children:\"This was intentional; we wanted people to see the problem and how we finally solved it, and then we wanted them to go and try it out for themselves. We didn't want to show them how to do it, we wanted them to figure it out themselves. We wanted them to see the problem and then go and try it out for themselves. I also wanted to do my video on the same topic, this time showing the tech behind it all and how it worked.\"}),`\n`,(0,n.jsx)(e.p,{children:\"This single content piece increased our daily sign-ups and our daily active users by a magnitude of almost 10.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"double-down-triple-down-quadruple-down\",children:\"Double down? Triple down? Quadruple down?\"}),`\n`,(0,n.jsx)(e.p,{children:\"The problem with most companies is that they need to double down on what's working. They need to triple down on what's working. They don't quadruple down on what's working. They keep doing the same thing over and over again, with different people, different audiences, and different target methods, hoping that it will work.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Do the opposite, double down on what is working. Triple down on what is working. Quadruple down on what is working. If you find the right person, they should be hyped about your product, and you should be promoted about their success. Working together should be easy! If it's not, you are working with the wrong person.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"sponsor-community-projects\",children:\"Sponsor community projects\"}),`\n`,(0,n.jsx)(e.p,{children:\"Have you ever tuned in to some of those events that bring minimal educational value but bring massive community value? I am talking about:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Gameshows\"}),`\n`,(0,n.jsx)(e.li,{children:\"Charity events\"}),`\n`,(0,n.jsx)(e.li,{children:\"Hackathons\"}),`\n`,(0,n.jsx)(e.li,{children:\"Community meetups\"}),`\n`,(0,n.jsx)(e.li,{children:\"Swag giveaways\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"SPONSOR THEM. If you are a developer tool, you should be sponsoring these events. You should be sponsoring the prizes, you should be sponsoring the swag, you should be sponsoring the food. You should be sponsoring the drinks. You should be sponsoring the venue. You should be sponsoring the speakers. You should be sponsoring the creators.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Before you get upset, the community needs these events. They are the lifeblood of what keeps the community together. When, as Clerk, I sponsored the:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Frontend Horse Christmas Spectacular\"}),`\n`,(0,n.jsx)(e.li,{children:\"Github projects\"}),`\n`,(0,n.jsx)(e.li,{children:\"Twitter Guesser game show... Which was hilarious.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Colby Fayock's site launch giveaways\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Some of those events had no real value to Clerk, but they had value to the community. Which means they had value to Clerk.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"sponsor-yt-videos\",children:\"Sponsor YT videos\"}),`\n`,(0,n.jsx)(e.p,{children:\"I've talked a lot about YouTube during this blog post, but I want to make sure you are looking at YouTube in two ways as you grow:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Increased discoverability/brand awareness\"}),`\n`,(0,n.jsx)(e.li,{children:\"Increased usage of your product\"}),`\n`]}),`\n`,(0,n.jsx)(e.h3,{id:\"increased-discoverabilitybrand-awareness\",children:\"Increased discoverability/brand awareness\"}),`\n`,(0,n.jsx)(e.p,{children:\"When you think about the results of a video. Views aren't everything, while yes, if you manage to work with large influencers, the views will be a byproduct. You want to think about the following:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"How many people are searching for your product?\"}),`\n`,(0,n.jsx)(e.li,{children:\"How many people are searching for your competitor's product?\"}),`\n`,(0,n.jsx)(e.li,{children:\"How many people are searching for the problem you solve?\"}),`\n`,(0,n.jsx)(e.li,{children:\"How many people are talking about the problem you solve, your product, or competitors' products?\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"The bottom one is increased by having more videos that aren't talking about your product. If you are the only person talking about it, why would anyone trust that your product is excellent?\"}),`\n`,(0,n.jsx)(e.h3,{id:\"increased-usage-of-your-product\",children:\"Increased usage of your product\"}),`\n`,(0,n.jsx)(e.p,{children:\"This part comes with time. You will see spikes in usage as sponsor videos go out. They are following along, but retention is the key. If you see a spike in usage and then a drop-off, you must figure out why. It's more complicated when you start because the %s are out of wack, but you can still see the trends.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"product-led-growth-1\",children:\"Product led growth\"}),`\n`,(0,n.jsx)(e.p,{children:\"Product led growth is super significant, and I like to do the following three things:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Onboarding (send an email when they sign up offering up a way to get in touch)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Users who are using the product consistently\"}),`\n`,(0,n.jsx)(e.li,{children:\"Offboarding (Why you leaving)\"}),`\n`]}),`\n`,(0,n.jsx)(e.h3,{id:\"onboarding\",children:\"Onboarding\"}),`\n`,(0,n.jsx)(e.p,{children:\"When a user onboards to your product, the first thing we do is send you an email. With three key points in it:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Quickstart\"}),`\n`,(0,n.jsx)(e.li,{children:\"Security\"}),`\n`,(0,n.jsx)(e.li,{children:\"Discord Community\"}),`\n`]}),`\n`,(0,n.jsx)(t,{src:\"/images/blog-images/how-to-market/welcome-unkey.png\",width:\"1920\",height:\"1080\",alt:\"Example onboarding email\"}),`\n`,(0,n.jsx)(e.p,{children:\"On top of this, they can respond to the email with feedback or questions. This is a great way to get feedback from users who are just getting started.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"users-who-are-using-the-product-consistently\",children:\"Users who are using the product consistently\"}),`\n`,(0,n.jsx)(e.p,{children:\"When users use the product consistently, we send them an email asking what they are building and how we can help. This email should be handwritten and should be from a natural person. This is a great way to get feedback from users using the product and build a relationship with them.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"offboarding\",children:\"Offboarding\"}),`\n`,(0,n.jsx)(e.p,{children:\"When a user offboards, we send them an email asking them why they are leaving. This email should also handwritten and should be from a real person. We can find out what was lacking, what they didn't like, and what we can do better.\"}),`\n`,(0,n.jsx)(e.p,{children:\"You will notice everything is related to feedback and building relationships. This is the key to product-led growth.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Traditional marketing is dead from Unkey's perspective, and I hope this blog post has helped you understand how we think about marketing and developer relations. If you have any questions, feel free to reach out to me on \",(0,n.jsx)(e.a,{href:\"https://x.com/james_r_perkins\",children:\"X(Twitter)\"}),\".\"]})]})}function u(o={}){let{wrapper:e}=o.components||{};return e?(0,n.jsx)(e,{...o,children:(0,n.jsx)(d,{...o})}):d(o)}function k(o,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+o+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return v(T);})();\n;return Component;",
    "slug": "how-unkey-treats-marketing",
    "url": "/blog/how-unkey-treats-marketing",
    "tableOfContents": [
      {
        "level": 2,
        "text": "TLDR",
        "slug": "tldr"
      },
      {
        "level": 3,
        "text": "Free",
        "slug": "free"
      },
      {
        "level": 3,
        "text": "If you have money to spend",
        "slug": "if-you-have-money-to-spend"
      },
      {
        "level": 3,
        "text": "Product Led growth",
        "slug": "product-led-growth"
      },
      {
        "level": 2,
        "text": "YouTube & Streaming",
        "slug": "youtube--streaming"
      },
      {
        "level": 3,
        "text": "Personal Channels vs Business Channels",
        "slug": "personal-channels-vs-business-channels"
      },
      {
        "level": 4,
        "text": "Personal Channel",
        "slug": "personal-channel"
      },
      {
        "level": 4,
        "text": "Business Channel",
        "slug": "business-channel"
      },
      {
        "level": 4,
        "text": "Content",
        "slug": "content"
      },
      {
        "level": 3,
        "text": "Streaming",
        "slug": "streaming"
      },
      {
        "level": 2,
        "text": "Tweeting / Social Media",
        "slug": "tweeting--social-media"
      },
      {
        "level": 3,
        "text": "Use your account",
        "slug": "use-your-account"
      },
      {
        "level": 3,
        "text": "When to use the business account",
        "slug": "when-to-use-the-business-account"
      },
      {
        "level": 2,
        "text": "Got Money?",
        "slug": "got-money"
      },
      {
        "level": 3,
        "text": "Find your people.",
        "slug": "find-your-people"
      },
      {
        "level": 3,
        "text": "Work with your people",
        "slug": "work-with-your-people"
      },
      {
        "level": 3,
        "text": "Double down? Triple down? Quadruple down?",
        "slug": "double-down-triple-down-quadruple-down"
      },
      {
        "level": 3,
        "text": "Sponsor community projects",
        "slug": "sponsor-community-projects"
      },
      {
        "level": 3,
        "text": "Sponsor YT videos",
        "slug": "sponsor-yt-videos"
      },
      {
        "level": 3,
        "text": "Increased discoverability/brand awareness",
        "slug": "increased-discoverabilitybrand-awareness"
      },
      {
        "level": 3,
        "text": "Increased usage of your product",
        "slug": "increased-usage-of-your-product"
      },
      {
        "level": 2,
        "text": "Product led growth",
        "slug": "product-led-growth-1"
      },
      {
        "level": 3,
        "text": "Onboarding",
        "slug": "onboarding"
      },
      {
        "level": 3,
        "text": "Users who are using the product consistently",
        "slug": "users-who-are-using-the-product-consistently"
      },
      {
        "level": 3,
        "text": "Offboarding",
        "slug": "offboarding"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "Artificial Intelligence (AI) has undeniably transformed the technology landscape in the past few years. From OpenAI to Llama 2, AI has permeated every facet of our lives. Yet, as with any groundbreaking technology, developers face unique challenges when working on AI projects. This is where Unkey comes in. Unkey's API management platform helps developers secure, manage, and scale their APIs.\n\n## What is Unkey?\n\nUnkey is an open source API management platform, that provides a low-latency option to create, manage and revoke API Keys for your API. We offer features like:\n\n- Rate limiting per key\n- Temporary keys\n- Limited use keys\n\nUnkey also offers seamless integration with popular programming languages making it easier for developers to work in an environment they are comfortable with. Whether you are a Typescript, Python, or a Go developer you can use Unkey in minutes.\n\n## How Unkey Can Help AI Projects\n\nWhen it comes to AI project development, Unkey is a game-changer. It aids in streamlining the API development process. With our robust features, Unkey allows developers to focus on the creative aspects of AI development rather than getting bogged down with how to secure their APIs.\n\nFor instance, consider developing an application that interacts with OpenAPI, you want users to be able to use your service but you don't want them to be able to abuse it. If you handle this yourself you need to think about:\n\n1. How do I identify the user\n2. Implement a rate limiting system.\n3. Implement a token system to allow them to use X tokens\n4. Make sure it's fast.\n\nWith Unkey you can simplify this by adding in a single API call to create a user's API Key with both a token system and rate limiting built in. Below is an example of a cURL request that creates a key with rate limiting of 10 requests, that refill at a rate of 1 request per second. The key also has 100 total requests allowed before they can no longer access the resource.\n\n```bash\ncurl --request POST \\\n  --url https://api.unkey.dev/v1/keys.createKey \\\n  --header 'Authorization: Bearer <UNKEY>' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n\t\"apiId\":\"<API_ID>\",\n\t\"ratelimit\":{\n\t\t\"type\":\"fast\",\n\t\t\"limit\":10,\n\t\t\"refillRate\": 1,\n\t\t\"refillInterval\": 1000\n\t},\n\t\"remaining\": 100\n}'\n```\n\nThe response includes the key itself, which you should pass on to your user and a keyId, which you can use later to update or revoke the key. Dont worry about storing the keyId, you can always query it later from Unkey when you need it.\n\n```jsx\n{\n  \"key\": \"prefix_5AkwpYpIHntGBpTHLqKg\",\n  \"keyId\": \"key_123\"\n}\n```\n\nSo now you have an API key, but how does that help you protect your AI project? Unkey provides a verify endpoint, this endpoint can verify a request in under 40 ms and provide you with the details you need to make a business decision. For example:\n\n```bash\ncurl --request POST \\\n  --url https://api.unkey.dev/v1/keys.verifyKey \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n    \"key\":\"THE_NEW_KEY\"\n  }'\n```\n\nThis returns the following in the body:\n\n```bash\n{\n   \"valid\":true,\n   \"remaining\":99,\n   \"ratelimit\":{\n      \"limit\":10,\n      \"remaining\":9,\n      \"reset\":1690065988700\n   }\n}\n```\n\nAs you see Unkey returns \"valid\": true which allows you to make an immediate business decision, if it is true let them access the resource, if it is false deny them access. On top of that, we return the total remaining requests, which you could return to your user, and finally their rate limits.\n\nEven though these examples are in cURL we have a typescript SDK and community SDKs in Go, Python, Elixir, and a Nuxt module.\n\n## How to Start Using Unkey for Your AI Projects\n\nStarting with Unkey for your AI projects is straightforward. To begin, sign up for your free Unkey account. As soon as you create your account you will be asked to create your workspace. Give it a name, and a slug. The name is shown only to you and not to your users.\n\nNext, you need to create a root API Key, this is a special API Key that allows you full read and write access to all current and future resources. Its important to keep this API Key safe, as it allows you to create, revoke, validate, and delete API Keys. You can do this by selecting settings and then clicking the Create New Key button.\n\n<Image src=\"/images/blog-images/ai-post/create-root-key.png\" alt=\"Create Root Key\" width=\"1920\" height=\"1080\"/>\n\nThen you can create your first API which allows you to track usage as well as segment keys, the name you choose is also not visible to users.\n\n<Image src=\"/images/blog-images/ai-post/create-api.png\" alt=\"Create API\" width=\"1920\" height=\"1080\"/>\n\nYou are now ready to integrate Unkey into your code! If you are manually issuing keys you can do that right from our dashboard, otherwise you can start reading our [documentation](http://unkey.com/docs) and learn about everything we have to offer.",
    "title": "How Unkey can help accelerate your AI development",
    "description": "Building AI projects and protecting the API can be a daunting task. With Unkey we simplify the experience.",
    "author": "james",
    "date": "2023-07-26",
    "tags": [
      "AI"
    ],
    "image": "/images/blog-images/covers/unkey-ai.png",
    "_meta": {
      "filePath": "how-we-ai.mdx",
      "fileName": "how-we-ai.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "how-we-ai"
    },
    "mdx": "var Component=(()=>{var d=Object.create;var r=Object.defineProperty;var y=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),k=(t,e)=>{for(var o in e)r(t,o,{get:e[o],enumerable:!0})},s=(t,e,o,i)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let a of p(e))!g.call(t,a)&&a!==o&&r(t,a,{get:()=>e[a],enumerable:!(i=y(e,a))||i.enumerable});return t};var w=(t,e,o)=>(o=t!=null?d(m(t)):{},s(e||!t||!t.__esModule?r(o,\"default\",{value:t,enumerable:!0}):o,t)),I=t=>s(r({},\"__esModule\",{value:!0}),t);var h=f((P,l)=>{l.exports=_jsx_runtime});var b={};k(b,{default:()=>u});var n=w(h());function c(t){let e={a:\"a\",code:\"code\",h2:\"h2\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",ul:\"ul\",...t.components},{Image:o}=e;return o||v(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"Artificial Intelligence (AI) has undeniably transformed the technology landscape in the past few years. From OpenAI to Llama 2, AI has permeated every facet of our lives. Yet, as with any groundbreaking technology, developers face unique challenges when working on AI projects. This is where Unkey comes in. Unkey's API management platform helps developers secure, manage, and scale their APIs.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"what-is-unkey\",children:\"What is Unkey?\"}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey is an open source API management platform, that provides a low-latency option to create, manage and revoke API Keys for your API. We offer features like:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Rate limiting per key\"}),`\n`,(0,n.jsx)(e.li,{children:\"Temporary keys\"}),`\n`,(0,n.jsx)(e.li,{children:\"Limited use keys\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey also offers seamless integration with popular programming languages making it easier for developers to work in an environment they are comfortable with. Whether you are a Typescript, Python, or a Go developer you can use Unkey in minutes.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"how-unkey-can-help-ai-projects\",children:\"How Unkey Can Help AI Projects\"}),`\n`,(0,n.jsx)(e.p,{children:\"When it comes to AI project development, Unkey is a game-changer. It aids in streamlining the API development process. With our robust features, Unkey allows developers to focus on the creative aspects of AI development rather than getting bogged down with how to secure their APIs.\"}),`\n`,(0,n.jsx)(e.p,{children:\"For instance, consider developing an application that interacts with OpenAPI, you want users to be able to use your service but you don't want them to be able to abuse it. If you handle this yourself you need to think about:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:\"How do I identify the user\"}),`\n`,(0,n.jsx)(e.li,{children:\"Implement a rate limiting system.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Implement a token system to allow them to use X tokens\"}),`\n`,(0,n.jsx)(e.li,{children:\"Make sure it's fast.\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"With Unkey you can simplify this by adding in a single API call to create a user's API Key with both a token system and rate limiting built in. Below is an example of a cURL request that creates a key with rate limiting of 10 requests, that refill at a rate of 1 request per second. The key also has 100 total requests allowed before they can no longer access the resource.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`curl --request POST \\\\\n  --url https://api.unkey.dev/v1/keys.createKey \\\\\n  --header 'Authorization: Bearer <UNKEY>' \\\\\n  --header 'Content-Type: application/json' \\\\\n  --data '{\n\t\"apiId\":\"<API_ID>\",\n\t\"ratelimit\":{\n\t\t\"type\":\"fast\",\n\t\t\"limit\":10,\n\t\t\"refillRate\": 1,\n\t\t\"refillInterval\": 1000\n\t},\n\t\"remaining\": 100\n}'\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"The response includes the key itself, which you should pass on to your user and a keyId, which you can use later to update or revoke the key. Don\\u2019t worry about storing the keyId, you can always query it later from Unkey when you need it.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-jsx\",children:`{\n  \"key\": \"prefix_5AkwpYpIHntGBpTHLqKg\",\n  \"keyId\": \"key_123\"\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"So now you have an API key, but how does that help you protect your AI project? Unkey provides a verify endpoint, this endpoint can verify a request in under 40 ms and provide you with the details you need to make a business decision. For example:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`curl --request POST \\\\\n  --url https://api.unkey.dev/v1/keys.verifyKey \\\\\n  --header 'Content-Type: application/json' \\\\\n  --data '{\n    \"key\":\"THE_NEW_KEY\"\n  }'\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"This returns the following in the body:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`{\n   \"valid\":true,\n   \"remaining\":99,\n   \"ratelimit\":{\n      \"limit\":10,\n      \"remaining\":9,\n      \"reset\":1690065988700\n   }\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:'As you see Unkey returns \"valid\": true which allows you to make an immediate business decision, if it is true let them access the resource, if it is false deny them access. On top of that, we return the total remaining requests, which you could return to your user, and finally their rate limits.'}),`\n`,(0,n.jsx)(e.p,{children:\"Even though these examples are in cURL we have a typescript SDK and community SDKs in Go, Python, Elixir, and a Nuxt module.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"how-to-start-using-unkey-for-your-ai-projects\",children:\"How to Start Using Unkey for Your AI Projects\"}),`\n`,(0,n.jsx)(e.p,{children:\"Starting with Unkey for your AI projects is straightforward. To begin, sign up for your free Unkey account. As soon as you create your account you will be asked to create your workspace. Give it a name, and a slug. The name is shown only to you and not to your users.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Next, you need to create a root API Key, this is a special API Key that allows you full read and write access to all current and future resources. It\\u2019s important to keep this API Key safe, as it allows you to create, revoke, validate, and delete API Keys. You can do this by selecting settings and then clicking the \\u201CCreate New Key\\u201D button.\"}),`\n`,(0,n.jsx)(o,{src:\"/images/blog-images/ai-post/create-root-key.png\",alt:\"Create Root Key\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"Then you can create your first API which allows you to track usage as well as segment keys, the name you choose is also not visible to users.\"}),`\n`,(0,n.jsx)(o,{src:\"/images/blog-images/ai-post/create-api.png\",alt:\"Create API\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"You are now ready to integrate Unkey into your code! If you are manually issuing keys you can do that right from our dashboard, otherwise you can start reading our \",(0,n.jsx)(e.a,{href:\"http://unkey.com/docs\",children:\"documentation\"}),\" and learn about everything we have to offer.\"]})]})}function u(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(c,{...t})}):c(t)}function v(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return I(b);})();\n;return Component;",
    "slug": "how-we-ai",
    "url": "/blog/how-we-ai",
    "tableOfContents": [
      {
        "level": 2,
        "text": "What is Unkey?",
        "slug": "what-is-unkey"
      },
      {
        "level": 2,
        "text": "How Unkey Can Help AI Projects",
        "slug": "how-unkey-can-help-ai-projects"
      },
      {
        "level": 2,
        "text": "How to Start Using Unkey for Your AI Projects",
        "slug": "how-to-start-using-unkey-for-your-ai-projects"
      }
    ]
  },
  {
    "content": "<Image src=\"/images/blog-images/covers/identities-beta.png\"/>\n\nToday we are excited to announce the beta release of Identities, a new feature that allows you to group and manage multiple keys to better match your tenant structure.\n\nUp until today you had the option to assign an `ownerId` to your keys, which allowed you to filter keys by a specific owner. This was useful for fetching keys by user or organisation via the API, but it didn't provide any additional functionality.\n\nWith Identities, you can now not only group keys together, but also share metadata and ratelimits across keys.\n\n## Shared Metadata\n\nMetadata can be used to store additional information about the identity that you need access to in your API handler. The identities' metadata is returned as part of the verification response and can be used to make decisions based on the identity. You could previously do this with key metadata but had to duplicate it to every key, which becomes annoying when you need to make changes later.\n\n## Shared Ratelimits\n\nSharing ratelimits across multiple keys allows you to ensure a single user or organisation doesn't exceed the rate limits you have set, regardless of how many keys they have. All of their keys will be subject to the same rate limits, which makes it easier to manage and enforce rate limits across your application.\n\nExample:\nYou sold a subscription to a customer that includes 100k requests per day, but they want to use 4 keys for different parts of their system. With identities you can share the ratelimit across all keys, so that regardless of which key they use, they won't exceed the 1000 requests per day.\n\n\n\n## Multiple Ratelimits\n\nRatelimiting is all about protecting your services or your wallet. We've heard you and we've made ratelimiting even more flexible.\n\nUsing multiple limits opens up a whole new world of possibilities. You can now set different limits for different use cases, such as:\n\n### Example: Burst Ratelimiting\n\nA single limit is often not enough to create a good user experience while keeping your API protected.\n\nFor example, you might want to limit the number of requests per minute to allow for some bursts and the number of requests per day to limit the total cost.\n\nYou can now do this by configuring 2 or more limits on the identity:\n\n- A burst level of 100 per minute\n- A base level of 10,000 per day\n  Whichever limit is reached first will be enforced and the request will be rejected.\n\n```typescript\n{\n  ratelimits: [\n    {\n      name: \"burst\"\n      limit: 100,\n      duration: 60000 // 1 minute\n    },\n    {\n      name: \"base\"\n      limit: 10000,\n      duration: 86400000 // 1 day\n    }\n  ]\n}\n\n```\n\n### Example: LLM Token usage\n\nThe most common way of limiting is setting a limit on how many requests they may do in a certain timeframe, but you can also limit based on other metrics, such as requested tokens for LLMs.\n\nIn this example we offer LLM inference as a service via multiple models and want to limit the number of requests and tokens consumed by each model.\n\n```typescript\n{\n  ratelimits: [\n    // baseline ratelimit of 100 requests per second\n    {\n      name: \"requests::api\",\n      limit: 100,\n      duration: 1000,\n    },\n\n    // llama-v3p1-405b-instruct\n    {\n      // Limit the number of requests to 100 per minute\n      name: \"requests::llama-v3p1-405b-instruct\",\n      limit: 100,\n      duration: 60000,\n    },\n    {\n      // Limit the number of tokens consumed to 100k per hour\n      name: \"tokens::llama-v3p1-405b-instruct\",\n      limit: 100000,\n      duration: 60000,\n    },\n\n    // mixtral-8x22b-instruct\n    // Assuming this one is cheaper, we can set higher limits\n    {\n      // Limit the number of requests to 1000 per minute\n      name: \"requests::mixtral-8x22b-instruct\",\n      limit: 1000,\n      duration: 60000,\n    },\n    {\n      // Limit the number of tokens consumed to 20mil per hour\n      name: \"tokens::mixtral-8x22b-instruct\",\n      limit: 20_000_000,\n      duration: 60000,\n    },\n  },\n}\n```\n\n## How it works\n\nAn identity consists of an `externalId`, `meta` and `ratelimits`.\n\n- `externalId`: A unique identifier for the identity. This can be a user ID, organisation ID, or any other identifier that makes sense for your use case.\n- `meta`: A JSON object that can store any additional information about the identity.\n- `ratelimits`: A list of ratelimits that should be shared across all keys in the identity.\n\nWhen you create a key, you can now assign it to an identity by providing the `identityId` or `externalId` in the key creation request. This will automatically group the key under the specified identity.\n\n```json\n{\n  \"identityId\": \"id_123\",\n  \"externalId\": \"user_123\"\n  // ...\n}\n```\n\n## Verifying keys\n\nIf your identity is configured with metadata and/or ratelimits, you can now [verify a key](https://www.unkey.com/docs/api-reference/keys/verify).\n\nTo use the configured ratelimits, you'll need to specify which one you want to use in the `ratelimits` parameter. You can optionally specify a `cost` for each ratelimit, which will be deducted from the ratelimit when the request is verified.\n\n```curl\ncurl --request POST \\\n  --url https://api.unkey.dev/v1/keys.verifyKey \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n  \"apiId\": \"api_1234\",\n  \"key\": \"sk_1234\",\n  \"ratelimits\": [\n    { \"name\": \"requests::api\" },\n    { \"name\": \"requests::llama-v3p1-405b-instruct\" },\n    { \"name\": \"tokens::llama-v3p1-405b-instruct\", \"cost\": 8152 }\n  ]\n}'\n```\n\nThe response will include the metadata of the identity, which you can use to make decisions in your API handler.\n\n```typescript\n{\n  // ...\n  \"valid\": true,\n  \"identity\": {\n    \"id\": \"id_123\",\n    \"externalId\": \"user_123\",\n    \"meta\": {\n      \"stripeCustomerId\": \"cus_123\",\n    }\n  }\n}\n```\n\n\n## Roadmap to GA\n\nStay tuned for improved analytics coming soon, allowing you to get an accurate overview of what each identity is doing.\n\nIdentities are in beta and only available via the API at the moment. We are working on adding support for identities in the dashboard.",
    "title": "Identities (beta)",
    "description": "Manage multiple keys under one user or organisation, with shared ratelimits and analytics.",
    "author": "andreas",
    "date": "2024-07-30",
    "tags": [
      "product"
    ],
    "image": "/images/blog-images/covers/identities-beta.png",
    "_meta": {
      "filePath": "identities-beta.mdx",
      "fileName": "identities-beta.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "identities-beta"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var r=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var y=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var g=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var i in e)r(t,i,{get:e[i],enumerable:!0})},s=(t,e,i,o)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let a of y(e))!f.call(t,a)&&a!==i&&r(t,a,{get:()=>e[a],enumerable:!(o=m(e,a))||o.enumerable});return t};var b=(t,e,i)=>(i=t!=null?u(p(t)):{},s(e||!t||!t.__esModule?r(i,\"default\",{value:t,enumerable:!0}):i,t)),k=t=>s(r({},\"__esModule\",{value:!0}),t);var d=g((q,l)=>{l.exports=_jsx_runtime});var x={};w(x,{default:()=>h});var n=b(d());function c(t){let e={a:\"a\",code:\"code\",h2:\"h2\",h3:\"h3\",li:\"li\",p:\"p\",pre:\"pre\",ul:\"ul\",...t.components},{Image:i}=e;return i||v(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i,{src:\"/images/blog-images/covers/identities-beta.png\"}),`\n`,(0,n.jsx)(e.p,{children:\"Today we are excited to announce the beta release of Identities, a new feature that allows you to group and manage multiple keys to better match your tenant structure.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Up until today you had the option to assign an \",(0,n.jsx)(e.code,{children:\"ownerId\"}),\" to your keys, which allowed you to filter keys by a specific owner. This was useful for fetching keys by user or organisation via the API, but it didn't provide any additional functionality.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"With Identities, you can now not only group keys together, but also share metadata and ratelimits across keys.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"shared-metadata\",children:\"Shared Metadata\"}),`\n`,(0,n.jsx)(e.p,{children:\"Metadata can be used to store additional information about the identity that you need access to in your API handler. The identities' metadata is returned as part of the verification response and can be used to make decisions based on the identity. You could previously do this with key metadata but had to duplicate it to every key, which becomes annoying when you need to make changes later.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"shared-ratelimits\",children:\"Shared Ratelimits\"}),`\n`,(0,n.jsx)(e.p,{children:\"Sharing ratelimits across multiple keys allows you to ensure a single user or organisation doesn't exceed the rate limits you have set, regardless of how many keys they have. All of their keys will be subject to the same rate limits, which makes it easier to manage and enforce rate limits across your application.\"}),`\n`,(0,n.jsx)(e.p,{children:`Example:\nYou sold a subscription to a customer that includes 100k requests per day, but they want to use 4 keys for different parts of their system. With identities you can share the ratelimit across all keys, so that regardless of which key they use, they won't exceed the 1000 requests per day.`}),`\n`,(0,n.jsx)(e.h2,{id:\"multiple-ratelimits\",children:\"Multiple Ratelimits\"}),`\n`,(0,n.jsx)(e.p,{children:\"Ratelimiting is all about protecting your services or your wallet. We've heard you and we've made ratelimiting even more flexible.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Using multiple limits opens up a whole new world of possibilities. You can now set different limits for different use cases, such as:\"}),`\n`,(0,n.jsx)(e.h3,{id:\"example-burst-ratelimiting\",children:\"Example: Burst Ratelimiting\"}),`\n`,(0,n.jsx)(e.p,{children:\"A single limit is often not enough to create a good user experience while keeping your API protected.\"}),`\n`,(0,n.jsx)(e.p,{children:\"For example, you might want to limit the number of requests per minute to allow for some bursts and the number of requests per day to limit the total cost.\"}),`\n`,(0,n.jsx)(e.p,{children:\"You can now do this by configuring 2 or more limits on the identity:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"A burst level of 100 per minute\"}),`\n`,(0,n.jsx)(e.li,{children:`A base level of 10,000 per day\nWhichever limit is reached first will be enforced and the request will be rejected.`}),`\n`]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`{\n  ratelimits: [\n    {\n      name: \"burst\"\n      limit: 100,\n      duration: 60000 // 1 minute\n    },\n    {\n      name: \"base\"\n      limit: 10000,\n      duration: 86400000 // 1 day\n    }\n  ]\n}\n\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"example-llm-token-usage\",children:\"Example: LLM Token usage\"}),`\n`,(0,n.jsx)(e.p,{children:\"The most common way of limiting is setting a limit on how many requests they may do in a certain timeframe, but you can also limit based on other metrics, such as requested tokens for LLMs.\"}),`\n`,(0,n.jsx)(e.p,{children:\"In this example we offer LLM inference as a service via multiple models and want to limit the number of requests and tokens consumed by each model.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`{\n  ratelimits: [\n    // baseline ratelimit of 100 requests per second\n    {\n      name: \"requests::api\",\n      limit: 100,\n      duration: 1000,\n    },\n\n    // llama-v3p1-405b-instruct\n    {\n      // Limit the number of requests to 100 per minute\n      name: \"requests::llama-v3p1-405b-instruct\",\n      limit: 100,\n      duration: 60000,\n    },\n    {\n      // Limit the number of tokens consumed to 100k per hour\n      name: \"tokens::llama-v3p1-405b-instruct\",\n      limit: 100000,\n      duration: 60000,\n    },\n\n    // mixtral-8x22b-instruct\n    // Assuming this one is cheaper, we can set higher limits\n    {\n      // Limit the number of requests to 1000 per minute\n      name: \"requests::mixtral-8x22b-instruct\",\n      limit: 1000,\n      duration: 60000,\n    },\n    {\n      // Limit the number of tokens consumed to 20mil per hour\n      name: \"tokens::mixtral-8x22b-instruct\",\n      limit: 20_000_000,\n      duration: 60000,\n    },\n  },\n}\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"how-it-works\",children:\"How it works\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"An identity consists of an \",(0,n.jsx)(e.code,{children:\"externalId\"}),\", \",(0,n.jsx)(e.code,{children:\"meta\"}),\" and \",(0,n.jsx)(e.code,{children:\"ratelimits\"}),\".\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.code,{children:\"externalId\"}),\": A unique identifier for the identity. This can be a user ID, organisation ID, or any other identifier that makes sense for your use case.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.code,{children:\"meta\"}),\": A JSON object that can store any additional information about the identity.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.code,{children:\"ratelimits\"}),\": A list of ratelimits that should be shared across all keys in the identity.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"When you create a key, you can now assign it to an identity by providing the \",(0,n.jsx)(e.code,{children:\"identityId\"}),\" or \",(0,n.jsx)(e.code,{children:\"externalId\"}),\" in the key creation request. This will automatically group the key under the specified identity.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-json\",children:`{\n  \"identityId\": \"id_123\",\n  \"externalId\": \"user_123\"\n  // ...\n}\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"verifying-keys\",children:\"Verifying keys\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"If your identity is configured with metadata and/or ratelimits, you can now \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/api-reference/keys/verify\",children:\"verify a key\"}),\".\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"To use the configured ratelimits, you'll need to specify which one you want to use in the \",(0,n.jsx)(e.code,{children:\"ratelimits\"}),\" parameter. You can optionally specify a \",(0,n.jsx)(e.code,{children:\"cost\"}),\" for each ratelimit, which will be deducted from the ratelimit when the request is verified.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-curl\",children:`curl --request POST \\\\\n  --url https://api.unkey.dev/v1/keys.verifyKey \\\\\n  --header 'Content-Type: application/json' \\\\\n  --data '{\n  \"apiId\": \"api_1234\",\n  \"key\": \"sk_1234\",\n  \"ratelimits\": [\n    { \"name\": \"requests::api\" },\n    { \"name\": \"requests::llama-v3p1-405b-instruct\" },\n    { \"name\": \"tokens::llama-v3p1-405b-instruct\", \"cost\": 8152 }\n  ]\n}'\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"The response will include the metadata of the identity, which you can use to make decisions in your API handler.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`{\n  // ...\n  \"valid\": true,\n  \"identity\": {\n    \"id\": \"id_123\",\n    \"externalId\": \"user_123\",\n    \"meta\": {\n      \"stripeCustomerId\": \"cus_123\",\n    }\n  }\n}\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"roadmap-to-ga\",children:\"Roadmap to GA\"}),`\n`,(0,n.jsx)(e.p,{children:\"Stay tuned for improved analytics coming soon, allowing you to get an accurate overview of what each identity is doing.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Identities are in beta and only available via the API at the moment. We are working on adding support for identities in the dashboard.\"})]})}function h(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(c,{...t})}):c(t)}function v(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return k(x);})();\n;return Component;",
    "slug": "identities-beta",
    "url": "/blog/identities-beta",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Shared Metadata",
        "slug": "shared-metadata"
      },
      {
        "level": 2,
        "text": "Shared Ratelimits",
        "slug": "shared-ratelimits"
      },
      {
        "level": 2,
        "text": "Multiple Ratelimits",
        "slug": "multiple-ratelimits"
      },
      {
        "level": 3,
        "text": "Example: Burst Ratelimiting",
        "slug": "example-burst-ratelimiting"
      },
      {
        "level": 3,
        "text": "Example: LLM Token usage",
        "slug": "example-llm-token-usage"
      },
      {
        "level": 2,
        "text": "How it works",
        "slug": "how-it-works"
      },
      {
        "level": 2,
        "text": "Verifying keys",
        "slug": "verifying-keys"
      },
      {
        "level": 2,
        "text": "Roadmap to GA",
        "slug": "roadmap-to-ga"
      }
    ]
  },
  {
    "content": "The sign-in flow for your application is the gateway and sometimes the first impression; one of the biggest issues is the returning user. The return user often gets presented with a screen that looks similar to this:\n\n<Image src=\"/images/blog-images/auth-experience/sign-in.png\" alt=\"sign in example\" width=\"1920\" height=\"1080\"/>\n\nThe problem is, what account did I use to sign up for this account? Was it Github? Was it Google? Or did I use my email? In great applications, Unkey included, account linking is used behind the scenes, which can help mitigate this issue.\n\n## What is Account linking?\n\nAccount linking allows developers to use the email provided and match that to a previously signed-up account, for example:\n\n1. A user signs up with a GitHub account, which has the email address james@unkey.dev\n2. The same user returns to the sign-in page and doesnt remember, so they select Google and james@unkey.dev\n3. During the flow, the developer identifies this user has signed up before and links the account together, placing the user on the correct dashboard.\n\nThe main issue with relying only on account linking is that users potentially use different emails for accounts. For example, my GitHub primary email is my personal email, and I use my work email as my Google account. So, if I accidentally select the wrong option, I will go through the onboarding experience, which is frustrating as a user.\n\n## Adding indicator to improve the User Experience\n\nTo improve the experience futher we can add an indicator to the sign-in page to show the user the last method they used to access our application.\n\n<Image src=\"/images/blog-images/auth-experience/last-used.png\" alt=\"sign in example\" width=\"1920\" height=\"1080\"/>\n\n### How can you implement this?\n\n>If you want to see an example that implements the code we without any auth provider check out this [code sandbox](https://codesandbox.io/p/devbox/jh34y6) out.\n\nFirst, we must add logic to the sign-in and sign-up flow to implement the Last used tag. The example below shows what a Clerk custom flow might look like and what we use at Unkey.\n\n```tsx\nconst oauthSignIn = async (provider: OAuthStrategy) => {\n    if (!signInLoaded) {\n      return null;\n    }\n    try {\n      setIsLoading(provider);\n      await signIn.authenticateWithRedirect({\n        strategy: provider,\n        redirectUrl: \"/auth/sso-callback\",\n        redirectUrlComplete: \"/apis\",\n      });\n    } catch (err) {\n      console.error(err);\n      setIsLoading(null);\n      toast.error((err as Error).message);\n    }\n  };\n```\n\nAs you can see from the example code above, we know what provider the end user is attempting to sign in with, so now we can store this and provide a UI update. The next step is implementing a hook to handle persisting and reading from local storage. We could write the hooks ourselves at Unkey. We opted to use usehook-ts, an excellent lightweight set of typesafe hooks with a small bundle size.\n\n```sh\nnpm install usehook-ts\n```\n\nNow, we can write our function.\n\n```tsx\n\"use client\";\nimport { useLocalStorage } from \"usehook-ts\";\n\nexport function useLastUsed() {\n  return useLocalStorage<\"github\" | \"google\" | \"email\" | undefined>(\"last_unkey_login\", undefined);\n}\n```\n\nThis function allows us to read and write our sign-in options to local storage. I will show how it is used in a second, but first, we need a UI element to show to the user. We opted for a simple text span displaying the last used, but you could display an icon or any text you prefer.\n\n```tsx\nexport const LastUsed: React.FC = () => {\n  return <span className=\"absolute right-4 text-xs text-content-subtle\">Last used</span>;\n};\n```\n\nNow, we have all the elements to show our end users what sign-in method they used previously. To do this, we can update our sign-in code to include the hook similar to setState\n\n```tsx\nconst [lastUsed, setLastUsed] = useLastUsed();\n\nconst oauthSignIn = async (provider: OAuthStrategy) => {\n    if (!signInLoaded) {\n      return null;\n    }\n    try {\n      setIsLoading(provider);\n      await signIn.authenticateWithRedirect({\n        strategy: provider,\n        redirectUrl: \"/auth/sso-callback\",\n        redirectUrlComplete: \"/apis\",\n      });\n      setLastUsed(provider === \"oauth_google\" ? \"google\" : \"github\");\n    } catch (err) {\n      console.error(err);\n      setIsLoading(null);\n      toast.error((err as Error).message);\n    }\n\n  };\n  ```\nThe final step is to show the user that it was the last used. Below is how we implemented it at Unkey: we placed it next to the button.\n\n```tsx\n<OAuthButton onClick={() => oauthSignIn(\"oauth_google\")}>\n  {isLoading === \"oauth_google\" ? (\n    <Loading className=\"w-6 h-6\" />\n    ) : (\n       <Google className=\"w-6 h-6\" />\n    )}\n  Google {lastUsed === \"google\" ? <LastUsed /> : null}\n</OAuthButton>\n```\nIn conclusion, improving the authentication user experience is crucial for ensuring a smooth and hassle-free sign-in process for returning users. By implementing account linking and adding a \"last used\" feature, we can address the issue of users potentially using different emails for their accounts and minimize the frustration of going through the onboarding experience multiple times.\n\n<Image src=\"/images/blog-images/auth-experience/discord.png\" alt=\"sign in example\" width=\"1920\" height=\"1080\"/>\n\nThese improvements benefit the end users and contribute to the application's success by creating a positive first impression and increasing user satisfaction. If you'd like to check out the full implementation you can find it in the [Unkey repository](https://github.com/unkeyed/unkey/).",
    "title": "Improve your authentication UX",
    "description": "Improving your authentication UX can allow for a smoother and more satisfying for returning user",
    "author": "james",
    "date": "2024-09-23",
    "tags": [
      "tutorials"
    ],
    "image": "/images/blog-images/auth-experience/og-image.png",
    "_meta": {
      "filePath": "improve-auth-experience.mdx",
      "fileName": "improve-auth-experience.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "improve-auth-experience"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,w=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),y=(t,e)=>{for(var i in e)o(t,i,{get:e[i],enumerable:!0})},r=(t,e,i,a)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let s of p(e))!w.call(t,s)&&s!==i&&o(t,s,{get:()=>e[s],enumerable:!(a=g(e,s))||a.enumerable});return t};var x=(t,e,i)=>(i=t!=null?u(m(t)):{},r(e||!t||!t.__esModule?o(i,\"default\",{value:t,enumerable:!0}):i,t)),k=t=>r(o({},\"__esModule\",{value:!0}),t);var h=f((U,l)=>{l.exports=_jsx_runtime});var v={};y(v,{default:()=>d});var n=x(h());function c(t){let e={a:\"a\",blockquote:\"blockquote\",code:\"code\",h2:\"h2\",h3:\"h3\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",...t.components},{Image:i}=e;return i||b(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"The sign-in flow for your application is the gateway and sometimes the first impression; one of the biggest issues is the returning user. The return user often gets presented with a screen that looks similar to this:\"}),`\n`,(0,n.jsx)(i,{src:\"/images/blog-images/auth-experience/sign-in.png\",alt:\"sign in example\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"The problem is, what account did I use to sign up for this account? Was it Github? Was it Google? Or did I use my email? In great applications, Unkey included, account linking is used behind the scenes, which can help mitigate this issue.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"what-is-account-linking\",children:\"What is Account linking?\"}),`\n`,(0,n.jsx)(e.p,{children:\"Account linking allows developers to use the email provided and match that to a previously signed-up account, for example:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[\"A user signs up with a GitHub account, which has the email address \",(0,n.jsx)(e.a,{href:\"mailto:james@unkey.dev\",children:\"james@unkey.dev\"})]}),`\n`,(0,n.jsxs)(e.li,{children:[\"The same user returns to the sign-in page and doesn\\u2019t remember, so they select Google and \",(0,n.jsx)(e.a,{href:\"mailto:james@unkey.dev\",children:\"james@unkey.dev\"})]}),`\n`,(0,n.jsx)(e.li,{children:\"During the flow, the developer identifies this user has signed up before and links the account together, placing the user on the correct dashboard.\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"The main issue with relying only on account linking is that users potentially use different emails for accounts. For example, my GitHub primary email is my personal email, and I use my work email as my Google account. So, if I accidentally select the wrong option, I will go through the onboarding experience, which is frustrating as a user.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"adding-indicator-to-improve-the-user-experience\",children:\"Adding indicator to improve the User Experience\"}),`\n`,(0,n.jsx)(e.p,{children:\"To improve the experience futher we can add an indicator to the sign-in page to show the user the last method they used to access our application.\"}),`\n`,(0,n.jsx)(i,{src:\"/images/blog-images/auth-experience/last-used.png\",alt:\"sign in example\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.h3,{id:\"how-can-you-implement-this\",children:\"How can you implement this?\"}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsxs)(e.p,{children:[\"If you want to see an example that implements the code we without any auth provider check out this \",(0,n.jsx)(e.a,{href:\"https://codesandbox.io/p/devbox/jh34y6\",children:\"code sandbox\"}),\" out.\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"First, we must add logic to the sign-in and sign-up flow to implement the \\u201CLast used\\u201D tag. The example below shows what a Clerk custom flow might look like and what we use at Unkey.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-tsx\",children:`const oauthSignIn = async (provider: OAuthStrategy) => {\n    if (!signInLoaded) {\n      return null;\n    }\n    try {\n      setIsLoading(provider);\n      await signIn.authenticateWithRedirect({\n        strategy: provider,\n        redirectUrl: \"/auth/sso-callback\",\n        redirectUrlComplete: \"/apis\",\n      });\n    } catch (err) {\n      console.error(err);\n      setIsLoading(null);\n      toast.error((err as Error).message);\n    }\n  };\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"As you can see from the example code above, we know what provider the end user is attempting to sign in with, so now we can store this and provide a UI update. The next step is implementing a hook to handle persisting and reading from local storage. We could write the hooks ourselves at Unkey. We opted to use usehook-ts, an excellent lightweight set of typesafe hooks with a small bundle size.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sh\",children:`npm install usehook-ts\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Now, we can write our function.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-tsx\",children:`\"use client\";\nimport { useLocalStorage } from \"usehook-ts\";\n\nexport function useLastUsed() {\n  return useLocalStorage<\"github\" | \"google\" | \"email\" | undefined>(\"last_unkey_login\", undefined);\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"This function allows us to read and write our sign-in options to local storage. I will show how it is used in a second, but first, we need a UI element to show to the user. We opted for a simple text span displaying the last used, but you could display an icon or any text you prefer.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-tsx\",children:`export const LastUsed: React.FC = () => {\n  return <span className=\"absolute right-4 text-xs text-content-subtle\">Last used</span>;\n};\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Now, we have all the elements to show our end users what sign-in method they used previously. To do this, we can update our sign-in code to include the hook similar to setState\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-tsx\",children:`const [lastUsed, setLastUsed] = useLastUsed();\n\nconst oauthSignIn = async (provider: OAuthStrategy) => {\n    if (!signInLoaded) {\n      return null;\n    }\n    try {\n      setIsLoading(provider);\n      await signIn.authenticateWithRedirect({\n        strategy: provider,\n        redirectUrl: \"/auth/sso-callback\",\n        redirectUrlComplete: \"/apis\",\n      });\n      setLastUsed(provider === \"oauth_google\" ? \"google\" : \"github\");\n    } catch (err) {\n      console.error(err);\n      setIsLoading(null);\n      toast.error((err as Error).message);\n    }\n\n  };\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"The final step is to show the user that it was the \\u201Clast used.\\u201D Below is how we implemented it at Unkey: we placed it next to the button.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-tsx\",children:`<OAuthButton onClick={() => oauthSignIn(\"oauth_google\")}>\n  {isLoading === \"oauth_google\" ? (\n    <Loading className=\"w-6 h-6\" />\n    ) : (\n       <Google className=\"w-6 h-6\" />\n    )}\n  Google {lastUsed === \"google\" ? <LastUsed /> : null}\n</OAuthButton>\n`})}),`\n`,(0,n.jsx)(e.p,{children:'In conclusion, improving the authentication user experience is crucial for ensuring a smooth and hassle-free sign-in process for returning users. By implementing account linking and adding a \"last used\" feature, we can address the issue of users potentially using different emails for their accounts and minimize the frustration of going through the onboarding experience multiple times.'}),`\n`,(0,n.jsx)(i,{src:\"/images/blog-images/auth-experience/discord.png\",alt:\"sign in example\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"These improvements benefit the end users and contribute to the application's success by creating a positive first impression and increasing user satisfaction. If you'd like to check out the full implementation you can find it in the \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/unkey/\",children:\"Unkey repository\"}),\".\"]})]})}function d(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(c,{...t})}):c(t)}function b(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return k(v);})();\n;return Component;",
    "slug": "improve-auth-experience",
    "url": "/blog/improve-auth-experience",
    "tableOfContents": [
      {
        "level": 2,
        "text": "What is Account linking?",
        "slug": "what-is-account-linking"
      },
      {
        "level": 2,
        "text": "Adding indicator to improve the User Experience",
        "slug": "adding-indicator-to-improve-the-user-experience"
      },
      {
        "level": 3,
        "text": "How can you implement this?",
        "slug": "how-can-you-implement-this"
      }
    ]
  },
  {
    "content": "Today, we are introducing standalone ratelimiting. With this feature, you can rate limit anything while still leveraging the power of Unkey. Our ratelimiting feature works similarly to our keys, providing low global latency and detailed analytics. Moreover, you can configure overrides for specific identifiers, giving you more flexibility.\n\nYou can [check out a demo](https://unkey.com/ratelimit) that shows our synchronous and asynchronous implementation versus a Redis-based ratelimiter.\n\n## Using our ratelimiter\n\nTo use our rate limit feature, you can use our API directly, an existing package like @unkey/api, or our new package @unkey/ratelimit, which is completely standalone from the other features in our API. The examples below will use the new package to keep things simple.\n\n### Configure your ratelimiter\n\nFirstly, you will want to configure the ratelimiter. Unkey uses namespaces to allow you to separate different parts of your application and have isolated limits for them. If the namespace doesn't exist, we will create it with the first request. For example, each of your tRPC routes could be a namespace. In this example, we use our `ai.generate` route.\n\n```typescript\nimport { Ratelimit }from \"@unkey/ratelimit\"\n\nconst unkey = new Ratelimit({\n  rootKey: process.env.UNKEY_ROOT_KEY,\n  namespace: \"ai.generate\",\n  limit: 10,\n  duration: \"30s\",\n});\n```\n\n### Using the ratelimiter\n\nWith the ratelimiter now configured, we can use it in a route to decide whether to proceed with handling the request or reject it with a 429 response. You will need to pass an identifier for the request; this could be anything, but commonly, it is a userId or an IP address.\n\n```typescript\nasync function handler(request) {\n  const identifier = request.getUserId();\n\n  const ratelimit = await unkey.limit(identifier);\n  if (!ratelimit.success) {\n    return new Response(\"try again later\", { status: 429 });\n  }\n  // handle the request here\n}\n```\n\n## Advanced usage\n\nRatelimting offers additional options to provide more advanced configurations, including cost, async requests, and resource audit logging. We also provide configurable overrides in the dashboard so specific resources with an identifier can have limits without adding additional code.\n\n### Overrides\n\nConfigurable overrides allow you to tell Unkey how to handle specific identifiers. For example, you may have a user or an IP that requires higher limits than your normal flows. Instead of having to write logic into your application, you can set the identifier in the dashboard, and we will handle it for you.\n\n<Image src=\"/images/blog-images/ratelimiting/overrides.png\" alt=\"Overrides example\" width=\"1920\" height=\"1080\"/>\n\n### async requests\n\nYou can enable async requests, which will sacrifice minimal accuracy and improve the latency even further. Our accuracy when using async requests is around 97%, but we can reduce the latency over a synchronous request by 30ms. You can enable this in the configuration or for specific usage of the rate limiter.\n\n**Ratelimit configuriation**\n\n```typescript\nconst unkey = new Ratelimit({\n  // ...\n  async: true,\n});\n```\n\n**Using the ratelimiter**\n\n```typescript\nasync function handler(request: NextApiRequest) {\n  const identifier = request.getUserId();\n\n  const ratelimit = await unkey.limit(identifier, {\n    async: true,\n  });\n  if (!ratelimit.success) {\n    return new Response(\"try again later\", { status: 429 });\n  }\n  // handle the request here\n}\n```\n\n### Cost configuration\n\nSometimes, you may have an expensive resource. We allow you to set a cost for the request, and we will deduct that cost from the current window and reject a request if it exceeds the allowed amount. For example:\n\n```typescript\nasync function handler(request: NextApiRequest) {\n  const identifier = request.getUserId();\n\n  const ratelimit = await unkey.limit(identifier, {\n    cost: 4,\n  });\n  if (!ratelimit.success) {\n    return new Response(\"try again later\", { status: 429 });\n  }\n  // handle the request here\n}\n```\n\nThis request would now cost 4 tokens versus 1, allowing you to be flexible about handling the expensive resources in your application.\n\n### Resource Audit logging\n\nUnkey provides audit logging out of the box at no additional cost to you. In cases where you want to create a paper trail, you can do by providing the ratelimit request with resource details, for example:\n\n```typescript\nasync function handler(request: NextApiRequest) {\n  const identifier = request.getUserId();\n\n  const ratelimit = await unkey.limit(identifier, {\n    resources: [\n      {\n        id: \"id_123\",\n        name: \"unkey\",\n        type: \"ai.generate\",\n      },\n    ],\n  });\n  if (!ratelimit.success) {\n    return new Response(\"try again later\", { status: 429 });\n  }\n  // handle the request here\n}\n```\n\nSending a request with a resource will provide an audit log in our dashboard that you can use; below is how it looks:\n\n<Image src=\"/images/blog-images/ratelimiting/audit.png\" alt=\"Audit Log example\" width=\"1920\" height=\"1080\"/>\n\n## Onboarding flow\n\nIf you are new to Unkey, we have a new onboarding flow for ratelimiting that will get you up and running in seconds. After you create your workspace, you will be asked if you want to use API keys or ratelimiting.\n\n<Image src=\"/images/blog-images/ratelimiting/onboarding-1.png\" alt=\"Options of keys or ratelimiting\" width=\"1920\" height=\"1080\"/>\n\nOnce you select ratelimiting, we will give you a cURL command to test. This command will create your first namespace by requesting our ratelimit endpoint.\n\n<Image src=\"/images/blog-images/ratelimiting/onboarding-2.png\" alt=\"Example of cURL command\" width=\"1920\" height=\"1080\"/>\n\nNow, you are ready to go and can start looking at our rich analytics or exploring the rest of Unkey.\n\n<Image src=\"/images/blog-images/ratelimiting/onboarding-3.png\" alt=\"Explore Unkey\" width=\"1920\" height=\"1080\"/>\n\n## Analytics\n\nSpeaking of rich analytics, we provide rich analytical data that can filter around identifiers. These analytics can help you understand what parts of your application are used most and by whom.\n\n<Image src=\"/images/blog-images/ratelimiting/analytics.png\" alt=\"Analytic example\" width=\"1920\" height=\"1080\"/>\n\n<Image src=\"/images/blog-images/ratelimiting/top-analytics.png\" alt=\"Top identifiers\" width=\"1920\" height=\"1080\"/>\n\nIf you are ready to start with our ratelimiter built for the modern web, check out our [documentation](https://unkey.com/docs/ratelimiting/introduction) or our [new template to get you started](https://unkey.com/templates/ratelimit-nextjs). If you want to see how we implemented this, check out our [GitHub repository](https://github.com/unkeyed/unkey).",
    "title": "Introducing standalone ratelimiting",
    "description": "Global ratelimiting built for the modern web.",
    "author": "james",
    "date": "2024-03-25",
    "tags": [
      "product"
    ],
    "image": "/images/blog-images/ratelimiting/ratelimit-cover.png",
    "_meta": {
      "filePath": "introducing-ratelimiting.mdx",
      "fileName": "introducing-ratelimiting.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "introducing-ratelimiting"
    },
    "mdx": "var Component=(()=>{var h=Object.create;var a=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var f=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),w=(n,e)=>{for(var t in e)a(n,t,{get:e[t],enumerable:!0})},s=(n,e,t,o)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of m(e))!y.call(n,r)&&r!==t&&a(n,r,{get:()=>e[r],enumerable:!(o=g(e,r))||o.enumerable});return n};var b=(n,e,t)=>(t=n!=null?h(p(n)):{},s(e||!n||!n.__esModule?a(t,\"default\",{value:n,enumerable:!0}):t,n)),k=n=>s(a({},\"__esModule\",{value:!0}),n);var c=f((I,l)=>{l.exports=_jsx_runtime});var x={};w(x,{default:()=>u});var i=b(c());function d(n){let e={a:\"a\",code:\"code\",h2:\"h2\",h3:\"h3\",p:\"p\",pre:\"pre\",strong:\"strong\",...n.components},{Image:t}=e;return t||v(\"Image\",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.p,{children:\"Today, we are introducing standalone ratelimiting. With this feature, you can rate limit anything while still leveraging the power of Unkey. Our ratelimiting feature works similarly to our keys, providing low global latency and detailed analytics. Moreover, you can configure overrides for specific identifiers, giving you more flexibility.\"}),`\n`,(0,i.jsxs)(e.p,{children:[\"You can \",(0,i.jsx)(e.a,{href:\"https://unkey.com/ratelimit\",children:\"check out a demo\"}),\" that shows our synchronous and asynchronous implementation versus a Redis-based ratelimiter.\"]}),`\n`,(0,i.jsx)(e.h2,{id:\"using-our-ratelimiter\",children:\"Using our ratelimiter\"}),`\n`,(0,i.jsx)(e.p,{children:\"To use our rate limit feature, you can use our API directly, an existing package like @unkey/api, or our new package @unkey/ratelimit, which is completely standalone from the other features in our API. The examples below will use the new package to keep things simple.\"}),`\n`,(0,i.jsx)(e.h3,{id:\"configure-your-ratelimiter\",children:\"Configure your ratelimiter\"}),`\n`,(0,i.jsxs)(e.p,{children:[\"Firstly, you will want to configure the ratelimiter. Unkey uses namespaces to allow you to separate different parts of your application and have isolated limits for them. If the namespace doesn't exist, we will create it with the first request. For example, each of your tRPC routes could be a namespace. In this example, we use our \",(0,i.jsx)(e.code,{children:\"ai.generate\"}),\" route.\"]}),`\n`,(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:\"language-typescript\",children:`import { Ratelimit }\\xA0from \"@unkey/ratelimit\"\n\nconst unkey = new Ratelimit({\n  rootKey: process.env.UNKEY_ROOT_KEY,\n  namespace: \"ai.generate\",\n  limit: 10,\n  duration: \"30s\",\n});\n`})}),`\n`,(0,i.jsx)(e.h3,{id:\"using-the-ratelimiter\",children:\"Using the ratelimiter\"}),`\n`,(0,i.jsx)(e.p,{children:\"With the ratelimiter now configured, we can use it in a route to decide whether to proceed with handling the request or reject it with a 429 response. You will need to pass an identifier for the request; this could be anything, but commonly, it is a userId or an IP address.\"}),`\n`,(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:\"language-typescript\",children:`async function handler(request) {\n  const identifier = request.getUserId();\n\n  const ratelimit = await unkey.limit(identifier);\n  if (!ratelimit.success) {\n    return new Response(\"try again later\", { status: 429 });\n  }\n  // handle the request here\n}\n`})}),`\n`,(0,i.jsx)(e.h2,{id:\"advanced-usage\",children:\"Advanced usage\"}),`\n`,(0,i.jsx)(e.p,{children:\"Ratelimting offers additional options to provide more advanced configurations, including cost, async requests, and resource audit logging. We also provide configurable overrides in the dashboard so specific resources with an identifier can have limits without adding additional code.\"}),`\n`,(0,i.jsx)(e.h3,{id:\"overrides\",children:\"Overrides\"}),`\n`,(0,i.jsx)(e.p,{children:\"Configurable overrides allow you to tell Unkey how to handle specific identifiers. For example, you may have a user or an IP that requires higher limits than your normal flows. Instead of having to write logic into your application, you can set the identifier in the dashboard, and we will handle it for you.\"}),`\n`,(0,i.jsx)(t,{src:\"/images/blog-images/ratelimiting/overrides.png\",alt:\"Overrides example\",width:\"1920\",height:\"1080\"}),`\n`,(0,i.jsx)(e.h3,{id:\"async-requests\",children:\"async requests\"}),`\n`,(0,i.jsx)(e.p,{children:\"You can enable async requests, which will sacrifice minimal accuracy and improve the latency even further. Our accuracy when using async requests is around 97%, but we can reduce the latency over a synchronous request by 30ms. You can enable this in the configuration or for specific usage of the rate limiter.\"}),`\n`,(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:\"Ratelimit configuriation\"})}),`\n`,(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:\"language-typescript\",children:`const unkey = new Ratelimit({\n  // ...\n  async: true,\n});\n`})}),`\n`,(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:\"Using the ratelimiter\"})}),`\n`,(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:\"language-typescript\",children:`async function handler(request: NextApiRequest) {\n  const identifier = request.getUserId();\n\n  const ratelimit = await unkey.limit(identifier, {\n    async: true,\n  });\n  if (!ratelimit.success) {\n    return new Response(\"try again later\", { status: 429 });\n  }\n  // handle the request here\n}\n`})}),`\n`,(0,i.jsx)(e.h3,{id:\"cost-configuration\",children:\"Cost configuration\"}),`\n`,(0,i.jsx)(e.p,{children:\"Sometimes, you may have an expensive resource. We allow you to set a cost for the request, and we will deduct that cost from the current window and reject a request if it exceeds the allowed amount. For example:\"}),`\n`,(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:\"language-typescript\",children:`async function handler(request: NextApiRequest) {\n  const identifier = request.getUserId();\n\n  const ratelimit = await unkey.limit(identifier, {\n    cost: 4,\n  });\n  if (!ratelimit.success) {\n    return new Response(\"try again later\", { status: 429 });\n  }\n  // handle the request here\n}\n`})}),`\n`,(0,i.jsx)(e.p,{children:\"This request would now cost 4 tokens versus 1, allowing you to be flexible about handling the expensive resources in your application.\"}),`\n`,(0,i.jsx)(e.h3,{id:\"resource-audit-logging\",children:\"Resource Audit logging\"}),`\n`,(0,i.jsx)(e.p,{children:\"Unkey provides audit logging out of the box at no additional cost to you. In cases where you want to create a paper trail, you can do by providing the ratelimit request with resource details, for example:\"}),`\n`,(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:\"language-typescript\",children:`async function handler(request: NextApiRequest) {\n  const identifier = request.getUserId();\n\n  const ratelimit = await unkey.limit(identifier, {\n    resources: [\n      {\n        id: \"id_123\",\n        name: \"unkey\",\n        type: \"ai.generate\",\n      },\n    ],\n  });\n  if (!ratelimit.success) {\n    return new Response(\"try again later\", { status: 429 });\n  }\n  // handle the request here\n}\n`})}),`\n`,(0,i.jsx)(e.p,{children:\"Sending a request with a resource will provide an audit log in our dashboard that you can use; below is how it looks:\"}),`\n`,(0,i.jsx)(t,{src:\"/images/blog-images/ratelimiting/audit.png\",alt:\"Audit Log example\",width:\"1920\",height:\"1080\"}),`\n`,(0,i.jsx)(e.h2,{id:\"onboarding-flow\",children:\"Onboarding flow\"}),`\n`,(0,i.jsx)(e.p,{children:\"If you are new to Unkey, we have a new onboarding flow for ratelimiting that will get you up and running in seconds. After you create your workspace, you will be asked if you want to use API keys or ratelimiting.\"}),`\n`,(0,i.jsx)(t,{src:\"/images/blog-images/ratelimiting/onboarding-1.png\",alt:\"Options of keys or ratelimiting\",width:\"1920\",height:\"1080\"}),`\n`,(0,i.jsx)(e.p,{children:\"Once you select ratelimiting, we will give you a cURL command to test. This command will create your first namespace by requesting our ratelimit endpoint.\"}),`\n`,(0,i.jsx)(t,{src:\"/images/blog-images/ratelimiting/onboarding-2.png\",alt:\"Example of cURL command\",width:\"1920\",height:\"1080\"}),`\n`,(0,i.jsx)(e.p,{children:\"Now, you are ready to go and can start looking at our rich analytics or exploring the rest of Unkey.\"}),`\n`,(0,i.jsx)(t,{src:\"/images/blog-images/ratelimiting/onboarding-3.png\",alt:\"Explore Unkey\",width:\"1920\",height:\"1080\"}),`\n`,(0,i.jsx)(e.h2,{id:\"analytics\",children:\"Analytics\"}),`\n`,(0,i.jsx)(e.p,{children:\"Speaking of rich analytics, we provide rich analytical data that can filter around identifiers. These analytics can help you understand what parts of your application are used most and by whom.\"}),`\n`,(0,i.jsx)(t,{src:\"/images/blog-images/ratelimiting/analytics.png\",alt:\"Analytic example\",width:\"1920\",height:\"1080\"}),`\n`,(0,i.jsx)(t,{src:\"/images/blog-images/ratelimiting/top-analytics.png\",alt:\"Top identifiers\",width:\"1920\",height:\"1080\"}),`\n`,(0,i.jsxs)(e.p,{children:[\"If you are ready to start with our ratelimiter built for the modern web, check out our \",(0,i.jsx)(e.a,{href:\"https://unkey.com/docs/ratelimiting/introduction\",children:\"documentation\"}),\" or our \",(0,i.jsx)(e.a,{href:\"https://unkey.com/templates/ratelimit-nextjs\",children:\"new template to get you started\"}),\". If you want to see how we implemented this, check out our \",(0,i.jsx)(e.a,{href:\"https://github.com/unkeyed/unkey\",children:\"GitHub repository\"}),\".\"]})]})}function u(n={}){let{wrapper:e}=n.components||{};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}function v(n,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+n+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return k(x);})();\n;return Component;",
    "slug": "introducing-ratelimiting",
    "url": "/blog/introducing-ratelimiting",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Using our ratelimiter",
        "slug": "using-our-ratelimiter"
      },
      {
        "level": 3,
        "text": "Configure your ratelimiter",
        "slug": "configure-your-ratelimiter"
      },
      {
        "level": 3,
        "text": "Using the ratelimiter",
        "slug": "using-the-ratelimiter"
      },
      {
        "level": 2,
        "text": "Advanced usage",
        "slug": "advanced-usage"
      },
      {
        "level": 3,
        "text": "Overrides",
        "slug": "overrides"
      },
      {
        "level": 3,
        "text": "async requests",
        "slug": "async-requests"
      },
      {
        "level": 3,
        "text": "Cost configuration",
        "slug": "cost-configuration"
      },
      {
        "level": 3,
        "text": "Resource Audit logging",
        "slug": "resource-audit-logging"
      },
      {
        "level": 2,
        "text": "Onboarding flow",
        "slug": "onboarding-flow"
      },
      {
        "level": 2,
        "text": "Analytics",
        "slug": "analytics"
      }
    ]
  },
  {
    "content": "At Unkey, our commitment isn't merely about providing API authentication. We are pushing the envelope and strive to make things as simple as possible for the developer community. That's why today, I'm incredibly excited to introduce our brand-new **Vercel Integration**.\n\n<div class=\"aspect-w-16 aspect-h-9 sm:h-[400px] sm:w-[640px] h-[240px] mx-4 md:mx-0\" >\n<iframe\nheight=\"100%\"\nwidth=\"100%\"\n src=\"https://www.youtube-nocookie.com/embed/fDKkicMZiCc?si=ksblX5j1-OUvNLpf&amp;controls=0\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowFullScreen></iframe>\n</div>\n\n## What does our Vercel integration do?\n\nThe integration connects to your existing Unkey workspace and sets the necessary environment variables in your Vercel project. We allow you to set an Unkey API for each Vercel environment (development, preview, production) and automatically set the correct variables for you. The Unkey root key will be passed as a sensitive environment variable, which will not be visible in the Vercel dashboard.\n\n<Image src=\"/images/blog-images/vercel/vercel.png\" alt=\"Vercel integration\" width=\"1920\" height=\"1080\"/>\n\n## How do I get started?\n\nTo get started check out our [documentation](https://unkey.com/docs/integrations/vercel) that gives you a step by step guide to integrate or the video posted above.",
    "title": "Zero config API authentication with Vercel",
    "description": "Integrate Unkey into Vercel to give you a environment variable free experience.",
    "author": "james",
    "date": "2023-10-04",
    "tags": [
      "product"
    ],
    "image": "/images/blog-images/covers/unkey-vercel.png",
    "_meta": {
      "filePath": "introducing-vercel-integration.mdx",
      "fileName": "introducing-vercel-integration.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "introducing-vercel-integration"
    },
    "mdx": "var Component=(()=>{var p=Object.create;var i=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var v=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)i(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,a)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of u(e))!y.call(t,r)&&r!==n&&i(t,r,{get:()=>e[r],enumerable:!(a=m(e,r))||a.enumerable});return t};var b=(t,e,n)=>(n=t!=null?p(g(t)):{},s(e||!t||!t.__esModule?i(n,\"default\",{value:t,enumerable:!0}):n,t)),f=t=>s(i({},\"__esModule\",{value:!0}),t);var d=v((_,c)=>{c.exports=_jsx_runtime});var k={};w(k,{default:()=>h});var o=b(d());function l(t){let e={a:\"a\",h2:\"h2\",p:\"p\",strong:\"strong\",...t.components},{Image:n}=e;return n||x(\"Image\",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(e.p,{children:[\"At Unkey, our commitment isn't merely about providing API authentication. We are pushing the envelope and strive to make things as simple as possible for the developer community. That's why today, I'm incredibly excited to introduce our brand-new \",(0,o.jsx)(e.strong,{children:\"Vercel Integration\"}),\".\"]}),`\n`,(0,o.jsx)(\"div\",{class:\"aspect-w-16 aspect-h-9 sm:h-[400px] sm:w-[640px] h-[240px] mx-4 md:mx-0\",children:(0,o.jsx)(\"iframe\",{height:\"100%\",width:\"100%\",src:\"https://www.youtube-nocookie.com/embed/fDKkicMZiCc?si=ksblX5j1-OUvNLpf&controls=0\",title:\"YouTube video player\",frameBorder:\"0\",allow:\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\",allowFullScreen:!0})}),`\n`,(0,o.jsx)(e.h2,{id:\"what-does-our-vercel-integration-do\",children:\"What does our Vercel integration do?\"}),`\n`,(0,o.jsx)(e.p,{children:\"The integration connects to your existing Unkey workspace and sets the necessary environment variables in your Vercel project. We allow you to set an Unkey API for each Vercel environment (development, preview, production) and automatically set the correct variables for you. The Unkey root key will be passed as a sensitive environment variable, which will not be visible in the Vercel dashboard.\"}),`\n`,(0,o.jsx)(n,{src:\"/images/blog-images/vercel/vercel.png\",alt:\"Vercel integration\",width:\"1920\",height:\"1080\"}),`\n`,(0,o.jsx)(e.h2,{id:\"how-do-i-get-started\",children:\"How do I get started?\"}),`\n`,(0,o.jsxs)(e.p,{children:[\"To get started check out our \",(0,o.jsx)(e.a,{href:\"https://unkey.com/docs/integrations/vercel\",children:\"documentation\"}),\" that gives you a step by step guide to integrate or the video posted above.\"]})]})}function h(t={}){let{wrapper:e}=t.components||{};return e?(0,o.jsx)(e,{...t,children:(0,o.jsx)(l,{...t})}):l(t)}function x(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return f(k);})();\n;return Component;",
    "slug": "introducing-vercel-integration",
    "url": "/blog/introducing-vercel-integration",
    "tableOfContents": [
      {
        "level": 2,
        "text": "What does our Vercel integration do?",
        "slug": "what-does-our-vercel-integration-do"
      },
      {
        "level": 2,
        "text": "How do I get started?",
        "slug": "how-do-i-get-started"
      }
    ]
  },
  {
    "content": "Last May I bought a [Bambu Labs A1](https://bambulab.com/en-us/a1). Mainly as a hobby and to make some parts for some home projects. While browsing for interesting creations from the community on [Makerworld](https://makerworld.com/en), I had the idea of creating myself a web app to store personal projects to reference and save notes and images of the progress. \n\n## How I built my project\n\nI am a relatively new developer, so planning larger projects like this is a new experience.\n\nTo build this project I needed:\n\n- Authentication \n- Database\n- Web application\n- Route protection\n\nI went with:\n\n- Auth.js\n- sqlite db and Drizzle ORM\n- NextJS\n- Unkey ratelimit protection\n\n I started with a basic database schema planning. I found that for me its always a good place to start. It allows me to get an idea of the data and how interaction with that data will happen. \n\n### Setup\n\nNext I gave myself a good starting point to quickly setup and hit the ground running. I found that the faster I can get something working the better for my ADHD.  So I used the [T3 stack](https://create.t3.gg/) to give me a good head start. \n\n```shell\npnpm create t3-app@latest\n```\n\nOptions used: \n<Image src=\"/images/blog-images/learn-by-building/createt3.png\" alt=\"Using the playground\" width=\"1920\" height=\"1080\"/>\n\n\n### Build\nContinuing that trend I added some basic [shadcn](https://ui.shadcn.com/) components to get started on the UI.\nIn just a short period of time I had a half decent looking app. But that was the easy part. \n\nSo UI being functional enough, I started digging into the api/server side of things. I set up the `Drizzle` schema and `tRPC` routes. Sure I may have needed the `tRPC` and `Drizzle` docs open the entire time. But hey, that is what they are for. \nMy first real hurdle was about now. As usual, I was starting to over think the schema and layout and whatever else. keeping on track with a larger project is a challenge for me. \n\nWhen planning out the db schema I started adding more columns than needed. I also added references I would not need making it more complicated than it needed to be. I often have to stop myself from bouncing to another file if an idea pops into my head. \nThis was a good experience as it allowed me to think about self restraint and management. Just telling myself that things are fluid and can be changed later was very helpful. Nothing is perfect on the first draft so building things in a way that allows for changes later is important. For me being flexible is the way forward and not over thinking and getting stuck on a single task. \n\n### Typescript\n\nI have been working in a Typescript project for about a year now, but because a lot of the code was implemented when I got to Unkey. I often struggled with debugging errors. \nOn this project because I implemented code from start to finish, I got a lot more familiar with debugging typescript errors.\n\nTo make my life a bit easier, I used [zod](https://zod.dev/) to manage the tRPC routes. \n\n```typescript\n getProjectsByCategory: publicProcedure\n    .input(\n      z.object({\n        category: z.string().min(3),\n      }),\n    )\n    .query(async ({ ctx, input }) => {\n      const project = await ctx.db.query.projects.findMany({\n        where: eq(projects.category, input.category.toUpperCase()),\n        orderBy: (projects, { desc }) => [desc(projects.createdAt)],\n        limit: 50,\n        with: { steps: true },\n      });\n      return project;\n    }),\n```\n\nAnd on the form side a controlled form element with `zod` and `react-hook-form` \n\n```typescript\nconst formSchema = z.object({\n\tprojectName: z.string().min(2).max(50),\n\tcategory: z.string().min(2).max(50),\n\tprojectDescription: z\n\t\t.string()\n\t\t.min(10, { message: \"Must be 10 or more characters long\" })\n\t\t.max(500, { message: \"Must be less than 500 characters long\" }),\n\tprojectImage: z\n\t\t.instanceof(File)\n\t\t.refine(\n\t\t\t(file) => !ACCEPTED_IMAGE_TYPES.includes(file?.type),\n\t\t\t\"Only .jpg, .jpeg and .png formats are supported.\",\n\t\t)\n\t\t.optional(),\n});\n```\nKeeping my types in check made it easy to track down errors from human error. things like passing the wrong type to routes or incorrect variable names. Just makes less thing I need to worry about once setup so I can focus on the things that need to be done and not tracking down a typo or something.   \n\n\n### Ratelimit\nIf I ever want to launch this live I figured it would be a good idea to limit abuse on any of the secured routes. The choice was pretty easy being as I work for a company that has a `Ratelimit` sdk.\n\n```shell\npnpm add @unkey/ratelimit\n\n```\n\nUnkey makes this incredible easy it take a couple of steps to implement. I used the docs as a reference point. [docs](https://www.unkey.com/docs/libraries/ts/ratelimit)\n\n### Created ratelimit procedure\n\n```typescript\nexport const rateLimitedProcedure = ({\n  limit,\n  duration,\n}: {\n  limit: number;\n  duration: number;\n}) =>\n  protectedProcedure.use(async (opts) => {\n    const unkey = new Ratelimit({\n      rootKey: env.UNKEY_ROOT_KEY,\n      namespace: `trpc_${opts.path}`,\n      limit: limit ?? 3,\n      duration: duration ? `${duration}s` : `${5}s`,\n    });\n\n    const ratelimit = await unkey.limit(opts.ctx.session.user.id);\n\n    if (!ratelimit.success) {\n      throw new TRPCError({\n        code: \"TOO_MANY_REQUESTS\",\n        message: JSON.stringify(ratelimit),\n      });\n    }\n\n    return opts.next({\n      ctx: {\n        ...opts.ctx,\n        remaining: ratelimit.remaining,\n      },\n    });\n  });\n```\n\nAnd then used like this on any route you want to `ratelimit`\n\n```typescript\n create: rateLimitedProcedure({ limit: 3, duration: 5 })\n    .input(\n      z.object({\n        projectName: z.string().min(3),\n        projectDescription: z.string(),\n        category: z.string(),\n        projectImage: z.string().optional(),\n      }),\n    )\n```\n\nThis is probably what took the longest. My experience is limited with `tRPC` routes and `ratelimiting`. I was stuck on this for a little while, as I have never really worked with tRPC and ratelimiting on my own. I tried to work through this, but needed to reach out to get help. Just like everyone else I hate bothering people but sometimes the best path forward to reaching out to someone else.\n\n## Conclusion\n\nIn making this project I learned a hell of a lot. I now have a more solid understanding of client/server communications. How to debug and fix `Typescript` errors more effectively. When to ask for help from someone who has more experience, while docs will get you pretty far there is no substitute for another person to pair with. Big thanks to [James](https://x.com/james_r_perkins) and [Andreas](https://x.com/chronark_) for all the help over the last year. I would like to add more features to this in the future, but for now I have added the example into Unkey's templates page for anyone interested in checking out the code. \n\n**Example**\n[Unkey ratelimiting with TRPC + Drizzle](https://www.unkey.com/templates/unkey-trpc-ratelimit)",
    "title": "Learn by building",
    "description": "What I learned developing a full application for the first time.",
    "author": "michael",
    "date": "2024-09-12",
    "tags": [
      "marketing"
    ],
    "image": "/images/blog-images/covers/learn-by-building.png",
    "_meta": {
      "filePath": "learn-by-building.mdx",
      "fileName": "learn-by-building.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "learn-by-building"
    },
    "mdx": "var Component=(()=>{var p=Object.create;var o=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var y=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),w=(n,e)=>{for(var r in e)o(n,r,{get:e[r],enumerable:!0})},s=(n,e,r,a)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let i of u(e))!f.call(n,i)&&i!==r&&o(n,i,{get:()=>e[i],enumerable:!(a=m(e,i))||a.enumerable});return n};var b=(n,e,r)=>(r=n!=null?p(g(n)):{},s(e||!n||!n.__esModule?o(r,\"default\",{value:n,enumerable:!0}):r,n)),k=n=>s(o({},\"__esModule\",{value:!0}),n);var d=y((v,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>h});var t=b(d());function l(n){let e={a:\"a\",code:\"code\",h2:\"h2\",h3:\"h3\",li:\"li\",p:\"p\",pre:\"pre\",strong:\"strong\",ul:\"ul\",...n.components},{Image:r}=e;return r||I(\"Image\",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(e.p,{children:[\"Last May I bought a \",(0,t.jsx)(e.a,{href:\"https://bambulab.com/en-us/a1\",children:\"Bambu Labs A1\"}),\". Mainly as a hobby and to make some parts for some home projects. While browsing for interesting creations from the community on \",(0,t.jsx)(e.a,{href:\"https://makerworld.com/en\",children:\"Makerworld\"}),\", I had the idea of creating myself a web app to store personal projects to reference and save notes and images of the progress.\"]}),`\n`,(0,t.jsx)(e.h2,{id:\"how-i-built-my-project\",children:\"How I built my project\"}),`\n`,(0,t.jsx)(e.p,{children:\"I am a relatively new developer, so planning larger projects like this is a new experience.\"}),`\n`,(0,t.jsx)(e.p,{children:\"To build this project I needed:\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsx)(e.li,{children:\"Authentication\"}),`\n`,(0,t.jsx)(e.li,{children:\"Database\"}),`\n`,(0,t.jsx)(e.li,{children:\"Web application\"}),`\n`,(0,t.jsx)(e.li,{children:\"Route protection\"}),`\n`]}),`\n`,(0,t.jsx)(e.p,{children:\"I went with:\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsx)(e.li,{children:\"Auth.js\"}),`\n`,(0,t.jsx)(e.li,{children:\"sqlite db and Drizzle ORM\"}),`\n`,(0,t.jsx)(e.li,{children:\"NextJS\"}),`\n`,(0,t.jsx)(e.li,{children:\"Unkey ratelimit protection\"}),`\n`]}),`\n`,(0,t.jsx)(e.p,{children:\"I started with a basic database schema planning. I found that for me its always a good place to start. It allows me to get an idea of the data and how interaction with that data will happen.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"setup\",children:\"Setup\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Next I gave myself a good starting point to quickly setup and hit the ground running. I found that the faster I can get something working the better for my ADHD.  So I used the \",(0,t.jsx)(e.a,{href:\"https://create.t3.gg/\",children:\"T3 stack\"}),\" to give me a good head start.\"]}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-shell\",children:`pnpm create t3-app@latest\n`})}),`\n`,(0,t.jsx)(e.p,{children:\"Options used:\"}),`\n`,(0,t.jsx)(r,{src:\"/images/blog-images/learn-by-building/createt3.png\",alt:\"Using the playground\",width:\"1920\",height:\"1080\"}),`\n`,(0,t.jsx)(e.h3,{id:\"build\",children:\"Build\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Continuing that trend I added some basic \",(0,t.jsx)(e.a,{href:\"https://ui.shadcn.com/\",children:\"shadcn\"}),` components to get started on the UI.\nIn just a short period of time I had a half decent looking app. But that was the easy part.`]}),`\n`,(0,t.jsxs)(e.p,{children:[\"So UI being functional enough, I started digging into the api/server side of things. I set up the \",(0,t.jsx)(e.code,{children:\"Drizzle\"}),\" schema and \",(0,t.jsx)(e.code,{children:\"tRPC\"}),\" routes. Sure I may have needed the \",(0,t.jsx)(e.code,{children:\"tRPC\"}),\" and \",(0,t.jsx)(e.code,{children:\"Drizzle\"}),` docs open the entire time. But hey, that is what they are for.\nMy first real hurdle was about now. As usual, I was starting to over think the schema and layout and whatever else. keeping on track with a larger project is a challenge for me.`]}),`\n`,(0,t.jsx)(e.p,{children:`When planning out the db schema I started adding more columns than needed. I also added references I would not need making it more complicated than it needed to be. I often have to stop myself from bouncing to another file if an idea pops into my head.\nThis was a good experience as it allowed me to think about self restraint and management. Just telling myself that things are fluid and can be changed later was very helpful. Nothing is perfect on the first draft so building things in a way that allows for changes later is important. For me being flexible is the way forward and not over thinking and getting stuck on a single task.`}),`\n`,(0,t.jsx)(e.h3,{id:\"typescript\",children:\"Typescript\"}),`\n`,(0,t.jsx)(e.p,{children:`I have been working in a Typescript project for about a year now, but because a lot of the code was implemented when I got to Unkey. I often struggled with debugging errors.\nOn this project because I implemented code from start to finish, I got a lot more familiar with debugging typescript errors.`}),`\n`,(0,t.jsxs)(e.p,{children:[\"To make my life a bit easier, I used \",(0,t.jsx)(e.a,{href:\"https://zod.dev/\",children:\"zod\"}),\" to manage the tRPC routes.\"]}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-typescript\",children:` getProjectsByCategory: publicProcedure\n    .input(\n      z.object({\n        category: z.string().min(3),\n      }),\n    )\n    .query(async ({ ctx, input }) => {\n      const project = await ctx.db.query.projects.findMany({\n        where: eq(projects.category, input.category.toUpperCase()),\n        orderBy: (projects, { desc }) => [desc(projects.createdAt)],\n        limit: 50,\n        with: { steps: true },\n      });\n      return project;\n    }),\n`})}),`\n`,(0,t.jsxs)(e.p,{children:[\"And on the form side a controlled form element with \",(0,t.jsx)(e.code,{children:\"zod\"}),\" and \",(0,t.jsx)(e.code,{children:\"react-hook-form\"})]}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-typescript\",children:`const formSchema = z.object({\n\tprojectName: z.string().min(2).max(50),\n\tcategory: z.string().min(2).max(50),\n\tprojectDescription: z\n\t\t.string()\n\t\t.min(10, { message: \"Must be 10 or more characters long\" })\n\t\t.max(500, { message: \"Must be less than 500 characters long\" }),\n\tprojectImage: z\n\t\t.instanceof(File)\n\t\t.refine(\n\t\t\t(file) => !ACCEPTED_IMAGE_TYPES.includes(file?.type),\n\t\t\t\"Only .jpg, .jpeg and .png formats are supported.\",\n\t\t)\n\t\t.optional(),\n});\n`})}),`\n`,(0,t.jsx)(e.p,{children:\"Keeping my types in check made it easy to track down errors from human error. things like passing the wrong type to routes or incorrect variable names. Just makes less thing I need to worry about once setup so I can focus on the things that need to be done and not tracking down a typo or something.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"ratelimit\",children:\"Ratelimit\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"If I ever want to launch this live I figured it would be a good idea to limit abuse on any of the secured routes. The choice was pretty easy being as I work for a company that has a \",(0,t.jsx)(e.code,{children:\"Ratelimit\"}),\" sdk.\"]}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-shell\",children:`pnpm add @unkey/ratelimit\n\n`})}),`\n`,(0,t.jsxs)(e.p,{children:[\"Unkey makes this incredible easy it take a couple of steps to implement. I used the docs as a reference point. \",(0,t.jsx)(e.a,{href:\"https://www.unkey.com/docs/libraries/ts/ratelimit\",children:\"docs\"})]}),`\n`,(0,t.jsx)(e.h3,{id:\"created-ratelimit-procedure\",children:\"Created ratelimit procedure\"}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-typescript\",children:`export const rateLimitedProcedure = ({\n  limit,\n  duration,\n}: {\n  limit: number;\n  duration: number;\n}) =>\n  protectedProcedure.use(async (opts) => {\n    const unkey = new Ratelimit({\n      rootKey: env.UNKEY_ROOT_KEY,\n      namespace: \\`trpc_\\${opts.path}\\`,\n      limit: limit ?? 3,\n      duration: duration ? \\`\\${duration}s\\` : \\`\\${5}s\\`,\n    });\n\n    const ratelimit = await unkey.limit(opts.ctx.session.user.id);\n\n    if (!ratelimit.success) {\n      throw new TRPCError({\n        code: \"TOO_MANY_REQUESTS\",\n        message: JSON.stringify(ratelimit),\n      });\n    }\n\n    return opts.next({\n      ctx: {\n        ...opts.ctx,\n        remaining: ratelimit.remaining,\n      },\n    });\n  });\n`})}),`\n`,(0,t.jsxs)(e.p,{children:[\"And then used like this on any route you want to \",(0,t.jsx)(e.code,{children:\"ratelimit\"})]}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-typescript\",children:` create: rateLimitedProcedure({ limit: 3, duration: 5 })\n    .input(\n      z.object({\n        projectName: z.string().min(3),\n        projectDescription: z.string(),\n        category: z.string(),\n        projectImage: z.string().optional(),\n      }),\n    )\n`})}),`\n`,(0,t.jsxs)(e.p,{children:[\"This is probably what took the longest. My experience is limited with \",(0,t.jsx)(e.code,{children:\"tRPC\"}),\" routes and \",(0,t.jsx)(e.code,{children:\"ratelimiting\"}),\". I was stuck on this for a little while, as I have never really worked with tRPC and ratelimiting on my own. I tried to work through this, but needed to reach out to get help. Just like everyone else I hate bothering people but sometimes the best path forward to reaching out to someone else.\"]}),`\n`,(0,t.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"In making this project I learned a hell of a lot. I now have a more solid understanding of client/server communications. How to debug and fix \",(0,t.jsx)(e.code,{children:\"Typescript\"}),\" errors more effectively. When to ask for help from someone who has more experience, while docs will get you pretty far there is no substitute for another person to pair with. Big thanks to \",(0,t.jsx)(e.a,{href:\"https://x.com/james_r_perkins\",children:\"James\"}),\" and \",(0,t.jsx)(e.a,{href:\"https://x.com/chronark_\",children:\"Andreas\"}),\" for all the help over the last year. I would like to add more features to this in the future, but for now I have added the example into Unkey's templates page for anyone interested in checking out the code.\"]}),`\n`,(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:\"Example\"}),`\n`,(0,t.jsx)(e.a,{href:\"https://www.unkey.com/templates/unkey-trpc-ratelimit\",children:\"Unkey ratelimiting with TRPC + Drizzle\"})]})]})}function h(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(l,{...n})}):l(n)}function I(n,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+n+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return k(j);})();\n;return Component;",
    "slug": "learn-by-building",
    "url": "/blog/learn-by-building",
    "tableOfContents": [
      {
        "level": 2,
        "text": "How I built my project",
        "slug": "how-i-built-my-project"
      },
      {
        "level": 3,
        "text": "Setup",
        "slug": "setup"
      },
      {
        "level": 3,
        "text": "Build",
        "slug": "build"
      },
      {
        "level": 3,
        "text": "Typescript",
        "slug": "typescript"
      },
      {
        "level": 3,
        "text": "Ratelimit",
        "slug": "ratelimit"
      },
      {
        "level": 3,
        "text": "Created ratelimit procedure",
        "slug": "created-ratelimit-procedure"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "[Unkey](https://unkey.com) is an open-source API key management tool with real-time API key creation, updating, and verification.\n\nIn this blog, we'll take a look at how we can use Unkey to make an Optical Character Recognition (OCR) API as a service. The OCR API takes in an image and returns the textual characters present in it.\n\nYou can find the complete source code on [GitHub](https://github.com/WilfredAlmeida/unkey-ocr).\n\n## Pre-requisites\n\nSignup and get started with the [Unkey](https://unkey.com) dashboard. As soon as you create your account you will be asked to create your workspace. Give it a name, and a slug. The name is shown only to you and not to your users.\n\n<Image src=\"/images/blog-images/ai-post/create-root-key.png\" alt=\"Create Root Key\" width=\"1920\" height=\"1080\"/>\n\nThen you can create your first API which allows you to track usage as well as segment keys, the name you choose is also not visible to users.\n\n<Image src=\"/images/blog-images/ai-post/create-api.png\" alt=\"Create API\" width=\"1920\" height=\"1080\"/>\n\nThe admin dashboard gives you access to several features in a simple-to-use interface. You can create new APIs, issue keys, revoke keys and see usage stats. You can also invite other users to your account so that they can manage your APIs.\n\n<Image src=\"/images/blog-images/ocr-post/3-dashboard.png\" alt=\"Dashboard\" width=\"1920\" height=\"1080\"/>\n\n---\n\n## Project Walkthrough\n\n<Image src=\"/images/blog-images/ocr-post/4-walkthrough.gif\" alt=\"Walkthrough\" width=\"1920\" height=\"1080\"/>\n\nThe project is an Express API in NodeJS.\n\nIt takes an image either as a file or base64 and does OCR on it and returns the resulting text.\n\n### OCR\n\nOCR is done via an npm package [tesseract.js](https://www.npmjs.com/package/tesseract.js). Following is its function which takes in the image and recognizes English and Spanish languages.\n\n```typescript\nconst doOcr = async (image) => {\n  try {\n    // It detects English and Spanish\n    const { data } = await Tesseract.recognize(image, \"spa+eng\", {\n      logger: (m) => console.log(m),\n    });\n\n    return { data: data, error: null };\n  } catch (error) {\n    console.log(error);\n    return { data: null, error: error };\n  }\n};\n```\n\n---\n\n## Endpoints Explained\n\n1. `/signup`: Sign up for an API key. Returns a JSON object with the API key.\n\nIt validates the email and provisions and returns an API key. The key is then used to authenticate the OCR endpoints.\n\nType: `POST`\n\nBody:\n\n| Name  | Type   | Description                   |\n| ----- | ------ | ----------------------------- |\n| email | string | Email address to sign up with |\n| name  | string | Name of user                  |\n\nReturns:\n\n| Name  | Type   | Description |\n| ----- | ------ | ----------- |\n| key   | string | API Key     |\n| keyId | string | API Key ID  |\n\n2. `/upload`: Upload an image to perform OCR. Returns a JSON object with the OCR results. It uses the API key to authenticate the request. It then performs OCR on the image and returns the results.\n\nType: `POST`\n\nHeaders:\n\n| Name   | Type   | Description            |\n| ------ | ------ | ---------------------- |\n| Bearer | string | API key in Bearer auth |\n\nBody:\n\n| Name       | Type | Description  |\n| ---------- | ---- | ------------ |\n| sampleFile | file | Image to use |\n\nReturns:\n\n| Name  | Type         | Description  |\n| ----- | ------------ | ------------ |\n| text  | string, null | OCR Results  |\n| error | string, null | Error if any |\n\n3. `/uploadBase64`: Upload a base64 encoded image to perform OCR. Returns a JSON object with the OCR results. It uses the API key to authenticate the request. It then performs OCR on the image and returns the results.\n\nType: `POST`\n\nHeaders:\n\n| Name   | Type   | Description            |\n| ------ | ------ | ---------------------- |\n| Bearer | string | API key in Bearer auth |\n\nBody:\n\n| Name        | Type   | Description          |\n| ----------- | ------ | -------------------- |\n| imageBase64 | string | Base64 encoded image |\n\nReturns:\n\n| Name  | Type         | Description  |\n| ----- | ------------ | ------------ |\n| text  | string, null | OCR Results  |\n| error | string, null | Error if any |\n\n4. `/upgradeUser`: Upgrade a user to a paid plan. It validates an imaginary transaction id and then upgrades the user.\n   It increases the usage limit of the user based on the subscription the user has purchased.\n\nType: `POST`\n\nHeaders: None\n\nBody:\n\n| Name          | Type   | Description                                                            |\n| ------------- | ------ | ---------------------------------------------------------------------- |\n| email         | string | Email address of the user                                              |\n| transactionId | string | Imaginary transaction id                                               |\n| apiKeyId      | string | Id of the API key to be updated. It is returned when a key is created. |\n\nReturns: None\n\n---\n\n## Understanding Unkey API key authentication\n\nUnkey uses fast and efficient on-the-edge systems to verify a key. It adds less than 40ms to our requests.\n\nThe key is provisioned per user in the `/signup` route. The user can then use the key to authenticate requests to the OCR endpoints.\n\n```javascript\n// /signUp endpoint\napp.post(\"/signUp\", async (req: Request, res: Response) => {\n  const { name = \"John Doe\", email = \"john@example.com\" } = req.body;\n\n  // Imaginary name and email validation\n\n  const myHeaders = new Headers();\n  myHeaders.append(\"Authorization\", `Bearer ${process.env.UNKEY_ROOT_KEY}`);\n  myHeaders.append(\"Content-Type\", \"application/json\");\n\n  const raw = JSON.stringify({\n    apiId: process.env.UNKEY_API_ID,\n    prefix: \"ocr\",\n    byteLength: 16,\n    ownerId: email,\n    meta: {\n      name: name,\n      email: email,\n    },\n    expires: Date.now() + 2592000000 // 30 days from now\n    ratelimit: {\n      duration: 1000,\n      limit: 1,\n    },\n  });\n\n\n  const createKeyResponse = await fetch(\n    \"https://api.unkey.dev/v1/keys.createKey\",\n    {\n      method: \"POST\",\n      headers: myHeaders,\n      body: raw,\n      redirect: \"follow\",\n    },\n  );\n  const createKeyResponseJson = await createKeyResponse.json();\n\n  if (createKeyResponseJson.error)\n    return res\n      .status(400)\n      .json({ error: createKeyResponseJson.error, keys: null });\n\n  return res.status(200).json({ keys: [createKeyResponseJson], error: null });\n});\n```\n\nThe user then has to send the API key in the `Authorization` header as a `Bearer` token. To verify the key, a simple API call is made to Unkey. More on this further ahead.\n\nTo verify the key, we've made a middleware in the `middleware.ts` file.\n\n### Key Creation\n\nAs shown in the above code block, the key is created in the `/signup` route in `index.ts`.\n\nIts params are explained in detail in the official [docs](https://unkey.com/docs/api-reference/keys/create)\n\nFollowing is a description of the params used in this example:\n\n- `apiId`: The API ID to create the key for. You create this API in the Unkey dashboard.\n\n- `prefix`: The prefix to use for the key. Every key is prefixed with this. This is useful to identify the key's purpose. For eg. we can have prefixes like `user_`, `admin_`, `service_`, `staging_`, `trial_`, `production_` etc.\n\n- `byteLength`: The byte length used to generate the key determines its entropy as well as its length. Higher is better, but keys become longer and more annoying to handle. The default is 16 bytes or 2^128 possible combinations.\n\n- `ownerId`: This can be any string. In this example, we're using the user's email address as the id. By doing this we'll be able to verify the appropriate owner of the key.\n\n- `meta`: Any metadata information we want to store with the key. In this example, we're storing the user's name and email.\n\n- `expires`: Keys can be auto-expired by providing a UNIX timestamp in milliseconds. Once keys expire they will automatically be deleted and are no longer valid.\n\n- `rateLimit`: Keys can be rate limited by certain parameters. This is extremely beneficial as it prevents abuse of our API. The rate limit is enforced on the edge, so it's extremely fast and efficient. The rate limit params we've used in this example are:\n\n  - `type`: Type of the rate limit. Read more: [Rate Limiting](https://unkey.com/docs/features/ratelimiting)\n\n  - `limit`: The number of requests allowed in the given time\n\n  - `refill`: The number of requests to refill in the given time\n\n  - `refillInterval`: The interval by which the requests are refilled\n\nIn the rate limit set in the `/signUp` route, the user is on a trial plan and is allowed 1 request every 10 seconds.\n\n### Key Verification\n\nThe API key verification is done in the `middleware.ts` file. We're making an API call to the Unkey API to verify the key by passing the `key` into the request body.\n\n```javascript\nimport { Request, Response, NextFunction } from \"express\";\n\n// An Express Middleware\nconst verifyApiKey = async (\n  req: Request,\n  res: Response,\n  next: NextFunction\n) => {\n  const authHeader = req.headers.authorization;\n  if (authHeader) {\n    // Get the token from request headers\n    const token = authHeader.split(\" \")[1].trim();\n\n    try {\n      const myHeaders = new Headers();\n      myHeaders.append(\"Content-Type\", \"application/json\");\n\n      const raw = JSON.stringify({\n        key: token,\n      });\n\n      const verifyKeyResponse = await fetch(\n        \"https://api.unkey.dev/v1/keys.verifyKey\",\n        {\n          method: \"POST\",\n          headers: myHeaders,\n          body: raw,\n          redirect: \"follow\",\n        }\n      );\n      const verifyKeyResponseJson = await verifyKeyResponse.json();\n\n      if (\n        !verifyKeyResponseJson.valid &&\n        verifyKeyResponseJson.code === \"RATE_LIMITED\"\n      )\n        return res.status(429).json({ message: \"RATE_LIMITED\" });\n\n      if (!verifyKeyResponseJson.valid)\n        return res.status(401).json({ message: \"Unauthorized\" });\n\n      next();\n    } catch (err) {\n      console.log(\"ERROR: \", err);\n      return res.status(401).json({ message: \"Unauthorized\" });\n    }\n  } else {\n    return res.status(401).json({ message: \"Unauthorized\" });\n  }\n};\n\nexport default verifyApiKey;\n```\n\n#### Key verification response\n\n```json\n{\n    \"valid\": true,\n    \"ownerId\": \"john@example.com\",\n    \"meta\": {\n        \"email\": \"john@example.com\",\n        \"name\": \"John Doe\"\n    },\n    \"expires\": Date.now() + 2592000000 // 30 days from now\n    \"ratelimit\": {\n        \"limit\": 1,\n        \"remaining\": 0,\n        \"reset\": 1690350175693\n    }\n}\n```\n\nLet's understand the response in detail:\n\n- `valid`: This is either `true` or `false` telling us if the key is valid or not.\n\n- `expires`: The UNIX timestamp in milliseconds when the key expires. Here, we've given the user a 30 days trial. So the key expires in 30 days.\n\n- `ratelimit`: Currently, the user is limited to 1 request every 10 seconds. The `limit` param tells us how many more requests the user has left. The `reset` tells us the time when the requests will be refilled. We can use this to show the user how much time is left before they can make another request.\n\n---\n\n## API as a Service Subscription Model\n\nSuppose we want to offer an API as a paid service with subscription tiers. We can easily implement that using Unkey.\n\nConsider the following plans:\n\n| Price      | Requests      | Rate Limit |\n| ---------- | ------------- | ---------- |\n| Free       | 100/month     | 6/min      |\n| $10/month  | 10,000/month  | 100/min    |\n| $100/month | 100,000/month | No limit   |\n\nSuppose the user upgrades to the $10/month plan, then, we can update the rate limit of the key to allow 100 requests per minute. Following is the `/upgradeUser` endpoint that does it. In the following snippet, we're updating the rate limit parameters for the user key.\n\n```javascript\napp.post(\"/upgradeUser\", async (req: Request, res: Response) => {\n  const { transactionId, email, apiKeyId } = req.body;\n\n  // Imaginary transactionId and email validation.\n  // Let's imagine the user upgraded to a paid plan.\n  // Now we have to increase the usage quota of the user.\n  // We can do that by updating the key.\n\n  const myHeaders = new Headers();\n  myHeaders.append(\"Content-Type\", \"application/json\");\n  myHeaders.append(\"Authorization\", `Bearer ${process.env.UNKEY_ROOT_KEY}`);\n\n  const raw = JSON.stringify({\n    keyId: apiKeyId,\n    ratelimit: {\n      async: true, // Fast rate limiting\n      duration: 1000, // Rate limit duration\n      limit: 100, // Maximum allowed requests for the user\n    },\n  });\n\n  const updateKeyRequest = await fetch(\n    \"https://api.unkey.dev/v1/keys.updateKey\",\n    {\n      keyId: \"example_key\"\n      method: \"PUT\",\n      headers: myHeaders,\n      body: raw,\n      redirect: \"follow\",\n    }\n  );\n\n  if (updateKeyRequest.status !== 200)\n    return res.status(400).json({ message: \"Something went wrong\" });\n\n  return res.status(200).json({ message: \"User upgraded successfully\" });\n});\n```\n\nIn the set rate limiting, users are granted 100 requests every minute. If the number of requests surpasses 100 within a single minute, a rate limit will be imposed. However, this limit is reset and replenished every minute, giving users a fresh allocation of 100 requests to use again.\n\n---\n\n## Conclusion\n\nThis tutorial aims to present to you an end-to-end use case scenario of how Unkey can fit and fulfill your requirements. Join our [Discord](https://unkey.com/discord) and get in touch. Share what's on your mind. Give the [Unkey repo a star on GitHub](https://github.com/unkeyed/unkey/) and keep building.",
    "title": "Building an OCR as a Service",
    "description": "Learn how to use Unkey to make an Optical Character Recognition (OCR) API as a service",
    "author": "wilfred",
    "date": "2023-08-10",
    "tags": [
      "tutorials"
    ],
    "image": "/images/blog-images/covers/ocr-service.png",
    "_meta": {
      "filePath": "ocr-service.mdx",
      "fileName": "ocr-service.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "ocr-service"
    },
    "mdx": "var Component=(()=>{var p=Object.create;var d=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var y=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),k=(t,e)=>{for(var r in e)d(t,r,{get:e[r],enumerable:!0})},s=(t,e,r,a)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let i of y(e))!g.call(t,i)&&i!==r&&d(t,i,{get:()=>e[i],enumerable:!(a=u(e,i))||a.enumerable});return t};var w=(t,e,r)=>(r=t!=null?p(m(t)):{},s(e||!t||!t.__esModule?d(r,\"default\",{value:t,enumerable:!0}):r,t)),b=t=>s(d({},\"__esModule\",{value:!0}),t);var l=f((T,h)=>{h.exports=_jsx_runtime});var v={};k(v,{default:()=>c});var n=w(l());function o(t){let e={a:\"a\",code:\"code\",h2:\"h2\",h3:\"h3\",h4:\"h4\",hr:\"hr\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",table:\"table\",tbody:\"tbody\",td:\"td\",th:\"th\",thead:\"thead\",tr:\"tr\",ul:\"ul\",...t.components},{Image:r}=e;return r||I(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.a,{href:\"https://unkey.com\",children:\"Unkey\"}),\" is an open-source API key management tool with real-time API key creation, updating, and verification.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"In this blog, we'll take a look at how we can use Unkey to make an Optical Character Recognition (OCR) API as a service. The OCR API takes in an image and returns the textual characters present in it.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"You can find the complete source code on \",(0,n.jsx)(e.a,{href:\"https://github.com/WilfredAlmeida/unkey-ocr\",children:\"GitHub\"}),\".\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"pre-requisites\",children:\"Pre-requisites\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Signup and get started with the \",(0,n.jsx)(e.a,{href:\"https://unkey.com\",children:\"Unkey\"}),\" dashboard. As soon as you create your account you will be asked to create your workspace. Give it a name, and a slug. The name is shown only to you and not to your users.\"]}),`\n`,(0,n.jsx)(r,{src:\"/images/blog-images/ai-post/create-root-key.png\",alt:\"Create Root Key\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"Then you can create your first API which allows you to track usage as well as segment keys, the name you choose is also not visible to users.\"}),`\n`,(0,n.jsx)(r,{src:\"/images/blog-images/ai-post/create-api.png\",alt:\"Create API\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"The admin dashboard gives you access to several features in a simple-to-use interface. You can create new APIs, issue keys, revoke keys and see usage stats. You can also invite other users to your account so that they can manage your APIs.\"}),`\n`,(0,n.jsx)(r,{src:\"/images/blog-images/ocr-post/3-dashboard.png\",alt:\"Dashboard\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsx)(e.h2,{id:\"project-walkthrough\",children:\"Project Walkthrough\"}),`\n`,(0,n.jsx)(r,{src:\"/images/blog-images/ocr-post/4-walkthrough.gif\",alt:\"Walkthrough\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"The project is an Express API in NodeJS.\"}),`\n`,(0,n.jsx)(e.p,{children:\"It takes an image either as a file or base64 and does OCR on it and returns the resulting text.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"ocr\",children:\"OCR\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"OCR is done via an npm package \",(0,n.jsx)(e.a,{href:\"https://www.npmjs.com/package/tesseract.js\",children:\"tesseract.js\"}),\". Following is its function which takes in the image and recognizes English and Spanish languages.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const doOcr = async (image) => {\n  try {\n    // It detects English and Spanish\n    const { data } = await Tesseract.recognize(image, \"spa+eng\", {\n      logger: (m) => console.log(m),\n    });\n\n    return { data: data, error: null };\n  } catch (error) {\n    console.log(error);\n    return { data: null, error: error };\n  }\n};\n`})}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsx)(e.h2,{id:\"endpoints-explained\",children:\"Endpoints Explained\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.code,{children:\"/signup\"}),\": Sign up for an API key. Returns a JSON object with the API key.\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"It validates the email and provisions and returns an API key. The key is then used to authenticate the OCR endpoints.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Type: \",(0,n.jsx)(e.code,{children:\"POST\"})]}),`\n`,(0,n.jsx)(e.p,{children:\"Body:\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Name\"}),(0,n.jsx)(e.th,{children:\"Type\"}),(0,n.jsx)(e.th,{children:\"Description\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"email\"}),(0,n.jsx)(e.td,{children:\"string\"}),(0,n.jsx)(e.td,{children:\"Email address to sign up with\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"name\"}),(0,n.jsx)(e.td,{children:\"string\"}),(0,n.jsx)(e.td,{children:\"Name of user\"})]})]})]}),`\n`,(0,n.jsx)(e.p,{children:\"Returns:\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Name\"}),(0,n.jsx)(e.th,{children:\"Type\"}),(0,n.jsx)(e.th,{children:\"Description\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"key\"}),(0,n.jsx)(e.td,{children:\"string\"}),(0,n.jsx)(e.td,{children:\"API Key\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"keyId\"}),(0,n.jsx)(e.td,{children:\"string\"}),(0,n.jsx)(e.td,{children:\"API Key ID\"})]})]})]}),`\n`,(0,n.jsxs)(e.ol,{start:\"2\",children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.code,{children:\"/upload\"}),\": Upload an image to perform OCR. Returns a JSON object with the OCR results. It uses the API key to authenticate the request. It then performs OCR on the image and returns the results.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Type: \",(0,n.jsx)(e.code,{children:\"POST\"})]}),`\n`,(0,n.jsx)(e.p,{children:\"Headers:\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Name\"}),(0,n.jsx)(e.th,{children:\"Type\"}),(0,n.jsx)(e.th,{children:\"Description\"})]})}),(0,n.jsx)(e.tbody,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"Bearer\"}),(0,n.jsx)(e.td,{children:\"string\"}),(0,n.jsx)(e.td,{children:\"API key in Bearer auth\"})]})})]}),`\n`,(0,n.jsx)(e.p,{children:\"Body:\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Name\"}),(0,n.jsx)(e.th,{children:\"Type\"}),(0,n.jsx)(e.th,{children:\"Description\"})]})}),(0,n.jsx)(e.tbody,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"sampleFile\"}),(0,n.jsx)(e.td,{children:\"file\"}),(0,n.jsx)(e.td,{children:\"Image to use\"})]})})]}),`\n`,(0,n.jsx)(e.p,{children:\"Returns:\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Name\"}),(0,n.jsx)(e.th,{children:\"Type\"}),(0,n.jsx)(e.th,{children:\"Description\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"text\"}),(0,n.jsx)(e.td,{children:\"string, null\"}),(0,n.jsx)(e.td,{children:\"OCR Results\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"error\"}),(0,n.jsx)(e.td,{children:\"string, null\"}),(0,n.jsx)(e.td,{children:\"Error if any\"})]})]})]}),`\n`,(0,n.jsxs)(e.ol,{start:\"3\",children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.code,{children:\"/uploadBase64\"}),\": Upload a base64 encoded image to perform OCR. Returns a JSON object with the OCR results. It uses the API key to authenticate the request. It then performs OCR on the image and returns the results.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Type: \",(0,n.jsx)(e.code,{children:\"POST\"})]}),`\n`,(0,n.jsx)(e.p,{children:\"Headers:\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Name\"}),(0,n.jsx)(e.th,{children:\"Type\"}),(0,n.jsx)(e.th,{children:\"Description\"})]})}),(0,n.jsx)(e.tbody,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"Bearer\"}),(0,n.jsx)(e.td,{children:\"string\"}),(0,n.jsx)(e.td,{children:\"API key in Bearer auth\"})]})})]}),`\n`,(0,n.jsx)(e.p,{children:\"Body:\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Name\"}),(0,n.jsx)(e.th,{children:\"Type\"}),(0,n.jsx)(e.th,{children:\"Description\"})]})}),(0,n.jsx)(e.tbody,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"imageBase64\"}),(0,n.jsx)(e.td,{children:\"string\"}),(0,n.jsx)(e.td,{children:\"Base64 encoded image\"})]})})]}),`\n`,(0,n.jsx)(e.p,{children:\"Returns:\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Name\"}),(0,n.jsx)(e.th,{children:\"Type\"}),(0,n.jsx)(e.th,{children:\"Description\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"text\"}),(0,n.jsx)(e.td,{children:\"string, null\"}),(0,n.jsx)(e.td,{children:\"OCR Results\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"error\"}),(0,n.jsx)(e.td,{children:\"string, null\"}),(0,n.jsx)(e.td,{children:\"Error if any\"})]})]})]}),`\n`,(0,n.jsxs)(e.ol,{start:\"4\",children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.code,{children:\"/upgradeUser\"}),`: Upgrade a user to a paid plan. It validates an imaginary transaction id and then upgrades the user.\nIt increases the usage limit of the user based on the subscription the user has purchased.`]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Type: \",(0,n.jsx)(e.code,{children:\"POST\"})]}),`\n`,(0,n.jsx)(e.p,{children:\"Headers: None\"}),`\n`,(0,n.jsx)(e.p,{children:\"Body:\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Name\"}),(0,n.jsx)(e.th,{children:\"Type\"}),(0,n.jsx)(e.th,{children:\"Description\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"email\"}),(0,n.jsx)(e.td,{children:\"string\"}),(0,n.jsx)(e.td,{children:\"Email address of the user\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"transactionId\"}),(0,n.jsx)(e.td,{children:\"string\"}),(0,n.jsx)(e.td,{children:\"Imaginary transaction id\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"apiKeyId\"}),(0,n.jsx)(e.td,{children:\"string\"}),(0,n.jsx)(e.td,{children:\"Id of the API key to be updated. It is returned when a key is created.\"})]})]})]}),`\n`,(0,n.jsx)(e.p,{children:\"Returns: None\"}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsx)(e.h2,{id:\"understanding-unkey-api-key-authentication\",children:\"Understanding Unkey API key authentication\"}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey uses fast and efficient on-the-edge systems to verify a key. It adds less than 40ms to our requests.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The key is provisioned per user in the \",(0,n.jsx)(e.code,{children:\"/signup\"}),\" route. The user can then use the key to authenticate requests to the OCR endpoints.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-javascript\",children:`// /signUp endpoint\napp.post(\"/signUp\", async (req: Request, res: Response) => {\n  const { name = \"John Doe\", email = \"john@example.com\" } = req.body;\n\n  // Imaginary name and email validation\n\n  const myHeaders = new Headers();\n  myHeaders.append(\"Authorization\", \\`Bearer \\${process.env.UNKEY_ROOT_KEY}\\`);\n  myHeaders.append(\"Content-Type\", \"application/json\");\n\n  const raw = JSON.stringify({\n    apiId: process.env.UNKEY_API_ID,\n    prefix: \"ocr\",\n    byteLength: 16,\n    ownerId: email,\n    meta: {\n      name: name,\n      email: email,\n    },\n    expires: Date.now() + 2592000000 // 30 days from now\n    ratelimit: {\n      duration: 1000,\n      limit: 1,\n    },\n  });\n\n\n  const createKeyResponse = await fetch(\n    \"https://api.unkey.dev/v1/keys.createKey\",\n    {\n      method: \"POST\",\n      headers: myHeaders,\n      body: raw,\n      redirect: \"follow\",\n    },\n  );\n  const createKeyResponseJson = await createKeyResponse.json();\n\n  if (createKeyResponseJson.error)\n    return res\n      .status(400)\n      .json({ error: createKeyResponseJson.error, keys: null });\n\n  return res.status(200).json({ keys: [createKeyResponseJson], error: null });\n});\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"The user then has to send the API key in the \",(0,n.jsx)(e.code,{children:\"Authorization\"}),\" header as a \",(0,n.jsx)(e.code,{children:\"Bearer\"}),\" token. To verify the key, a simple API call is made to Unkey. More on this further ahead.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"To verify the key, we've made a middleware in the \",(0,n.jsx)(e.code,{children:\"middleware.ts\"}),\" file.\"]}),`\n`,(0,n.jsx)(e.h3,{id:\"key-creation\",children:\"Key Creation\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"As shown in the above code block, the key is created in the \",(0,n.jsx)(e.code,{children:\"/signup\"}),\" route in \",(0,n.jsx)(e.code,{children:\"index.ts\"}),\".\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Its params are explained in detail in the official \",(0,n.jsx)(e.a,{href:\"https://unkey.com/docs/api-reference/keys/create\",children:\"docs\"})]}),`\n`,(0,n.jsx)(e.p,{children:\"Following is a description of the params used in this example:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"apiId\"}),\": The API ID to create the key for. You create this API in the Unkey dashboard.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"prefix\"}),\": The prefix to use for the key. Every key is prefixed with this. This is useful to identify the key's purpose. For eg. we can have prefixes like \",(0,n.jsx)(e.code,{children:\"user_\"}),\", \",(0,n.jsx)(e.code,{children:\"admin_\"}),\", \",(0,n.jsx)(e.code,{children:\"service_\"}),\", \",(0,n.jsx)(e.code,{children:\"staging_\"}),\", \",(0,n.jsx)(e.code,{children:\"trial_\"}),\", \",(0,n.jsx)(e.code,{children:\"production_\"}),\" etc.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"byteLength\"}),\": The byte length used to generate the key determines its entropy as well as its length. Higher is better, but keys become longer and more annoying to handle. The default is 16 bytes or 2^128 possible combinations.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"ownerId\"}),\": This can be any string. In this example, we're using the user's email address as the id. By doing this we'll be able to verify the appropriate owner of the key.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"meta\"}),\": Any metadata information we want to store with the key. In this example, we're storing the user's name and email.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"expires\"}),\": Keys can be auto-expired by providing a UNIX timestamp in milliseconds. Once keys expire they will automatically be deleted and are no longer valid.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"rateLimit\"}),\": Keys can be rate limited by certain parameters. This is extremely beneficial as it prevents abuse of our API. The rate limit is enforced on the edge, so it's extremely fast and efficient. The rate limit params we've used in this example are:\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"type\"}),\": Type of the rate limit. Read more: \",(0,n.jsx)(e.a,{href:\"https://unkey.com/docs/features/ratelimiting\",children:\"Rate Limiting\"})]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"limit\"}),\": The number of requests allowed in the given time\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"refill\"}),\": The number of requests to refill in the given time\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"refillInterval\"}),\": The interval by which the requests are refilled\"]}),`\n`]}),`\n`]}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"In the rate limit set in the \",(0,n.jsx)(e.code,{children:\"/signUp\"}),\" route, the user is on a trial plan and is allowed 1 request every 10 seconds.\"]}),`\n`,(0,n.jsx)(e.h3,{id:\"key-verification\",children:\"Key Verification\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The API key verification is done in the \",(0,n.jsx)(e.code,{children:\"middleware.ts\"}),\" file. We're making an API call to the Unkey API to verify the key by passing the \",(0,n.jsx)(e.code,{children:\"key\"}),\" into the request body.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-javascript\",children:`import { Request, Response, NextFunction } from \"express\";\n\n// An Express Middleware\nconst verifyApiKey = async (\n  req: Request,\n  res: Response,\n  next: NextFunction\n) => {\n  const authHeader = req.headers.authorization;\n  if (authHeader) {\n    // Get the token from request headers\n    const token = authHeader.split(\" \")[1].trim();\n\n    try {\n      const myHeaders = new Headers();\n      myHeaders.append(\"Content-Type\", \"application/json\");\n\n      const raw = JSON.stringify({\n        key: token,\n      });\n\n      const verifyKeyResponse = await fetch(\n        \"https://api.unkey.dev/v1/keys.verifyKey\",\n        {\n          method: \"POST\",\n          headers: myHeaders,\n          body: raw,\n          redirect: \"follow\",\n        }\n      );\n      const verifyKeyResponseJson = await verifyKeyResponse.json();\n\n      if (\n        !verifyKeyResponseJson.valid &&\n        verifyKeyResponseJson.code === \"RATE_LIMITED\"\n      )\n        return res.status(429).json({ message: \"RATE_LIMITED\" });\n\n      if (!verifyKeyResponseJson.valid)\n        return res.status(401).json({ message: \"Unauthorized\" });\n\n      next();\n    } catch (err) {\n      console.log(\"ERROR: \", err);\n      return res.status(401).json({ message: \"Unauthorized\" });\n    }\n  } else {\n    return res.status(401).json({ message: \"Unauthorized\" });\n  }\n};\n\nexport default verifyApiKey;\n`})}),`\n`,(0,n.jsx)(e.h4,{id:\"key-verification-response\",children:\"Key verification response\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-json\",children:`{\n    \"valid\": true,\n    \"ownerId\": \"john@example.com\",\n    \"meta\": {\n        \"email\": \"john@example.com\",\n        \"name\": \"John Doe\"\n    },\n    \"expires\": Date.now() + 2592000000 // 30 days from now\n    \"ratelimit\": {\n        \"limit\": 1,\n        \"remaining\": 0,\n        \"reset\": 1690350175693\n    }\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Let's understand the response in detail:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"valid\"}),\": This is either \",(0,n.jsx)(e.code,{children:\"true\"}),\" or \",(0,n.jsx)(e.code,{children:\"false\"}),\" telling us if the key is valid or not.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"expires\"}),\": The UNIX timestamp in milliseconds when the key expires. Here, we've given the user a 30 days trial. So the key expires in 30 days.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"ratelimit\"}),\": Currently, the user is limited to 1 request every 10 seconds. The \",(0,n.jsx)(e.code,{children:\"limit\"}),\" param tells us how many more requests the user has left. The \",(0,n.jsx)(e.code,{children:\"reset\"}),\" tells us the time when the requests will be refilled. We can use this to show the user how much time is left before they can make another request.\"]}),`\n`]}),`\n`]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsx)(e.h2,{id:\"api-as-a-service-subscription-model\",children:\"API as a Service Subscription Model\"}),`\n`,(0,n.jsx)(e.p,{children:\"Suppose we want to offer an API as a paid service with subscription tiers. We can easily implement that using Unkey.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Consider the following plans:\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Price\"}),(0,n.jsx)(e.th,{children:\"Requests\"}),(0,n.jsx)(e.th,{children:\"Rate Limit\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"Free\"}),(0,n.jsx)(e.td,{children:\"100/month\"}),(0,n.jsx)(e.td,{children:\"6/min\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"$10/month\"}),(0,n.jsx)(e.td,{children:\"10,000/month\"}),(0,n.jsx)(e.td,{children:\"100/min\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"$100/month\"}),(0,n.jsx)(e.td,{children:\"100,000/month\"}),(0,n.jsx)(e.td,{children:\"No limit\"})]})]})]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Suppose the user upgrades to the $10/month plan, then, we can update the rate limit of the key to allow 100 requests per minute. Following is the \",(0,n.jsx)(e.code,{children:\"/upgradeUser\"}),\" endpoint that does it. In the following snippet, we're updating the rate limit parameters for the user key.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-javascript\",children:`app.post(\"/upgradeUser\", async (req: Request, res: Response) => {\n  const { transactionId, email, apiKeyId } = req.body;\n\n  // Imaginary transactionId and email validation.\n  // Let's imagine the user upgraded to a paid plan.\n  // Now we have to increase the usage quota of the user.\n  // We can do that by updating the key.\n\n  const myHeaders = new Headers();\n  myHeaders.append(\"Content-Type\", \"application/json\");\n  myHeaders.append(\"Authorization\", \\`Bearer \\${process.env.UNKEY_ROOT_KEY}\\`);\n\n  const raw = JSON.stringify({\n    keyId: apiKeyId,\n    ratelimit: {\n      async: true, // Fast rate limiting\n      duration: 1000, // Rate limit duration\n      limit: 100, // Maximum allowed requests for the user\n    },\n  });\n\n  const updateKeyRequest = await fetch(\n    \"https://api.unkey.dev/v1/keys.updateKey\",\n    {\n      keyId: \"example_key\"\n      method: \"PUT\",\n      headers: myHeaders,\n      body: raw,\n      redirect: \"follow\",\n    }\n  );\n\n  if (updateKeyRequest.status !== 200)\n    return res.status(400).json({ message: \"Something went wrong\" });\n\n  return res.status(200).json({ message: \"User upgraded successfully\" });\n});\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"In the set rate limiting, users are granted 100 requests every minute. If the number of requests surpasses 100 within a single minute, a rate limit will be imposed. However, this limit is reset and replenished every minute, giving users a fresh allocation of 100 requests to use again.\"}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"This tutorial aims to present to you an end-to-end use case scenario of how Unkey can fit and fulfill your requirements. Join our \",(0,n.jsx)(e.a,{href:\"https://unkey.com/discord\",children:\"Discord\"}),\" and get in touch. Share what's on your mind. Give the \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/unkey/\",children:\"Unkey repo a star on GitHub\"}),\" and keep building.\"]})]})}function c(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(o,{...t})}):o(t)}function I(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return b(v);})();\n;return Component;",
    "slug": "ocr-service",
    "url": "/blog/ocr-service",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Pre-requisites",
        "slug": "pre-requisites"
      },
      {
        "level": 2,
        "text": "Project Walkthrough",
        "slug": "project-walkthrough"
      },
      {
        "level": 3,
        "text": "OCR",
        "slug": "ocr"
      },
      {
        "level": 2,
        "text": "Endpoints Explained",
        "slug": "endpoints-explained"
      },
      {
        "level": 2,
        "text": "Understanding Unkey API key authentication",
        "slug": "understanding-unkey-api-key-authentication"
      },
      {
        "level": 3,
        "text": "Key Creation",
        "slug": "key-creation"
      },
      {
        "level": 3,
        "text": "Key Verification",
        "slug": "key-verification"
      },
      {
        "level": 4,
        "text": "Key verification response",
        "slug": "key-verification-response"
      },
      {
        "level": 2,
        "text": "API as a Service Subscription Model",
        "slug": "api-as-a-service-subscription-model"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "Unkey just launched our [API Playground!](https://play.unkey.com) This is a try-before-you-buy experience that allows developers to gain a basic understanding of Unkey's features.\n\n## What Is It\n\nThe Unkey [API Playground](https://play.unkey.com) is a playground Yes, it's just a place to test our API before committing to an Unkey account. It is set up to guide you through a typical use case with an interactive experience. This meets the definition I found most interesting on dictionary.com: an arena of operation or activity.\n\n<Image src=\"/images/blog-images/playground-launch/playground.gif\" alt=\"Using the playground\" width=\"1920\" height=\"1080\"/>\n\n## No Strings Attached\n\nYou do not need to sign up for an account until you're ready to start authenticating your API. Navigate to the API Playground and mess around all you like. The Playground showcases the most common uses of Unkey, our API keys. While it's not an exhaustive list of features Unkey provides, it's a good starting point for new users.\n\n## Using The Playground\n\nThe process is simple and user-friendly:\n\n1. Visit the Unkey [API Playground](https://play.unkey.com) webpage.\n2. Use the interactive experience to learn about the features of unkey.\n3. View real-time responses of each of our API calls.\n\nThe playground is structured linearly and uses actual Unkey API calls. You're encouraged to experiment with your own inputs, but you can, of course, use the prefilled examples. It's simple and quick so you can get back to coding what you love.\n\n## Why did we build the playground?\nWe built our playground because we wanted to give you the ability to test out our most popular features in a sandboxed environment. Whether you are a new developer exploring API authentication for the first time or a seasoned developer who wants to skip the docs and see it in real-time, we have you covered.\nIn any case, if you or your company are seeking API authentication, then Unkey is a quick and efficient solution to consider, and the [API Playground](https://play.unkey.com) is a good starting point.\n\n## Conclusion\nSo jump into our [API Playground](https://play.unkey.com) and mess around. Make some calls and get a feel for how Unkey works. If you are one of the first to complete our playground and sign up for an Unkey account, we will send you some swag! Feel free to jump into our [Discord](https://unkey.com/discord) and ask questions or tell us your thoughts.",
    "title": "Unkey Playground",
    "description": "A new page for interested developers to see what Unkey is about.",
    "author": "michael",
    "date": "2024-06-24",
    "tags": [
      "launchweek",
      "marketing"
    ],
    "image": "/images/blog-images/covers/playground.png",
    "_meta": {
      "filePath": "playground.mdx",
      "fileName": "playground.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "playground"
    },
    "mdx": "var Component=(()=>{var h=Object.create;var a=Object.defineProperty;var y=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var m=(o,e)=>()=>(e||o((e={exports:{}}).exports,e),e.exports),k=(o,e)=>{for(var t in e)a(o,t,{get:e[t],enumerable:!0})},s=(o,e,t,r)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let i of p(e))!f.call(o,i)&&i!==t&&a(o,i,{get:()=>e[i],enumerable:!(r=y(e,i))||r.enumerable});return o};var w=(o,e,t)=>(t=o!=null?h(g(o)):{},s(e||!o||!o.__esModule?a(t,\"default\",{value:o,enumerable:!0}):t,o)),I=o=>s(a({},\"__esModule\",{value:!0}),o);var l=m((v,u)=>{u.exports=_jsx_runtime});var x={};k(x,{default:()=>c});var n=w(l());function d(o){let e={a:\"a\",h2:\"h2\",li:\"li\",ol:\"ol\",p:\"p\",...o.components},{Image:t}=e;return t||P(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\"Unkey just launched our \",(0,n.jsx)(e.a,{href:\"https://play.unkey.com\",children:\"API Playground!\"}),\" This is a try-before-you-buy experience that allows developers to gain a basic understanding of Unkey's features.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"what-is-it\",children:\"What Is It\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The Unkey \",(0,n.jsx)(e.a,{href:\"https://play.unkey.com\",children:\"API Playground\"}),\" is a playground\\u2026 Yes, it's just a place to test our API before committing to an Unkey account. It is set up to guide you through a typical use case with an interactive experience. This meets the definition I found most interesting on dictionary.com: \\u201Can arena of operation or activity.\\u201D\"]}),`\n`,(0,n.jsx)(t,{src:\"/images/blog-images/playground-launch/playground.gif\",alt:\"Using the playground\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.h2,{id:\"no-strings-attached\",children:\"No Strings Attached\"}),`\n`,(0,n.jsx)(e.p,{children:\"You do not need to sign up for an account until you're ready to start authenticating your API. Navigate to the API Playground and mess around all you like. The Playground showcases the most common uses of Unkey, our API keys. While it's not an exhaustive list of features Unkey provides, it's a good starting point for new users.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"using-the-playground\",children:\"Using The Playground\"}),`\n`,(0,n.jsx)(e.p,{children:\"The process is simple and user-friendly:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[\"Visit the Unkey \",(0,n.jsx)(e.a,{href:\"https://play.unkey.com\",children:\"API Playground\"}),\" webpage.\"]}),`\n`,(0,n.jsx)(e.li,{children:\"Use the interactive experience to learn about the features of unkey.\"}),`\n`,(0,n.jsx)(e.li,{children:\"View real-time responses of each of our API calls.\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"The playground is structured linearly and uses actual Unkey API calls. You're encouraged to experiment with your own inputs, but you can, of course, use the prefilled examples. It's simple and quick so you can get back to coding what you love.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"why-did-we-build-the-playground\",children:\"Why did we build the playground?\"}),`\n`,(0,n.jsxs)(e.p,{children:[`We built our playground because we wanted to give you the ability to test out our most popular features in a sandboxed environment. Whether you are a new developer exploring API authentication for the first time or a seasoned developer who wants to skip the docs and see it in real-time, we have you covered.\nIn any case, if you or your company are seeking API authentication, then Unkey is a quick and efficient solution to consider, and the `,(0,n.jsx)(e.a,{href:\"https://play.unkey.com\",children:\"API Playground\"}),\" is a good starting point.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"So jump into our \",(0,n.jsx)(e.a,{href:\"https://play.unkey.com\",children:\"API Playground\"}),\" and mess around. Make some calls and get a feel for how Unkey works. If you are one of the first to complete our playground and sign up for an Unkey account, we will send you some swag! Feel free to jump into our \",(0,n.jsx)(e.a,{href:\"https://unkey.com/discord\",children:\"Discord\"}),\" and ask questions or tell us your thoughts.\"]})]})}function c(o={}){let{wrapper:e}=o.components||{};return e?(0,n.jsx)(e,{...o,children:(0,n.jsx)(d,{...o})}):d(o)}function P(o,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+o+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return I(x);})();\n;return Component;",
    "slug": "playground",
    "url": "/blog/playground",
    "tableOfContents": [
      {
        "level": 2,
        "text": "What Is It",
        "slug": "what-is-it"
      },
      {
        "level": 2,
        "text": "No Strings Attached",
        "slug": "no-strings-attached"
      },
      {
        "level": 2,
        "text": "Using The Playground",
        "slug": "using-the-playground"
      },
      {
        "level": 2,
        "text": "Why did we build the playground?",
        "slug": "why-did-we-build-the-playground"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "Ratelimiting is not just a feature; it's a lifeline for production applications. Without it, you could face a skyrocketing bill. Your server could be pushed to its limits, leaving real users stranded and your application's reputation at stake.\n\nUnkey provides ratelimiting that is distributed globally and can be easily added to any server, ensuring your protection. We will discuss the features of our service, including synchronous and asynchronous protection, identifier overrides, and how our analytical data can help you identify spikes in usage and how it can be used in a tRPC application.\n\n## Prerequisites\n\nTo get up and running with the app and follow along, you need:\n\n- A fundamental understanding of Next.js, primarily regarding routes and server-side data loading.\n- Basic familiarity with tRPC.\n- An application with user authentication implemented. This example uses Auth.js, but you can use any provider you like.\n- Access to your `UNKEY_ROOT_KEY`, which you can get by signing up for a free account\n\nIn this post, we will use create-t3-app for the demo, so feel free to use that if you want an easy way to use tRPC + Auth.js in a Next.js application.\n\n## Installing the `@unkey/ratelimit` package\n\nBefore we start coding, we need to install the `@unkey/ratelimit` package. This package gives you access to Unkey's API with type safety.\n\n```bash\nnpm install @unkey/ratelimit\n```\n\n### Updating our env\n\nWe need to use the `UNKEY_ROOT_KEY` to run our ratelimiting package, so we must first update the `env.js` file in the `src` directory. Add `UNKEY_ROOT_KEY: z.string()` to the `server` object and `UNKEY_ROOT_KEY: process.env.UNKEY_ROOT_KEY` to the `runtimeEnv` object.\n\nNow that it is updated add your Unkey root key to your .env as `UNKEY_ROOT_KEY` which can be found in the Unkey dashboard under settings Root Keys.\n\n## Adding ratelimiting to a procedure\n\nNow that the package is installed and our `.env` has been updated, we can configure our ratelimiter. Inside the `server/api/routers/post` file, we have a `create` procedure. This procedure allows users to create posts; currently, users can create as many as they like and as quickly as they like.\n\n### Configure our ratelimiter\n\nIn this example, we will configure our ratelimiter in the procedure itself. Of course, you can abstract this into a utility file if you prefer. First, we must import `Ratelimit` from the `@unkey/ratelimit` package and `TRPCError` and `env`.\n\n```typescript\nimport { z } from \"zod\";\n\nimport {\n  createTRPCRouter,\n  protectedProcedure,\n  publicProcedure,\n} from \"~/server/api/trpc\";\nimport { posts } from \"~/server/db/schema\";\nimport { env } from \"~/env\";\nimport { TRPCError } from \"@trpc/server\";\nimport { Ratelimit } from \"@unkey/ratelimit\";\n```\n\nTo configure the Ratelimiter, we need to pass four things along, the root key, the namespace, the limit, and the duration of our ratelimiting. Inside the mutation, add the following:\n\n```typescript\nconst unkey = new Ratelimit({\n  rootKey: env.UNKEY_ROOT_KEY,\n  namespace: \"posts.create\",\n  limit: 3,\n  duration: \"5s\",\n});\n```\n\nThe namespace can be anything, but we are using the tRPC route and procedure to make it easier to track in Unkey's analytics. We now have the ability to rate-limit this procedure, allowing only three requests per five seconds.\n\n### Using our ratelimiting\n\nTo use the ratelimit, we need an identifier. This can be anything you like, such as a user ID or an IP address. We will be using our user's ID as they are required to be logged in to create a new post. Then, we can call `unkey.limit` with the identifier, and unkey will return a boolean of true or false, which we can use to make a decision.\n\n```typescript\nconst { success } = await unkey.limit(ctx.session.user.id);\n```\n\nSo now we have the boolean we can check if it's false and then throw a TRPCError telling the user they have been ratelimited and stop any more logic running.\n\n```typescript\nconst { success } = await unkey.limit(ctx.session.user.id);\n\nif (!success) {\n  throw new TRPCError({ code: \"TOO_MANY_REQUESTS\" });\n}\n```\n\nAt this point, our code is ready to test. Give it a whirl, and try posting multiple times. You will see that the posts won't update anymore after you are rate-limited.\n\n## What about more expensive requests?\n\nUnkey allows you to tell us how expensive a request should be. For example, maybe you have an AI route that costs you a lot more than any other route, so you want to reduce the number of requests that can be used.\n\n```typescript\nconst { success } = await unkey.limit(ctx.session.user.id, {\n  cost: 3,\n});\n```\n\nThis request costs three instead of one, giving you extra flexibility around expensive routes.\n\n## Faster response\n\nAlthough Unkey response times are fast, there are some cases where you are willing to give up some accuracy in favor of quicker response times. You can use our `async` option, which has 98% accuracy, but we don't need to confirm the limit with the origin before returning a decision. You can set this either on the `limit` request or on the configuration itself.\n\n```typescript\nconst unkey = new Ratelimit({\n  rootKey: env.UNKEY_ROOT_KEY,\n  namespace: \"posts.create\",\n  limit: 3,\n  duration: \"5s\",\n  async: true,\n});\n\n// or\n\nconst { success } = await unkey.limit(ctx.session.user.id, {\n  async: true,\n});\n```\n\nWhile this is a small overview of using Unkey's ratelimiting with tRPC, we also offer other features that aren't covered here, including:\n\n- Overrides for specific identifiers\n- Metadata\n- Resources flagging\n\nYou can read more about those features in our documentation on [Ratelimiting](https://www.unkey.com/docs/ratelimiting/introduction).",
    "title": "How to ratelimit tRPC routes with Unkey",
    "description": "Learn how to use Unkey to ratelimit tRPC routes in your Next.js application.",
    "author": "james",
    "date": "2024-05-17",
    "tags": [
      "tutorials"
    ],
    "image": "/images/blog-images/covers/trpc-ratelimit.png",
    "_meta": {
      "filePath": "ratelimit-trpc-routes.mdx",
      "fileName": "ratelimit-trpc-routes.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "ratelimit-trpc-routes"
    },
    "mdx": "var Component=(()=>{var h=Object.create;var a=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(i,e)=>()=>(e||i((e={exports:{}}).exports,e),e.exports),w=(i,e)=>{for(var t in e)a(i,t,{get:e[t],enumerable:!0})},s=(i,e,t,o)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of m(e))!g.call(i,r)&&r!==t&&a(i,r,{get:()=>e[r],enumerable:!(o=p(e,r))||o.enumerable});return i};var k=(i,e,t)=>(t=i!=null?h(y(i)):{},s(e||!i||!i.__esModule?a(t,\"default\",{value:i,enumerable:!0}):t,i)),v=i=>s(a({},\"__esModule\",{value:!0}),i);var l=f((T,c)=>{c.exports=_jsx_runtime});var b={};w(b,{default:()=>u});var n=k(l());function d(i){let e={a:\"a\",code:\"code\",h2:\"h2\",h3:\"h3\",li:\"li\",p:\"p\",pre:\"pre\",ul:\"ul\",...i.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"Ratelimiting is not just a feature; it's a lifeline for production applications. Without it, you could face a skyrocketing bill. Your server could be pushed to its limits, leaving real users stranded and your application's reputation at stake.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey provides ratelimiting that is distributed globally and can be easily added to any server, ensuring your protection. We will discuss the features of our service, including synchronous and asynchronous protection, identifier overrides, and how our analytical data can help you identify spikes in usage and how it can be used in a tRPC application.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"prerequisites\",children:\"Prerequisites\"}),`\n`,(0,n.jsx)(e.p,{children:\"To get up and running with the app and follow along, you need:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"A fundamental understanding of Next.js, primarily regarding routes and server-side data loading.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Basic familiarity with tRPC.\"}),`\n`,(0,n.jsx)(e.li,{children:\"An application with user authentication implemented. This example uses Auth.js, but you can use any provider you like.\"}),`\n`,(0,n.jsxs)(e.li,{children:[\"Access to your \",(0,n.jsx)(e.code,{children:\"UNKEY_ROOT_KEY\"}),\", which you can get by signing up for a free account\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"In this post, we will use create-t3-app for the demo, so feel free to use that if you want an easy way to use tRPC + Auth.js in a Next.js application.\"}),`\n`,(0,n.jsxs)(e.h2,{id:\"installing-the-unkeyratelimit-package\",children:[\"Installing the \",(0,n.jsx)(e.code,{children:\"@unkey/ratelimit\"}),\" package\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Before we start coding, we need to install the \",(0,n.jsx)(e.code,{children:\"@unkey/ratelimit\"}),\" package. This package gives you access to Unkey's API with type safety.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`npm install @unkey/ratelimit\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"updating-our-env\",children:\"Updating our env\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"We need to use the \",(0,n.jsx)(e.code,{children:\"UNKEY_ROOT_KEY\"}),\" to run our ratelimiting package, so we must first update the \",(0,n.jsx)(e.code,{children:\"env.js\"}),\" file in the \",(0,n.jsx)(e.code,{children:\"src\"}),\" directory. Add \",(0,n.jsx)(e.code,{children:\"UNKEY_ROOT_KEY: z.string()\"}),\" to the \",(0,n.jsx)(e.code,{children:\"server\"}),\" object and \",(0,n.jsx)(e.code,{children:\"UNKEY_ROOT_KEY: process.env.UNKEY_ROOT_KEY\"}),\" to the \",(0,n.jsx)(e.code,{children:\"runtimeEnv\"}),\" object.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Now that it is updated add your Unkey root key to your .env as \",(0,n.jsx)(e.code,{children:\"UNKEY_ROOT_KEY\"}),\" which can be found in the Unkey dashboard under settings Root Keys.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"adding-ratelimiting-to-a-procedure\",children:\"Adding ratelimiting to a procedure\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Now that the package is installed and our \",(0,n.jsx)(e.code,{children:\".env\"}),\" has been updated, we can configure our ratelimiter. Inside the \",(0,n.jsx)(e.code,{children:\"server/api/routers/post\"}),\" file, we have a \",(0,n.jsx)(e.code,{children:\"create\"}),\" procedure. This procedure allows users to create posts; currently, users can create as many as they like and as quickly as they like.\"]}),`\n`,(0,n.jsx)(e.h3,{id:\"configure-our-ratelimiter\",children:\"Configure our ratelimiter\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"In this example, we will configure our ratelimiter in the procedure itself. Of course, you can abstract this into a utility file if you prefer. First, we must import \",(0,n.jsx)(e.code,{children:\"Ratelimit\"}),\" from the \",(0,n.jsx)(e.code,{children:\"@unkey/ratelimit\"}),\" package and \",(0,n.jsx)(e.code,{children:\"TRPCError\"}),\" and \",(0,n.jsx)(e.code,{children:\"env\"}),\".\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { z } from \"zod\";\n\nimport {\n  createTRPCRouter,\n  protectedProcedure,\n  publicProcedure,\n} from \"~/server/api/trpc\";\nimport { posts } from \"~/server/db/schema\";\nimport { env } from \"~/env\";\nimport { TRPCError } from \"@trpc/server\";\nimport { Ratelimit } from \"@unkey/ratelimit\";\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"To configure the Ratelimiter, we need to pass four things along, the root key, the namespace, the limit, and the duration of our ratelimiting. Inside the mutation, add the following:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const unkey = new Ratelimit({\n  rootKey: env.UNKEY_ROOT_KEY,\n  namespace: \"posts.create\",\n  limit: 3,\n  duration: \"5s\",\n});\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"The namespace can be anything, but we are using the tRPC route and procedure to make it easier to track in Unkey's analytics. We now have the ability to rate-limit this procedure, allowing only three requests per five seconds.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"using-our-ratelimiting\",children:\"Using our ratelimiting\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"To use the ratelimit, we need an identifier. This can be anything you like, such as a user ID or an IP address. We will be using our user's ID as they are required to be logged in to create a new post. Then, we can call \",(0,n.jsx)(e.code,{children:\"unkey.limit\"}),\" with the identifier, and unkey will return a boolean of true or false, which we can use to make a decision.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const { success } = await unkey.limit(ctx.session.user.id);\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"So now we have the boolean we can check if it's false and then throw a TRPCError telling the user they have been ratelimited and stop any more logic running.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const { success } = await unkey.limit(ctx.session.user.id);\n\nif (!success) {\n  throw new TRPCError({ code: \"TOO_MANY_REQUESTS\" });\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"At this point, our code is ready to test. Give it a whirl, and try posting multiple times. You will see that the posts won't update anymore after you are rate-limited.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"what-about-more-expensive-requests\",children:\"What about more expensive requests?\"}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey allows you to tell us how expensive a request should be. For example, maybe you have an AI route that costs you a lot more than any other route, so you want to reduce the number of requests that can be used.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const { success } = await unkey.limit(ctx.session.user.id, {\n  cost: 3,\n});\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"This request costs three instead of one, giving you extra flexibility around expensive routes.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"faster-response\",children:\"Faster response\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Although Unkey response times are fast, there are some cases where you are willing to give up some accuracy in favor of quicker response times. You can use our \",(0,n.jsx)(e.code,{children:\"async\"}),\" option, which has 98% accuracy, but we don't need to confirm the limit with the origin before returning a decision. You can set this either on the \",(0,n.jsx)(e.code,{children:\"limit\"}),\" request or on the configuration itself.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const unkey = new Ratelimit({\n  rootKey: env.UNKEY_ROOT_KEY,\n  namespace: \"posts.create\",\n  limit: 3,\n  duration: \"5s\",\n  async: true,\n});\n\n// or\n\nconst { success } = await unkey.limit(ctx.session.user.id, {\n  async: true,\n});\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"While this is a small overview of using Unkey's ratelimiting with tRPC, we also offer other features that aren't covered here, including:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Overrides for specific identifiers\"}),`\n`,(0,n.jsx)(e.li,{children:\"Metadata\"}),`\n`,(0,n.jsx)(e.li,{children:\"Resources flagging\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"You can read more about those features in our documentation on \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/ratelimiting/introduction\",children:\"Ratelimiting\"}),\".\"]})]})}function u(i={}){let{wrapper:e}=i.components||{};return e?(0,n.jsx)(e,{...i,children:(0,n.jsx)(d,{...i})}):d(i)}return v(b);})();\n;return Component;",
    "slug": "ratelimit-trpc-routes",
    "url": "/blog/ratelimit-trpc-routes",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Prerequisites",
        "slug": "prerequisites"
      },
      {
        "level": 2,
        "text": "Installing the `@unkey/ratelimit` package",
        "slug": "installing-the-unkeyratelimit-package"
      },
      {
        "level": 3,
        "text": "Updating our env",
        "slug": "updating-our-env"
      },
      {
        "level": 2,
        "text": "Adding ratelimiting to a procedure",
        "slug": "adding-ratelimiting-to-a-procedure"
      },
      {
        "level": 3,
        "text": "Configure our ratelimiter",
        "slug": "configure-our-ratelimiter"
      },
      {
        "level": 3,
        "text": "Using our ratelimiting",
        "slug": "using-our-ratelimiting"
      },
      {
        "level": 2,
        "text": "What about more expensive requests?",
        "slug": "what-about-more-expensive-requests"
      },
      {
        "level": 2,
        "text": "Faster response",
        "slug": "faster-response"
      }
    ]
  },
  {
    "content": "## Understanding OTP\nA One-Time Password (OTP) is a unique code valid for only one login session or transaction. It adds an extra layer of security by preventing fraudulent access to your accounts, even if someone else knows your password.\nYou've likely encountered OTPs many times. For instance, when logging into your bank account from a new device, you may receive an OTP via SMS or email, which you must enter to verify your identity. Another typical example is the login flow, where instead of entering a password, an OTP is sent to your email. \n\nWithout ratelimiting, an attacker could try several OTPs in quick succession in a so-called 'brute force attack' to find the right one to gain access to an account.\n\nBy limiting the number of OTP attempts within a specific timeframe, it becomes practically impossible for an attacker to guess the right OTP before it expires.\n\n## Implementing ratelimiting\n\n### Prerequisites\n\n- [Unkey account](https://app.unkey.com)\n- Unkey root key with permissions `create_namespace`, `limit`\n\nIf you prefer, you can use our example here and skip the entire tutorial below. Also, if you want to see it live, you can see an implementation below using Unkey and Resend [here](https://otp-example.vercel.app/)\n\nBefore we begin with the tutorial, it should be stated that OTP implementations will have two separate requests: sending the OTP via email or SMS and verifying the request.\n\nLets start with the sending of an OTP. Below is an insecure OTP implementation with a fake email that sends a random 6-digit code to the user via a next.js server action.\n\n```typescript\n\"use server\";\nimport { randomInt } from \"crypto\";\n\nexport async function sendOTP(formData: FormData) {\n  try {\n    const email = formData.get(\"email\") as string | null;\n    if (!email) {\n      return {\n        success: false,\n        error: \"Email was not supplied, please try again\",\n        statusCode: 400,\n      };\n    }\n    const otp = randomInt(100000, 999999).toString();\n\n    const { data, error } = await emails.send({\n      from: \"james@unkey.com\",\n      to: email,\n      subject: \"OTP code\",\n      text: `Your OTP code is ${otp}`\n    });\n    // handled error\n    if (error) {\n      console.error(error);\n      return { success: false, error: \"Failed to send email\", statusCode: 500 };\n    }\n    return {\n      success: true,\n      statusCode: 201,\n    };\n    //catch\n  } catch (e) {\n    return { success: false, error: \"Failed to send email\", statusCode: 500 };\n  }\n}\n```\n\n### Adding ratelimiting to sending an OTP\n\nFirst, youll need to install the `@unkey/ratelimit` package to your project and then add the following imports.\n\n```typescript\nimport { Ratelimit } from \"@unkey/ratelimit\";\nimport { headers } from \"next/headers\";\n```\n\nWe will use the headers to retrieve the IP of the requester and use that as an identifier to limit against. Now we need to configure the ratelimiter\n\n```typescript\nconst unkey = new Ratelimit({\n  rootKey: process.env.UNKEY_ROOT_KEY,\n  namespace: \"otp-send\",\n  limit: 2,\n  duration: \"60s\",\n})\n\nexport async function sendOTP(formData: FormData) {\n  // sending OTP logic\n```\n\nThe above code will configure a new namespace named `otp-send` if it doesnt exist and limit the requests to two per minute. Of course, any number of attempts, but two emails per minute should suffice for the end user.\n\nNow that we have our ratelimiter configured, we can modify the request to first retrieve the IP address; this will check for both the forwarded IP address and the real IP from the headers. We will use the forwarded IP first and fall back to the real IP.\n\n```typescript\nexport async function sendOTP(formData: FormData) {\n  try {\n    // check for forwarded\n    let forwardedIP = headers().get(\"x-forwarded-for\");\n    // check for real-ip\n    let realIP = headers().get(\"x-real-ip\");\n    if(forwardedIP){\n      forwardedIP = forwardedIP.split(/, /)[0]\n    }\n    if (realIP) realIP = realIP.trim();\n    // sending logic below\n```\n\nNow we have access to an identifier, and we can run our rate limit against it. Add the following code before checking if the user has provided an email.\n\n```typescript\nconst { success, reset } = await unkey.limit(\n      forwardedIP || realIP || \"no-ip\",\n    );\n    const millis = reset - Date.now();\n    const timeToReset = Math.floor(millis / 1000);\n\t\t// if this is unsuccesful return a time to reset to the user so they know how long to wait\n    if (!success) {\n      return {\n        success: false,\n        error: `You can request a new code in ${timeToReset} seconds`,\n        statusCode: 429,\n      };\n    }\n\n    const email = formData.get(\"email\") as string | null;\n    //shortened for tutorial.\n```\n\nYoull notice that we check for `forwardedIP` and then the `realIP`, and finally, if nothing is available, we will use `no-ip` for the fallback. This endpoint is now protected; a user can send two requests per minute. Below is a demo of how you could present this to the user:\n\n<Image unoptimize=\"true\" src=\"/images/blog-images/otp-ratelimit/15fps_1080.gif\" alt=\"Example of sending ratelimits\" width=\"1920\" height=\"1080\"/>\n\n### Ratelimiting the OTP verification\n\nThe endpoint that verifies an OTP has more potential for brute force attacks; sending codes down with no restriction will give a bad actor plenty of time to try numerous codes to get the right one.\n\nThis is where the flexibility of ratelimiting for Unkey can come into play while it is similar to the above server action. For example\n\n```typescript\nexport async function verifyOTP(prevState: any, formData: FormData) {\n  try {\n    // check for forwarded\n    let forwardedIP = headers().get(\"x-forwarded-for\");\n    // check for real-ip\n    let realIP = headers().get(\"x-real-ip\");\n    if (forwardedIP) {\n      forwardedIP.split(/, /)[0];\n    }\n    if (realIP) {\n      realIP = realIP.trim();\n    }\n\n    const code = formData.get(\"code\") as string | null;\n\n    if (!code) {\n      return {\n        success: false,\n        error: \"Code was not supplied, please try again\",\n        statusCode: 400,\n      };\n    }\n\n    const { success, reset } = await unkey.limit(\n      forwardedIP || realIP || \"no-ip\",\n    );\n    const millis = reset - Date.now();\n    const timeToReset = Math.floor(millis / 1000);\n\n    if (!success) {\n      return {\n        success: false,\n        error: `You have been rate limited, please wait ${timeToReset} seconds and try entering a new code`,\n        statusCode: 429,\n      };\n    }\n    // Handle verification of your OTP\n```\n\nYou can set the limits and namespace to be different, allowing you to be more restrictive and keep all your analytical data separated, for example.\n\n```typescript\nconst unkey = new Ratelimit({\n  rootKey: process.env.UNKEY_ROOT_KEY!,\n  namespace: \"otp-verify\",\n  limit: 2,\n  duration: \"30s\",\n});\n```\n\nThis operation will allow a user to try twice every 30 seconds before it ratelimits the operation for the IP. Below is an example of how this could look in your application from the example code.\n\n<Image unoptimize=\"true\" src=\"/images/blog-images/otp-ratelimit/otp-verify-1080.gif\" alt=\"Example of verifying ratelimits\" width=\"1920\" height=\"1080\"/>\n\n## Best Practices in Rate Limiting OTP\n\nImplementing rate limiting is one thing, but ratelimiting effectively requires following best practices. Here are some tips:\n\n- **Set reasonable limits**: Your users should have enough attempts to enter their OTP correctly, but not so many that an attacker could guess.\n- **Educate your users**: Make sure your users understand why they're being blocked from logging in after too many attempts and how long they have to wait before they can try again.\n- **Monitor and adjust**: Regularly review your system's performance and adapt your limits as needed.\n\nThese practices enhance the security and efficiency of OTPs while maintaining a positive user experience.\n\nYou can read more about Unkeys Ratelimiting our [documentation](https://www.unkey.com/docs/ratelimiting/introduction), you can see the [demo](https://otp-example.vercel.app/) of this in action and test what happens when you go over limits.",
    "title": "Ratelimiting OTP endpoints",
    "description": "Without ratelimiting OTP endpoints you are exposed to brute force attacks, learn how to secure the endpoints using a ratelimiter.",
    "author": "james",
    "date": "2024-07-18",
    "tags": [
      "tutorials"
    ],
    "image": "/images/blog-images/otp-ratelimit/otp-ratelimit.png",
    "_meta": {
      "filePath": "ratelimiting-otp.mdx",
      "fileName": "ratelimiting-otp.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "ratelimiting-otp"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var a=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var y=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var i in e)a(t,i,{get:e[i],enumerable:!0})},s=(t,e,i,o)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of p(e))!g.call(t,r)&&r!==i&&a(t,r,{get:()=>e[r],enumerable:!(o=m(e,r))||o.enumerable});return t};var P=(t,e,i)=>(i=t!=null?u(f(t)):{},s(e||!t||!t.__esModule?a(i,\"default\",{value:t,enumerable:!0}):i,t)),v=t=>s(a({},\"__esModule\",{value:!0}),t);var c=y((x,l)=>{l.exports=_jsx_runtime});var k={};w(k,{default:()=>h});var n=P(c());function d(t){let e={a:\"a\",code:\"code\",h2:\"h2\",h3:\"h3\",li:\"li\",p:\"p\",pre:\"pre\",strong:\"strong\",ul:\"ul\",...t.components},{Image:i}=e;return i||b(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.h2,{id:\"understanding-otp\",children:\"Understanding OTP\"}),`\n`,(0,n.jsx)(e.p,{children:`A One-Time Password (OTP) is a unique code valid for only one login session or transaction. It adds an extra layer of security by preventing fraudulent access to your accounts, even if someone else knows your password.\nYou've likely encountered OTPs many times. For instance, when logging into your bank account from a new device, you may receive an OTP via SMS or email, which you must enter to verify your identity. Another typical example is the login flow, where instead of entering a password, an OTP is sent to your email.`}),`\n`,(0,n.jsx)(e.p,{children:\"Without ratelimiting, an attacker could try several OTPs in quick succession in a so-called 'brute force attack' to find the right one to gain access to an account.\"}),`\n`,(0,n.jsx)(e.p,{children:\"By limiting the number of OTP attempts within a specific timeframe, it becomes practically impossible for an attacker to guess the right OTP before it expires.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"implementing-ratelimiting\",children:\"Implementing ratelimiting\"}),`\n`,(0,n.jsx)(e.h3,{id:\"prerequisites\",children:\"Prerequisites\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"https://app.unkey.com\",children:\"Unkey account\"})}),`\n`,(0,n.jsxs)(e.li,{children:[\"Unkey root key with permissions \",(0,n.jsx)(e.code,{children:\"create_namespace\"}),\", \",(0,n.jsx)(e.code,{children:\"limit\"})]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"If you prefer, you can use our example here and skip the entire tutorial below. Also, if you want to see it live, you can see an implementation below using Unkey and Resend \",(0,n.jsx)(e.a,{href:\"https://otp-example.vercel.app/\",children:\"here\"})]}),`\n`,(0,n.jsx)(e.p,{children:\"Before we begin with the tutorial, it should be stated that OTP implementations will have two separate requests: sending the OTP via email or SMS and verifying the request.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Let\\u2019s start with the sending of an OTP. Below is an insecure OTP implementation with a fake email that sends a random 6-digit code to the user via a next.js server action.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`\"use server\";\nimport { randomInt } from \"crypto\";\n\nexport async function sendOTP(formData: FormData) {\n  try {\n    const email = formData.get(\"email\") as string | null;\n    if (!email) {\n      return {\n        success: false,\n        error: \"Email was not supplied, please try again\",\n        statusCode: 400,\n      };\n    }\n    const otp = randomInt(100000, 999999).toString();\n\n    const { data, error } = await emails.send({\n      from: \"james@unkey.com\",\n      to: email,\n      subject: \"OTP code\",\n      text: \\`Your OTP code is \\${otp}\\`\n    });\n    // handled error\n    if (error) {\n      console.error(error);\n      return { success: false, error: \"Failed to send email\", statusCode: 500 };\n    }\n    return {\n      success: true,\n      statusCode: 201,\n    };\n    //catch\n  } catch (e) {\n    return { success: false, error: \"Failed to send email\", statusCode: 500 };\n  }\n}\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"adding-ratelimiting-to-sending-an-otp\",children:\"Adding ratelimiting to sending an OTP\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"First, you\\u2019ll need to install the \",(0,n.jsx)(e.code,{children:\"@unkey/ratelimit\"}),\" package to your project and then add the following imports.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { Ratelimit } from \"@unkey/ratelimit\";\nimport { headers } from \"next/headers\";\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"We will use the headers to retrieve the IP of the requester and use that as an identifier to limit against. Now we need to configure the ratelimiter\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const unkey = new Ratelimit({\n  rootKey: process.env.UNKEY_ROOT_KEY,\n  namespace: \"otp-send\",\n  limit: 2,\n  duration: \"60s\",\n})\n\nexport async function sendOTP(formData: FormData) {\n  // sending OTP logic\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"The above code will configure a new namespace named \",(0,n.jsx)(e.code,{children:\"otp-send\"}),\" if it doesn\\u2019t exist and limit the requests to two per minute. Of course, any number of attempts, but two emails per minute should suffice for the end user.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Now that we have our ratelimiter configured, we can modify the request to first retrieve the IP address; this will check for both the forwarded IP address and the real IP from the headers. We will use the forwarded IP first and fall back to the real IP.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`export async function sendOTP(formData: FormData) {\n  try {\n    // check for forwarded\n    let forwardedIP = headers().get(\"x-forwarded-for\");\n    // check for real-ip\n    let realIP = headers().get(\"x-real-ip\");\n    if(forwardedIP){\n      forwardedIP = forwardedIP.split(/, /)[0]\n    }\n    if (realIP) realIP = realIP.trim();\n    // sending logic below\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Now we have access to an identifier, and we can run our rate limit against it. Add the following code before checking if the user has provided an email.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const { success, reset } = await unkey.limit(\n      forwardedIP || realIP || \"no-ip\",\n    );\n    const millis = reset - Date.now();\n    const timeToReset = Math.floor(millis / 1000);\n\t\t// if this is unsuccesful return a time to reset to the user so they know how long to wait\n    if (!success) {\n      return {\n        success: false,\n        error: \\`You can request a new code in \\${timeToReset} seconds\\`,\n        statusCode: 429,\n      };\n    }\n\n    const email = formData.get(\"email\") as string | null;\n    //shortened for tutorial.\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"You\\u2019ll notice that we check for \",(0,n.jsx)(e.code,{children:\"forwardedIP\"}),\" and then the \",(0,n.jsx)(e.code,{children:\"realIP\"}),\", and finally, if nothing is available, we will use \",(0,n.jsx)(e.code,{children:\"no-ip\"}),\" for the fallback. This endpoint is now protected; a user can send two requests per minute. Below is a demo of how you could present this to the user:\"]}),`\n`,(0,n.jsx)(i,{unoptimize:\"true\",src:\"/images/blog-images/otp-ratelimit/15fps_1080.gif\",alt:\"Example of sending ratelimits\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.h3,{id:\"ratelimiting-the-otp-verification\",children:\"Ratelimiting the OTP verification\"}),`\n`,(0,n.jsx)(e.p,{children:\"The endpoint that verifies an OTP has more potential for brute force attacks; sending codes down with no restriction will give a bad actor plenty of time to try numerous codes to get the right one.\"}),`\n`,(0,n.jsx)(e.p,{children:\"This is where the flexibility of ratelimiting for Unkey can come into play while it is similar to the above server action. For example\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`export async function verifyOTP(prevState: any, formData: FormData) {\n  try {\n    // check for forwarded\n    let forwardedIP = headers().get(\"x-forwarded-for\");\n    // check for real-ip\n    let realIP = headers().get(\"x-real-ip\");\n    if (forwardedIP) {\n      forwardedIP.split(/, /)[0];\n    }\n    if (realIP) {\n      realIP = realIP.trim();\n    }\n\n    const code = formData.get(\"code\") as string | null;\n\n    if (!code) {\n      return {\n        success: false,\n        error: \"Code was not supplied, please try again\",\n        statusCode: 400,\n      };\n    }\n\n    const { success, reset } = await unkey.limit(\n      forwardedIP || realIP || \"no-ip\",\n    );\n    const millis = reset - Date.now();\n    const timeToReset = Math.floor(millis / 1000);\n\n    if (!success) {\n      return {\n        success: false,\n        error: \\`You have been rate limited, please wait \\${timeToReset} seconds and try entering a new code\\`,\n        statusCode: 429,\n      };\n    }\n    // Handle verification of your OTP\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"You can set the limits and namespace to be different, allowing you to be more restrictive and keep all your analytical data separated, for example.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const unkey = new Ratelimit({\n  rootKey: process.env.UNKEY_ROOT_KEY!,\n  namespace: \"otp-verify\",\n  limit: 2,\n  duration: \"30s\",\n});\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"This operation will allow a user to try twice every 30 seconds before it ratelimits the operation for the IP. Below is an example of how this could look in your application from the example code.\"}),`\n`,(0,n.jsx)(i,{unoptimize:\"true\",src:\"/images/blog-images/otp-ratelimit/otp-verify-1080.gif\",alt:\"Example of verifying ratelimits\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.h2,{id:\"best-practices-in-rate-limiting-otp\",children:\"Best Practices in Rate Limiting OTP\"}),`\n`,(0,n.jsx)(e.p,{children:\"Implementing rate limiting is one thing, but ratelimiting effectively requires following best practices. Here are some tips:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Set reasonable limits\"}),\": Your users should have enough attempts to enter their OTP correctly, but not so many that an attacker could guess.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Educate your users\"}),\": Make sure your users understand why they're being blocked from logging in after too many attempts and how long they have to wait before they can try again.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Monitor and adjust\"}),\": Regularly review your system's performance and adapt your limits as needed.\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"These practices enhance the security and efficiency of OTPs while maintaining a positive user experience.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"You can read more about Unkey\\u2019s Ratelimiting our \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/ratelimiting/introduction\",children:\"documentation\"}),\", you can see the \",(0,n.jsx)(e.a,{href:\"https://otp-example.vercel.app/\",children:\"demo\"}),\" of this in action and test what happens when you go over limits.\"]})]})}function h(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(d,{...t})}):d(t)}function b(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return v(k);})();\n;return Component;",
    "slug": "ratelimiting-otp",
    "url": "/blog/ratelimiting-otp",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Implementing ratelimiting",
        "slug": "implementing-ratelimiting"
      },
      {
        "level": 3,
        "text": "Prerequisites",
        "slug": "prerequisites"
      },
      {
        "level": 3,
        "text": "Adding ratelimiting to sending an OTP",
        "slug": "adding-ratelimiting-to-sending-an-otp"
      },
      {
        "level": 3,
        "text": "Ratelimiting the OTP verification",
        "slug": "ratelimiting-the-otp-verification"
      },
      {
        "level": 2,
        "text": "Best Practices in Rate Limiting OTP",
        "slug": "best-practices-in-rate-limiting-otp"
      }
    ]
  },
  {
    "content": "Supabase offers [edge functions](https://supabase.com/docs/guides/functions) built upon Deno. They have a variety of uses for applications like OpenAI or working with their storage product. In this post, we will show you how to use Unkey to secure your function in just a few lines of code.\n\n## What is Unkey?\n\nUnkey is an open source API management platform that helps developers secure, manage, and scale their APIs. Unkey has built-in features that can make it easier than ever to provide an API to your end users, including:\n\n- Per key rate limiting\n- Limited usage keys\n- Time-based keys\n- Per key analytics\n\n## Prerequisites\n\n1. Create a [Supabase account](https://supabase.com)\n2. Create a [Unkey account](https://unkey.com) and follow our [Quickstart guide](https://unkey.com/docs/quickstart). So you have an API key to verify.\n3. Setup [Supabase CLI](https://supabase.com/docs/guides/cli/local-development) for local development.\n\n## Create our project\n\n### Create a project folder\n\nFirst, we need to create a folder. Let's call that `unkey-supabase`. This will be where our supabase functions exist going forward.\n\n```bash\nmkdir unkey-supabase && cd unkey-supabase\n```\n\n### Start Supabase services\n\nNow, we have a folder for our project. We can initialize and start Supabase for local development.\n\n```bash\nsupabase init\n```\n\nMake sure Docker is running. The `start` command uses Docker to start the Supabase services.\nThis command may take a while to run if this is the first time using the CLI.\n\n```bash\nsupabase start\n```\n\n## Create a Supabase function\n\nNow that Supabase is setup, we can create a Supabase function. This function will be where we secure it using Unkey.\n\n```bash\nsupabase functions new hello-world\n```\n\nThis command creates a function stub in your Supabase folder at `./functions/hello-world/index.ts`. This stub will have a function that returns the name passed in as data for the request.\n\n```typescript title=\"./functions/hello-world/index.ts\"\nimport { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\n\nconsole.log(\"Hello from Functions!\");\n\nserve(async (req) => {\n  const { name } = await req.json();\n  const data = {\n    message: `Hello ${name}!`,\n  };\n\n  return new Response(JSON.stringify(data), {\n    headers: { \"Content-Type\": \"application/json\" },\n  });\n});\n```\n\n### Test your Supabase function\n\nBefore making any changes, let's ensure your Supabase function runs. Inside the function, you should see a cURL command similar to the following:\n\n```bash\ncurl -i --location --request POST 'http://localhost:54321/functions/v1/' \\\n--header 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0' \\\n--header 'Content-Type: application/json' \\\n--data '{\"name\":\"hello-world\"}'\n```\n\nAfter invoking your Edge Function, you should see the response `{ \"message\":\"Hello Functions!\" }`.\n\n> If you receive an error Invalid JWT, find the `ANON_KEY` of your project in the Dashboard under Settings > API.\n\n## Add Unkey to secure our Supabase function\n\n### Add `verifyKey` to our function\n\nNow that we have a function, we must add Unkey to secure the endpoint. Supabase uses Deno, so instead of installing our npm package, we will use ESM CDN to provide the `verifyKey` function we need.\n\n```typescript {2} title=\"./functions/hello-world/index.ts\"\nimport { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\nimport { verifyKey } from \"https://esm.sh/@unkey/api\";\n```\n\n### What does `verifyKey` do?\n\nUnkey's `verifykey` lets you verify a key from your end users. We will return a result and you can decide whether to give the user access to a resource or not based upon that result. For example, a response could be:\n\n```json\n{\n  \"result\": {\n    \"valid\": true,\n    \"ownerId\": \"james\",\n    \"meta\": {\n      \"hello\": \"world\"\n    }\n  }\n}\n```\n\n### Updating our Supabase function\n\nFirst, let's remove the boilerplate code from the function so we can work on adding Unkey.\n\n```typescript title=\"./functions/hello-world/index.ts\"\nimport { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\nimport { verifyKey } from \"https://esm.sh/@unkey/api\";\n\nserve(async (req) => {});\n```\n\nNext, we will wrap the `serve` function inside a try-catch. Just in case something goes wrong, we can handle that.\n\n```typescript title=\"./functions/hello-world/index.ts\"\nimport { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\nimport { verifyKey } from \"https://esm.sh/@unkey/api\";\n\nserve(async (req) => {\n  try {\n    // handle our functions here.\n  } catch (error) {\n    // return a 500 error if there is an error with a message.\n    return new Response(JSON.stringify({ error: error.message }), {\n      status: 500,\n    });\n  }\n});\n```\n\n#### Check headers for API Key\n\nInside our try, we can look for a header containing the user's API Key. In this example we will use `x-unkey-api-key` but you could call the header whatever you want. If there is no header will immediately return 401.\n\n```typescript title=\"./functions/hello-world/index.ts\"\nimport { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\nimport { verifyKey } from \"https://esm.sh/@unkey/api\";\n\nserve(async (req) => {\n  try {\n    const token = req.headers.get(\"x-unkey-api-key\");\n    if (!token) {\n      return new Response(\"Unauthorized\", { status: 401 });\n    }\n  } catch (error) {\n    // return a 500 error if there is an error with a message.\n    return new Response(JSON.stringify({ error: error.message }), {\n      status: 500,\n    });\n  }\n});\n```\n\n## Verifying the key\n\nThe `verifyKey` function returns a `result` and `error`, making the logic easy to handle. Below is a simplified example of the verification flow.\n\n```typescript\nconst { result, error } = await verifyKey(\"key_123\");\nif (error) {\n  // handle potential network or bad request error\n  // a link to our docs will be in the `error.docs` field\n  console.error(error.message);\n  return;\n}\nif (!result.valid) {\n  // do not grant access\n  return;\n}\n// process request\nconsole.log(result);\n```\n\nNow you have a basic understanding of verification, let's add this to our Supabase function.\n\n```typescript title=\"./functions/hello-world/index.ts\"\nserve(async (req) => {\n  try {\n    const token = req.headers.get(\"x-unkey-api-key\");\n    if (!token) {\n      return new Response(\"No API Key provided\", { status: 401 });\n    }\n    const { result, error } = await verifyKey(token);\n    if (error) {\n      // handle potential network or bad request error\n      // a link to our docs will be in the `error.docs` field\n      console.error(error.message);\n      return new Response(JSON.stringify({ error: error.message }), {\n        status: 400,\n      });\n    }\n    if (!result.valid) {\n      // do not grant access\n      return new Response(JSON.stringify({ error: \"API Key is not valid for this request\" }), {\n        status: 401,\n      });\n    }\n    return new Response(JSON.stringify({ result }), { status: 200 });\n  }\n```\n\n### Testing our Supabase function\n\nWe can send a curl request to our endpoint to test this functionality. Below is an example of the curl to send. Remember, we now need to include our API key.\n\n```bash\ncurl -XPOST -H 'Authorization: Bearer <SUPBASE_BEARER_TOKEN>' \\\n-H 'x-unkey-api-key: <UNKEY_API_KEY>' \\\n-H \"Content-type: application/json\" 'http://localhost:54321/functions/v1/hello-world'\n```\n\n## Adding CORS for added security\n\nAdding CORS allows us to call our function from the frontend and decide what headers can be passed to our function. Inside your `functions` folder, add a file called `cors.ts`. Inside this cors file, we will tell the Supabase function which headers and origins are allowed.\n\n```typescript title=\"./functions/cors.ts\"\nexport const corsHeaders = {\n  \"Access-Control-Allow-Origin\": \"*\",\n  \"Access-Control-Allow-Headers\":\n    \"authorization, x-client-info, x-unkey-api-key, content-type\",\n};\n```\n\n## Conclusion\n\nIn this post, we have covered how to use Unkey with Supabase functions to secure them. You can check out the code for this project in our [Examples folder](https://github.com/unkeyed/examples/tree/main/supabase-functions)",
    "title": "Secure your Supabase functions with Unkey",
    "description": "Learn how to use Unkey to secure your Supabase functions",
    "author": "james",
    "date": "2023-10-03",
    "tags": [
      "tutorials"
    ],
    "image": "/images/blog-images/covers/unkey-supabase.png",
    "_meta": {
      "filePath": "secure-supabase-functions-using-unkey.mdx",
      "fileName": "secure-supabase-functions-using-unkey.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "secure-supabase-functions-using-unkey"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var f=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var g=(r,e)=>()=>(e||r((e={exports:{}}).exports,e),e.exports),w=(r,e)=>{for(var t in e)o(r,t,{get:e[t],enumerable:!0})},a=(r,e,t,i)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let s of f(e))!m.call(r,s)&&s!==t&&o(r,s,{get:()=>e[s],enumerable:!(i=p(e,s))||i.enumerable});return r};var k=(r,e,t)=>(t=r!=null?u(y(r)):{},a(e||!r||!r.__esModule?o(t,\"default\",{value:r,enumerable:!0}):t,r)),b=r=>a(o({},\"__esModule\",{value:!0}),r);var l=g((I,c)=>{c.exports=_jsx_runtime});var v={};w(v,{default:()=>h});var n=k(l());function d(r){let e={a:\"a\",blockquote:\"blockquote\",code:\"code\",h2:\"h2\",h3:\"h3\",h4:\"h4\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",ul:\"ul\",...r.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\"Supabase offers \",(0,n.jsx)(e.a,{href:\"https://supabase.com/docs/guides/functions\",children:\"edge functions\"}),\" built upon Deno. They have a variety of uses for applications like OpenAI or working with their storage product. In this post, we will show you how to use Unkey to secure your function in just a few lines of code.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"what-is-unkey\",children:\"What is Unkey?\"}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey is an open source API management platform that helps developers secure, manage, and scale their APIs. Unkey has built-in features that can make it easier than ever to provide an API to your end users, including:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Per key rate limiting\"}),`\n`,(0,n.jsx)(e.li,{children:\"Limited usage keys\"}),`\n`,(0,n.jsx)(e.li,{children:\"Time-based keys\"}),`\n`,(0,n.jsx)(e.li,{children:\"Per key analytics\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"prerequisites\",children:\"Prerequisites\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[\"Create a \",(0,n.jsx)(e.a,{href:\"https://supabase.com\",children:\"Supabase account\"})]}),`\n`,(0,n.jsxs)(e.li,{children:[\"Create a \",(0,n.jsx)(e.a,{href:\"https://unkey.com\",children:\"Unkey account\"}),\" and follow our \",(0,n.jsx)(e.a,{href:\"https://unkey.com/docs/quickstart\",children:\"Quickstart guide\"}),\". So you have an API key to verify.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[\"Setup \",(0,n.jsx)(e.a,{href:\"https://supabase.com/docs/guides/cli/local-development\",children:\"Supabase CLI\"}),\" for local development.\"]}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"create-our-project\",children:\"Create our project\"}),`\n`,(0,n.jsx)(e.h3,{id:\"create-a-project-folder\",children:\"Create a project folder\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"First, we need to create a folder. Let's call that \",(0,n.jsx)(e.code,{children:\"unkey-supabase\"}),\". This will be where our supabase functions exist going forward.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`mkdir unkey-supabase && cd unkey-supabase\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"start-supabase-services\",children:\"Start Supabase services\"}),`\n`,(0,n.jsx)(e.p,{children:\"Now, we have a folder for our project. We can initialize and start Supabase for local development.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`supabase init\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Make sure Docker is running. The \",(0,n.jsx)(e.code,{children:\"start\"}),` command uses Docker to start the Supabase services.\nThis command may take a while to run if this is the first time using the CLI.`]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`supabase start\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"create-a-supabase-function\",children:\"Create a Supabase function\"}),`\n`,(0,n.jsx)(e.p,{children:\"Now that Supabase is setup, we can create a Supabase function. This function will be where we secure it using Unkey.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`supabase functions new hello-world\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"This command creates a function stub in your Supabase folder at \",(0,n.jsx)(e.code,{children:\"./functions/hello-world/index.ts\"}),\". This stub will have a function that returns the name passed in as data for the request.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\n\nconsole.log(\"Hello from Functions!\");\n\nserve(async (req) => {\n  const { name } = await req.json();\n  const data = {\n    message: \\`Hello \\${name}!\\`,\n  };\n\n  return new Response(JSON.stringify(data), {\n    headers: { \"Content-Type\": \"application/json\" },\n  });\n});\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"test-your-supabase-function\",children:\"Test your Supabase function\"}),`\n`,(0,n.jsx)(e.p,{children:\"Before making any changes, let's ensure your Supabase function runs. Inside the function, you should see a cURL command similar to the following:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`curl -i --location --request POST 'http://localhost:54321/functions/v1/' \\\\\n--header 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0' \\\\\n--header 'Content-Type: application/json' \\\\\n--data '{\"name\":\"hello-world\"}'\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"After invoking your Edge Function, you should see the response \",(0,n.jsx)(e.code,{children:'{ \"message\":\"Hello Functions!\" }'}),\".\"]}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsxs)(e.p,{children:[\"If you receive an error Invalid JWT, find the \",(0,n.jsx)(e.code,{children:\"ANON_KEY\"}),\" of your project in the Dashboard under Settings > API.\"]}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"add-unkey-to-secure-our-supabase-function\",children:\"Add Unkey to secure our Supabase function\"}),`\n`,(0,n.jsxs)(e.h3,{id:\"add-verifykey-to-our-function\",children:[\"Add \",(0,n.jsx)(e.code,{children:\"verifyKey\"}),\" to our function\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Now that we have a function, we must add Unkey to secure the endpoint. Supabase uses Deno, so instead of installing our npm package, we will use ESM CDN to provide the \",(0,n.jsx)(e.code,{children:\"verifyKey\"}),\" function we need.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\nimport { verifyKey } from \"https://esm.sh/@unkey/api\";\n`})}),`\n`,(0,n.jsxs)(e.h3,{id:\"what-does-verifykey-do\",children:[\"What does \",(0,n.jsx)(e.code,{children:\"verifyKey\"}),\" do?\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Unkey's \",(0,n.jsx)(e.code,{children:\"verifykey\"}),\" lets you verify a key from your end users. We will return a result and you can decide whether to give the user access to a resource or not based upon that result. For example, a response could be:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-json\",children:`{\n  \"result\": {\n    \"valid\": true,\n    \"ownerId\": \"james\",\n    \"meta\": {\n      \"hello\": \"world\"\n    }\n  }\n}\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"updating-our-supabase-function\",children:\"Updating our Supabase function\"}),`\n`,(0,n.jsx)(e.p,{children:\"First, let's remove the boilerplate code from the function so we can work on adding Unkey.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\nimport { verifyKey } from \"https://esm.sh/@unkey/api\";\n\nserve(async (req) => {});\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Next, we will wrap the \",(0,n.jsx)(e.code,{children:\"serve\"}),\" function inside a try-catch. Just in case something goes wrong, we can handle that.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\nimport { verifyKey } from \"https://esm.sh/@unkey/api\";\n\nserve(async (req) => {\n  try {\n    // handle our functions here.\n  } catch (error) {\n    // return a 500 error if there is an error with a message.\n    return new Response(JSON.stringify({ error: error.message }), {\n      status: 500,\n    });\n  }\n});\n`})}),`\n`,(0,n.jsx)(e.h4,{id:\"check-headers-for-api-key\",children:\"Check headers for API Key\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Inside our try, we can look for a header containing the user's API Key. In this example we will use \",(0,n.jsx)(e.code,{children:\"x-unkey-api-key\"}),\" but you could call the header whatever you want. If there is no header will immediately return 401.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { serve } from \"https://deno.land/std@0.168.0/http/server.ts\";\nimport { verifyKey } from \"https://esm.sh/@unkey/api\";\n\nserve(async (req) => {\n  try {\n    const token = req.headers.get(\"x-unkey-api-key\");\n    if (!token) {\n      return new Response(\"Unauthorized\", { status: 401 });\n    }\n  } catch (error) {\n    // return a 500 error if there is an error with a message.\n    return new Response(JSON.stringify({ error: error.message }), {\n      status: 500,\n    });\n  }\n});\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"verifying-the-key\",children:\"Verifying the key\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The \",(0,n.jsx)(e.code,{children:\"verifyKey\"}),\" function returns a \",(0,n.jsx)(e.code,{children:\"result\"}),\" and \",(0,n.jsx)(e.code,{children:\"error\"}),\", making the logic easy to handle. Below is a simplified example of the verification flow.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const { result, error } = await verifyKey(\"key_123\");\nif (error) {\n  // handle potential network or bad request error\n  // a link to our docs will be in the \\`error.docs\\` field\n  console.error(error.message);\n  return;\n}\nif (!result.valid) {\n  // do not grant access\n  return;\n}\n// process request\nconsole.log(result);\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Now you have a basic understanding of verification, let's add this to our Supabase function.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`serve(async (req) => {\n  try {\n    const token = req.headers.get(\"x-unkey-api-key\");\n    if (!token) {\n      return new Response(\"No API Key provided\", { status: 401 });\n    }\n    const { result, error } = await verifyKey(token);\n    if (error) {\n      // handle potential network or bad request error\n      // a link to our docs will be in the \\`error.docs\\` field\n      console.error(error.message);\n      return new Response(JSON.stringify({ error: error.message }), {\n        status: 400,\n      });\n    }\n    if (!result.valid) {\n      // do not grant access\n      return new Response(JSON.stringify({ error: \"API Key is not valid for this request\" }), {\n        status: 401,\n      });\n    }\n    return new Response(JSON.stringify({ result }), { status: 200 });\n  }\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"testing-our-supabase-function\",children:\"Testing our Supabase function\"}),`\n`,(0,n.jsx)(e.p,{children:\"We can send a curl request to our endpoint to test this functionality. Below is an example of the curl to send. Remember, we now need to include our API key.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`curl -XPOST -H 'Authorization: Bearer <SUPBASE_BEARER_TOKEN>' \\\\\n-H 'x-unkey-api-key: <UNKEY_API_KEY>' \\\\\n-H \"Content-type: application/json\" 'http://localhost:54321/functions/v1/hello-world'\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"adding-cors-for-added-security\",children:\"Adding CORS for added security\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Adding CORS allows us to call our function from the frontend and decide what headers can be passed to our function. Inside your \",(0,n.jsx)(e.code,{children:\"functions\"}),\" folder, add a file called \",(0,n.jsx)(e.code,{children:\"cors.ts\"}),\". Inside this cors file, we will tell the Supabase function which headers and origins are allowed.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`export const corsHeaders = {\n  \"Access-Control-Allow-Origin\": \"*\",\n  \"Access-Control-Allow-Headers\":\n    \"authorization, x-client-info, x-unkey-api-key, content-type\",\n};\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"In this post, we have covered how to use Unkey with Supabase functions to secure them. You can check out the code for this project in our \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/examples/tree/main/supabase-functions\",children:\"Examples folder\"})]})]})}function h(r={}){let{wrapper:e}=r.components||{};return e?(0,n.jsx)(e,{...r,children:(0,n.jsx)(d,{...r})}):d(r)}return b(v);})();\n;return Component;",
    "slug": "secure-supabase-functions-using-unkey",
    "url": "/blog/secure-supabase-functions-using-unkey",
    "tableOfContents": [
      {
        "level": 2,
        "text": "What is Unkey?",
        "slug": "what-is-unkey"
      },
      {
        "level": 2,
        "text": "Prerequisites",
        "slug": "prerequisites"
      },
      {
        "level": 2,
        "text": "Create our project",
        "slug": "create-our-project"
      },
      {
        "level": 3,
        "text": "Create a project folder",
        "slug": "create-a-project-folder"
      },
      {
        "level": 3,
        "text": "Start Supabase services",
        "slug": "start-supabase-services"
      },
      {
        "level": 2,
        "text": "Create a Supabase function",
        "slug": "create-a-supabase-function"
      },
      {
        "level": 3,
        "text": "Test your Supabase function",
        "slug": "test-your-supabase-function"
      },
      {
        "level": 2,
        "text": "Add Unkey to secure our Supabase function",
        "slug": "add-unkey-to-secure-our-supabase-function"
      },
      {
        "level": 3,
        "text": "Add `verifyKey` to our function",
        "slug": "add-verifykey-to-our-function"
      },
      {
        "level": 3,
        "text": "What does `verifyKey` do?",
        "slug": "what-does-verifykey-do"
      },
      {
        "level": 3,
        "text": "Updating our Supabase function",
        "slug": "updating-our-supabase-function"
      },
      {
        "level": 4,
        "text": "Check headers for API Key",
        "slug": "check-headers-for-api-key"
      },
      {
        "level": 2,
        "text": "Verifying the key",
        "slug": "verifying-the-key"
      },
      {
        "level": 3,
        "text": "Testing our Supabase function",
        "slug": "testing-our-supabase-function"
      },
      {
        "level": 2,
        "text": "Adding CORS for added security",
        "slug": "adding-cors-for-added-security"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "Large language models are getting faster and cheaper. The below charts show progress in OpenAI's GPT family of models over the past\nyear:\n\n*Cost per million tokens ($)*\n<Image src=\"/images/blog-images/semantic-caching/cost-per-token-2.png\" alt=\"Chart of cost per token over time\" width=\"1920\" height=\"1080\" />\n\n*Tokens per second*\n<Image src=\"/images/blog-images/semantic-caching/tokens-per-second-2.png\" alt=\"Chart of cost per token over time\" width=\"1920\" height=\"1080\" />\n\nRecent releases like Meta's Llama 3 and Gemini Flash have pushed the cost / speed frontier further:\n\n*Below data is for May 2024*\n\n<Image src=\"/images/blog-images/semantic-caching/models-comparison.png\" alt=\"Chart comparing cost and speed of LLMs in May 2024\" width=\"1920\" height=\"1080\" />\n\nAs cost and latency have decreased, more complex LLM workflows have become increasingly viable, which in turn bring their own set of challenges.\n\n<Image src=\"/images/blog-images/semantic-caching/llm-agent-tweet.png\" alt=\"Chart comparing cost and speed of LLMs in May 2024\" width=\"1920\" height=\"1080\" />\n\nSince these workflows often involve multiple steps and retries, taking measures to reduce cost and latency remains helpful. One way to do\nso is via *semantic caching*.\n\n## Example use case: RAG\n\nSay that you want to build a RAG (retrieval-augmented generation) chatbot for customer support. It can respond to user queries and suggest\narticles from your support center.\n\nThis workflow would involve multiple API calls:\n\n1. Generate embedding of user query\n2. Search vector DB for relevant embeddings and append to prompt\n3. Query LLM API with enhanced prompt\n\nThrough caching, you could avoid doing this work except for when users ask questions that haven't been asked before - otherwise, re-use\nexisting work.\n\n## Caching\n\nA simple caching solution would be to cache results using the user query as the key, and the result of the workflow as the value.\n\nThis would enable re-use of responses between identical queries. But it would rely on user queries being phrased identically.\n\nFor instance, if two users asked \"How do I cancel my subscription\" then the second would be served the cached response. But if another\nuser was to ask \"I need to cancel my subscription - how?\" then we'd see a cache miss. The question is the same in terms of its intent,\nbut the phrasing is different.\n\nThis is how semantic caching can be useful: through caching based on the embedding of the query, we can ensure that all users who ask\nthe same question receive a cache hit. The below diagrams give an overview of the architecture:\n\n<Image src=\"/images/blog-images/semantic-caching/cachehit.png\" alt=\"Diagram showing cache hit\" width=\"1920\" height=\"1080\" />\n<Image src=\"/images/blog-images/semantic-caching/cachemiss.png\" alt=\"Diagram showing cache miss\" width=\"1920\" height=\"1080\" />\n\n\n## Try it now\n\nIn response to feedback from our AI customers, we're offering semantic caching now as part of Unkey. You can enable it now through\n[signing up](https://unkey.dev/semantic-caching) and changing the baseUrl parameter of the OpenAI SDK:\n\n```typescript\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY,\n  baseURL: \"https://<gateway>.llm.unkey.io\", // change the baseUrl parameter to your gateway name\n});\n```\n\nUnkey's semantic caching is free, supports streaming, and comes with built-in observability and analytics. In future we will offer deeper integration with Unkey's API keys for enhanced security and performance.\n\nIf you'd like to read more about how it works, check out our [documentation](https://unkey.dev/docs/semantic-caching).",
    "title": "Semantic caching",
    "description": "Faster, cheaper LLM API calls",
    "author": "dom",
    "date": "2024-06-26",
    "tags": [
      "launchweek",
      "marketing",
      "AI"
    ],
    "image": "/images/blog-images/covers/semantic-cache.png",
    "_meta": {
      "filePath": "semantic-caching.mdx",
      "fileName": "semantic-caching.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "semantic-caching"
    },
    "mdx": "var Component=(()=>{var g=Object.create;var s=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,w=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),y=(t,e)=>{for(var i in e)s(t,i,{get:e[i],enumerable:!0})},o=(t,e,i,r)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let a of p(e))!w.call(t,a)&&a!==i&&s(t,a,{get:()=>e[a],enumerable:!(r=m(e,a))||r.enumerable});return t};var b=(t,e,i)=>(i=t!=null?g(u(t)):{},o(e||!t||!t.__esModule?s(i,\"default\",{value:t,enumerable:!0}):i,t)),k=t=>o(s({},\"__esModule\",{value:!0}),t);var h=f((A,c)=>{c.exports=_jsx_runtime});var I={};y(I,{default:()=>d});var n=b(h());function l(t){let e={a:\"a\",code:\"code\",em:\"em\",h2:\"h2\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",...t.components},{Image:i}=e;return i||v(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:`Large language models are getting faster and cheaper. The below charts show progress in OpenAI's GPT family of models over the past\nyear:`}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.em,{children:\"Cost per million tokens ($)\"})}),`\n`,(0,n.jsx)(i,{src:\"/images/blog-images/semantic-caching/cost-per-token-2.png\",alt:\"Chart of cost per token over time\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.em,{children:\"Tokens per second\"})}),`\n`,(0,n.jsx)(i,{src:\"/images/blog-images/semantic-caching/tokens-per-second-2.png\",alt:\"Chart of cost per token over time\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"Recent releases like Meta's Llama 3 and Gemini Flash have pushed the cost / speed frontier further:\"}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.em,{children:\"Below data is for May 2024\"})}),`\n`,(0,n.jsx)(i,{src:\"/images/blog-images/semantic-caching/models-comparison.png\",alt:\"Chart comparing cost and speed of LLMs in May 2024\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"As cost and latency have decreased, more complex LLM workflows have become increasingly viable, which in turn bring their own set of challenges.\"}),`\n`,(0,n.jsx)(i,{src:\"/images/blog-images/semantic-caching/llm-agent-tweet.png\",alt:\"Chart comparing cost and speed of LLMs in May 2024\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsxs)(e.p,{children:[`Since these workflows often involve multiple steps and retries, taking measures to reduce cost and latency remains helpful. One way to do\nso is via `,(0,n.jsx)(e.em,{children:\"semantic caching\"}),\".\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"example-use-case-rag\",children:\"Example use case: RAG\"}),`\n`,(0,n.jsx)(e.p,{children:`Say that you want to build a RAG (retrieval-augmented generation) chatbot for customer support. It can respond to user queries and suggest\narticles from your support center.`}),`\n`,(0,n.jsx)(e.p,{children:\"This workflow would involve multiple API calls:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Generate embedding of user query\"}),`\n`,(0,n.jsx)(e.li,{children:\"Search vector DB for relevant embeddings and append to prompt\"}),`\n`,(0,n.jsx)(e.li,{children:\"Query LLM API with enhanced prompt\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:`Through caching, you could avoid doing this work except for when users ask questions that haven't been asked before - otherwise, re-use\nexisting work.`}),`\n`,(0,n.jsx)(e.h2,{id:\"caching\",children:\"Caching\"}),`\n`,(0,n.jsx)(e.p,{children:\"A simple caching solution would be to cache results using the user query as the key, and the result of the workflow as the value.\"}),`\n`,(0,n.jsx)(e.p,{children:\"This would enable re-use of responses between identical queries. But it would rely on user queries being phrased identically.\"}),`\n`,(0,n.jsx)(e.p,{children:`For instance, if two users asked \"How do I cancel my subscription\" then the second would be served the cached response. But if another\nuser was to ask \"I need to cancel my subscription - how?\" then we'd see a cache miss. The question is the same in terms of its intent,\nbut the phrasing is different.`}),`\n`,(0,n.jsx)(e.p,{children:`This is how semantic caching can be useful: through caching based on the embedding of the query, we can ensure that all users who ask\nthe same question receive a cache hit. The below diagrams give an overview of the architecture:`}),`\n`,(0,n.jsx)(i,{src:\"/images/blog-images/semantic-caching/cachehit.png\",alt:\"Diagram showing cache hit\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(i,{src:\"/images/blog-images/semantic-caching/cachemiss.png\",alt:\"Diagram showing cache miss\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.h2,{id:\"try-it-now\",children:\"Try it now\"}),`\n`,(0,n.jsxs)(e.p,{children:[`In response to feedback from our AI customers, we're offering semantic caching now as part of Unkey. You can enable it now through\n`,(0,n.jsx)(e.a,{href:\"https://unkey.dev/semantic-caching\",children:\"signing up\"}),\" and changing the baseUrl parameter of the OpenAI SDK:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY,\n  baseURL: \"https://<gateway>.llm.unkey.io\", // change the baseUrl parameter to your gateway name\n});\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey's semantic caching is free, supports streaming, and comes with built-in observability and analytics. In future we will offer deeper integration with Unkey's API keys for enhanced security and performance.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"If you'd like to read more about how it works, check out our \",(0,n.jsx)(e.a,{href:\"https://unkey.dev/docs/semantic-caching\",children:\"documentation\"}),\".\"]})]})}function d(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(l,{...t})}):l(t)}function v(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return k(I);})();\n;return Component;",
    "slug": "semantic-caching",
    "url": "/blog/semantic-caching",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Example use case: RAG",
        "slug": "example-use-case-rag"
      },
      {
        "level": 2,
        "text": "Caching",
        "slug": "caching"
      },
      {
        "level": 2,
        "text": "Try it now",
        "slug": "try-it-now"
      }
    ]
  },
  {
    "content": "Introducing the Unkey toolbox, an opinionated set of tools designed to streamline creating new APIs. The toolbox comes packed with features that allow you to create performant and secure APIs with high quality documentation.\n\n![CLI example](/images/blog-images/toolbox/cli-example.gif)\n\nThe toolbox offers a variety of technologies we believe are essential for creating APIs, including:\n\n- [Cloudflare workers](https://cloudflare.com)\n- [Hono](https://hono.dev)\n- [Turso](https://turso.tech)\n- Your choice of [Prisma](https://prisma.io) or [Drizzle](https://orm.drizzle.team/)\n- Documentation built on the [Fumadocs](https://fumadocs.vercel.app/) including documentation generation via openapi spec.\n\nOf course the toolbox also includes Unkey in a variety of ways, including keys, ratelimiting and caching.\n\n## Getting Started with the Unkey Toolbox\n\nGetting started with the Unkey Toolbox is easy! Just use `npx @unkey/create-api` from your terminal and follow the CLI prompts. Once you run the CLI youll have a fully functioning API with a variety of endpoints and documentation.\n\nThe only thing left to do is sign up for an Unkey account and an Turso account and follow the instructions from the CLI to get your API up and running.\n\n## Whats next for the toolbox?\n\nWe want to add more features to the toolbox including new database providers, billing integrations and of course more endpoint examples. Our toolbox is open source just like the rest of Unkey so you can drive what gets built or contribute yourself.\n\nCheck out the [repository](https://github.com/unkeyed/toolbox) to request features and how all the code works.",
    "title": "Unkey Toolbox: Your gateway to creating performant APIs",
    "description": "A brand new CLI that makes it easier than ever to create APIs",
    "author": "james",
    "date": "2024-06-27",
    "tags": [
      "launchweek",
      "marketing"
    ],
    "image": "/images/blog-images/covers/toolbox.png",
    "_meta": {
      "filePath": "toolbox.mdx",
      "fileName": "toolbox.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "toolbox"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var r=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var f=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var x=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),y=(n,e)=>{for(var o in e)r(n,o,{get:e[o],enumerable:!0})},l=(n,e,o,a)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let i of f(e))!g.call(n,i)&&i!==o&&r(n,i,{get:()=>e[i],enumerable:!(a=p(e,i))||a.enumerable});return n};var b=(n,e,o)=>(o=n!=null?u(m(n)):{},l(e||!n||!n.__esModule?r(o,\"default\",{value:n,enumerable:!0}):o,n)),w=n=>l(r({},\"__esModule\",{value:!0}),n);var c=x((I,h)=>{h.exports=_jsx_runtime});var k={};y(k,{default:()=>d});var t=b(c());function s(n){let e={a:\"a\",code:\"code\",h2:\"h2\",img:\"img\",li:\"li\",p:\"p\",ul:\"ul\",...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.p,{children:\"Introducing the Unkey toolbox, an opinionated set of tools designed to streamline creating new APIs. The toolbox comes packed with features that allow you to create performant and secure APIs with high quality documentation.\"}),`\n`,(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{src:\"/images/blog-images/toolbox/cli-example.gif\",alt:\"CLI example\"})}),`\n`,(0,t.jsx)(e.p,{children:\"The toolbox offers a variety of technologies we believe are essential for creating APIs, including:\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:\"https://cloudflare.com\",children:\"Cloudflare workers\"})}),`\n`,(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:\"https://hono.dev\",children:\"Hono\"})}),`\n`,(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:\"https://turso.tech\",children:\"Turso\"})}),`\n`,(0,t.jsxs)(e.li,{children:[\"Your choice of \",(0,t.jsx)(e.a,{href:\"https://prisma.io\",children:\"Prisma\"}),\" or \",(0,t.jsx)(e.a,{href:\"https://orm.drizzle.team/\",children:\"Drizzle\"})]}),`\n`,(0,t.jsxs)(e.li,{children:[\"Documentation built on the \",(0,t.jsx)(e.a,{href:\"https://fumadocs.vercel.app/\",children:\"Fumadocs\"}),\" including documentation generation via openapi spec.\"]}),`\n`]}),`\n`,(0,t.jsx)(e.p,{children:\"Of course the toolbox also includes Unkey in a variety of ways, including keys, ratelimiting and caching.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"getting-started-with-the-unkey-toolbox\",children:\"Getting Started with the Unkey Toolbox\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Getting started with the Unkey Toolbox is easy! Just use \",(0,t.jsx)(e.code,{children:\"npx @unkey/create-api\"}),\" from your terminal and follow the CLI prompts. Once you run the CLI you\\u2019ll have a fully functioning API with a variety of endpoints and documentation.\"]}),`\n`,(0,t.jsx)(e.p,{children:\"The only thing left to do is sign up for an Unkey account and an Turso account and follow the instructions from the CLI to get your API up and running.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"whats-next-for-the-toolbox\",children:\"What\\u2019s next for the toolbox?\"}),`\n`,(0,t.jsx)(e.p,{children:\"We want to add more features to the toolbox including new database providers, billing integrations and of course more endpoint examples. Our toolbox is open source just like the rest of Unkey so you can drive what gets built or contribute yourself.\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Check out the \",(0,t.jsx)(e.a,{href:\"https://github.com/unkeyed/toolbox\",children:\"repository\"}),\" to request features and how all the code works.\"]})]})}function d(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(s,{...n})}):s(n)}return w(k);})();\n;return Component;",
    "slug": "toolbox",
    "url": "/blog/toolbox",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Getting Started with the Unkey Toolbox",
        "slug": "getting-started-with-the-unkey-toolbox"
      },
      {
        "level": 2,
        "text": "Whats next for the toolbox?",
        "slug": "whats-next-for-the-toolbox"
      }
    ]
  },
  {
    "content": "The Unkey pre-seed round was led by[Essence VC](https://www.essencevc.fund/)and joined by [Sunflower Capital](https://www.linkedin.com/in/liujiang1/), [The Normal Fund](https://new-normal.ventures/), and some fantastic friends.\n\n## Essence VCleads our round.\n\nWhen we met Tim Chen for the first time, Andreas and I were blown away by his experience and his immediate understanding of our vision. We only needed ten minutes before we were bouncing ideas and thinking about where to go with Unkey.\n\nTim also introduced us to our other partners (Sunflower Capital and The New Normal Fund), who were just as excited to see how API authentication and authorization could be simplified.\n\n### Angels\n\nOur angels are a fantastic group of people in no particular order:\n\n- Andrew Miklas (Functional Capital / Ex PageDuty Co Founder)\n- Ant Wilson & Rory Wilding (Supabase Co Founder / Head of Growth at Supabase)\n- Paul Copplestone (Supabase Co Founder)\n- Theo Browne (Ping / YouTube / Twitch / Twitter)\n- Ian Livingstone (Startup Advisor / Investor)\n- Preston-Werner Ventures (Led by Tom Preston-Werner Co-Founder of GitHub)\n- George & Chris Perkins (James mum and dad)\n- Zain Allarakhia (ex Pipe)\n\n## How it all started\n\nAndreas and I started Unkey in the middle of June and launched on June 21st, the community loved Unkey and we got some awesome feedback. Once we understood that this side project, which started as a way to solve an annoying problem we both had experienced, was needed by more and more people, we set our sights on building an entire business for it.\n\nWe worked nights and weekends for months to ensure Unkey made scaling user-facing APIs more accessible than ever. Shout out to all the friends and family who supported us getting through the 16+ hour days.\n\n## How's it going\n\nSince the launch in June, we have had success with the product:\n\n- 1.2k stars on [GitHub](https://github.com/unkeyed/unkey)\n- We have done over 13 million API key verifications.\n- 1.6k users have signed up\n\n## What's next?\n\nNow that Unkey is funded, we can focus on building the best developer experience in the API space. You may be wondering what is next.\n\n- Hiring 1-2 more engineers.\n- Create an easy-to-use permission system that allows you to control access through RBAC, ABAC, or REBAC.\n- Create a new gateway system that allows any developer to understand and configure.\n\nTalking about hiring, if you are interested in being part of the team. Check out the [job posting and apply](/careers).\n\nThank you for all the support, and we look forward to bringing API scalability to developers like never before.",
    "title": "Unkey raises 1.5 million pre-seed",
    "description": "We raised a pre-seed to build the best developer experience for API authentication and authorization",
    "author": "james",
    "date": "2023-11-15",
    "tags": [
      "company"
    ],
    "image": "/images/blog-images/funding/funding-cover.png",
    "_meta": {
      "filePath": "unkey-raises-1-5-million.mdx",
      "fileName": "unkey-raises-1-5-million.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "unkey-raises-1-5-million"
    },
    "mdx": "var Component=(()=>{var c=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var w=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var f=(i,e)=>()=>(e||i((e={exports:{}}).exports,e),e.exports),y=(i,e)=>{for(var r in e)o(i,r,{get:e[r],enumerable:!0})},d=(i,e,r,a)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let t of w(e))!m.call(i,t)&&t!==r&&o(i,t,{get:()=>e[t],enumerable:!(a=p(e,t))||a.enumerable});return i};var b=(i,e,r)=>(r=i!=null?c(g(i)):{},d(e||!i||!i.__esModule?o(r,\"default\",{value:i,enumerable:!0}):r,i)),k=i=>d(o({},\"__esModule\",{value:!0}),i);var l=f((x,s)=>{s.exports=_jsx_runtime});var C={};y(C,{default:()=>u});var n=b(l());function h(i){let e={a:\"a\",h2:\"h2\",h3:\"h3\",li:\"li\",p:\"p\",ul:\"ul\",...i.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\"The Unkey pre-seed round was led by\\xA0\",(0,n.jsx)(e.a,{href:\"https://www.essencevc.fund/\",children:\"Essence VC\"}),\"\\xA0and joined by \",(0,n.jsx)(e.a,{href:\"https://www.linkedin.com/in/liujiang1/\",children:\"Sunflower Capital\"}),\", \",(0,n.jsx)(e.a,{href:\"https://new-normal.ventures/\",children:\"The Normal Fund\"}),\", and some fantastic friends.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"essence-vcleads-our-round\",children:\"Essence VC\\xA0leads our round.\"}),`\n`,(0,n.jsx)(e.p,{children:\"When we met Tim Chen for the first time, Andreas and I were blown away by his experience and his immediate understanding of our vision. We only needed ten minutes before we were bouncing ideas and thinking about where to go with Unkey.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Tim also introduced us to our other partners (Sunflower Capital and The New Normal Fund), who were just as excited to see how API authentication and authorization could be simplified.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"angels\",children:\"Angels\"}),`\n`,(0,n.jsx)(e.p,{children:\"Our angels are a fantastic group of people in no particular order:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Andrew Miklas (Functional Capital / Ex PageDuty Co Founder)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Ant Wilson & Rory Wilding (Supabase Co Founder / Head of Growth at Supabase)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Paul Copplestone (Supabase Co Founder)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Theo Browne (Ping / YouTube / Twitch / Twitter)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Ian Livingstone (Startup Advisor / Investor)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Preston-Werner Ventures (Led by Tom Preston-Werner Co-Founder of GitHub)\"}),`\n`,(0,n.jsx)(e.li,{children:\"George & Chris Perkins (James\\u2019 mum and dad)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Zain Allarakhia (ex Pipe)\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"how-it-all-started\",children:\"How it all started\"}),`\n`,(0,n.jsx)(e.p,{children:\"Andreas and I started Unkey in the middle of June and launched on June 21st, the community loved Unkey and we got some awesome feedback. Once we understood that this side project, which started as a way to solve an annoying problem we both had experienced, was needed by more and more people, we set our sights on building an entire business for it.\"}),`\n`,(0,n.jsx)(e.p,{children:\"We worked nights and weekends for months to ensure Unkey made scaling user-facing APIs more accessible than ever. Shout out to all the friends and family who supported us getting through the 16+ hour days.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"hows-it-going\",children:\"How's it going\"}),`\n`,(0,n.jsx)(e.p,{children:\"Since the launch in June, we have had success with the product:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[\"1.2k stars on \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/unkey\",children:\"GitHub\"})]}),`\n`,(0,n.jsx)(e.li,{children:\"We have done over 13 million API key verifications.\"}),`\n`,(0,n.jsx)(e.li,{children:\"1.6k users have signed up\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"whats-next\",children:\"What's next?\"}),`\n`,(0,n.jsx)(e.p,{children:\"Now that Unkey is funded, we can focus on building the best developer experience in the API space. You may be wondering what is next.\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Hiring 1-2 more engineers.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Create an easy-to-use permission system that allows you to control access through RBAC, ABAC, or REBAC.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Create a new gateway system that allows any developer to understand and configure.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Talking about hiring, if you are interested in being part of the team. Check out the \",(0,n.jsx)(e.a,{href:\"/careers\",children:\"job posting and apply\"}),\".\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Thank you for all the support, and we look forward to bringing API scalability to developers like never before.\"})]})}function u(i={}){let{wrapper:e}=i.components||{};return e?(0,n.jsx)(e,{...i,children:(0,n.jsx)(h,{...i})}):h(i)}return k(C);})();\n;return Component;",
    "slug": "unkey-raises-1-5-million",
    "url": "/blog/unkey-raises-1-5-million",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Essence VCleads our round.",
        "slug": "essence-vcleads-our-round"
      },
      {
        "level": 3,
        "text": "Angels",
        "slug": "angels"
      },
      {
        "level": 2,
        "text": "How it all started",
        "slug": "how-it-all-started"
      },
      {
        "level": 2,
        "text": "How's it going",
        "slug": "hows-it-going"
      },
      {
        "level": 2,
        "text": "What's next?",
        "slug": "whats-next"
      }
    ]
  },
  {
    "content": "When working with your external facing API and having a client application, you need to identify which user owns an API Key. Having a way to identify the user allows you to understand their usage of your product better. This blog is going to cover how you can use your authentication provider to add a way to identify the user.\n\n## What is Unkey?\n\nUnkey is an open source API management platform that helps developers secure, manage, and scale their APIs. Unkey has built-in features that can make it easier than ever to provide an API to your end users, including:\n\n- Per key rate limiting\n- Limited usage keys\n- Time-based keys\n- Per key analytics\n\n## Setting up our project\n\nWe will use my favorite authentication provider, Clerk, in this example. The concepts described below are agnostic, so feel free to use whatever provider works for you. We will also use Next.js for demo purposes, but it isn't a requirement.\n\n### Create a Next.js application and install dependencies.\n\nThe first thing we want to do is create our Next.js application and install our dependencies.\n\n```bash\nnpx create-next-app@latest unkey-with-auth\n```\n\nWe need Unkey's typescript library and Clerk's next.js package for dependencies.\n\n```bash\nnpm install @unkey/api @clerk/nextjs\n```\n\nThen, finally, we are going to use Shadcn to speed up the styling. If you copy the two commands below, it will install everything you need.\n\n```bash\nnpx shadcn-ui@latest init\n\nnpx shadcn-ui@latest add button input label card\n```\n\nMake sure you include your Clerk secret key and publishable key in your `.env.local` file. You can find these in your Clerk dashboard. You will also need an Unkey root key and API ID. You can find these in your Unkey dashboard.\n\n```bash\nNEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_xxxxxxxxxxxxxx\nCLERK_SECRET_KEY=sk_test_xxxxxxxxxxxxxx\nUNKEY_API_ID=api_xxxxxxxxxxxxxx\nUNKEY_ROOT_KEY=unkey_xxxxxxxxxxxxxx\n```\n\n### Clerk setup (optional)\n\nYou can skip this step if you aren't using Clerk as an auth provider. We only need to update our root layout file and add middleware.\n\n#### Root layout\n\n```typescript\nimport \"./globals.css\";\nimport { Inter } from \"next/font/google\";\nimport { ClerkProvider } from \"@clerk/nextjs\";\n\nconst inter = Inter({ subsets: [\"latin\"] });\n\nexport const metadata: Metadata = {\n  title: \"Create Next App\",\n\n  description: \"Generated by create next app\",\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <ClerkProvider>\n      <html lang=\"en\">\n        <body>{children}</body>\n      </html>\n    </ClerkProvider>\n  );\n}\n```\n\n#### Middleware.ts\n\nThen, you need to add middleware.ts to the root of the project. This protects all pages and routes except `/api/secret`. More on that later.\n\n```typescript\nimport { authMiddleware } from \"@clerk/nextjs\";\n\nexport default authMiddleware({\n  publicRoutes: \"/api/secret\",\n});\n\nexport const config = {\n  matcher: [\"/((?!.+\\\\.[\\\\w]+$|_next).*)\", \"/\", \"/(api|trpc)(.*)\"],\n};\n```\n\n## Creating a key associated with a user.\n\nUnkey accepts an owner_id when creating a key that we can use to associate our auth provider's unique identifier, such as `user_id`. In our example application, we are going to use a server action to create the key.\n\n### Create our Unkey client component\n\nWe will create a client component that takes a name for an API. This API key name can make it easier to identify the critical self and not the owner in our demo, but it gives you an idea of how the flow would work. Create a folder called `keys` and a `client.tsx` file. Inside that file, add the following imports from our components from shadcn.\n\n```typescript\n\"use client\";\nimport { Button } from \"@/components/ui/button\";\nimport {\n  Card,\n  CardContent,\n  CardDescription,\n  CardFooter,\n  CardHeader,\n  CardTitle,\n} from \"@/components/ui/card\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\n```\n\nNow, we can create our component, which we will name `UnkeyElements` and use the card component to create an easy-to-use form.\n\n```typescript\nconst UnkeyElements = () => {\n  return (\n    <div className=\"mt-8\">\n      <Card className=\"w-[350px]\">\n        <CardHeader>\n          <CardTitle>Create API Key</CardTitle>\n          <CardDescription>\n            Create your API key so you can interact with our API.\n          </CardDescription>\n        </CardHeader>\n\n        <form>\n          <CardContent>\n            <div className=\"grid w-full items-center gap-4\">\n              <div className=\"flex flex-col space-y-1.5\">\n                <Label htmlFor=\"name\">Give your key a name</Label>\n                <Input name=\"name\" placeholder=\"Key for next big thing\" />\n              </div>\n            </div>\n          </CardContent>\n          <CardFooter className=\"flex justify-between\">\n            <Button type=\"submit\">Create Key</Button>\n          </CardFooter>\n        </form>\n      </Card>\n    </div>\n  );\n};\nexport { UnkeyElements };\n```\n\nMake sure to import this into your `page.tsx` file and add it to the page.\n\n```typescript\nimport { UnkeyElements } from \"./keys/client\";\n\nexport default function Home() {\n  return (\n    <main className=\"flex min-h-screen flex-col items-center justify-between p-24\">\n      <div className=\"flex flex-col items-center justify-center\">\n        <h1 className=\"text-4xl font-bold\">\n          Welcome to the Unkey + Auth Provider\n        </h1>\n        <p className=\"text-xl mt-4\">\n          This is a demo of how you can use Unkey to secure your API with an\n          Auth Provider.\n        </p>\n        <UnkeyElements />\n      </div>\n    </main>\n  );\n}\n```\n\n### Adding a server action\n\nOur server action will allow us to create a key in our application in the `keys` folder, add a `create.ts` file. Then, in this file, we will use our auth provider and Unkey together.\n\n```typescript\n\"use server\";\nimport { auth } from \"@clerk/nextjs\";\nimport { Unkey } from \"@unkey/api\";\nexport async function create(formData: FormData) {\n  \"use server\";\n  const { userId } = auth();\n  if (!userId) {\n    return null;\n  }\n  const token = process.env.UNKEY_ROOT_KEY;\n  const apiId = process.env.UNKEY_API_ID;\n\n  if (!token || !apiId) {\n    return null;\n  }\n\n  const name = (formData.get(\"name\") as string) ?? \"My Awesome API\";\n  const unkey = new Unkey({ token });\n  const key = await unkey.keys.create({\n    name: name,\n    ownerId: userId,\n    apiId,\n  });\n  return { key: key.result };\n}\n```\n\nThe key creation server action will check if the user is authenticated. If they are, it will create a key with the name provided and the user's ID. If the user isn't authenticated, it will return null. We now have a way to track which user owns which key.\n\n### Adding our creation server action to our client component\n\nNow, we have a way to create a key to add to our client component. In our `client.tsx` file, we will add our server action import and `useState` to handle the returned key.\n\n```typescript\nimport { create } from \"./create\";\nimport { useState } from \"react\";\n```\n\nNow we have the imports, we can add an `onCreate` function to our component that will call our server action. We can now call that function when the form is submitted.\n\n```typescript\nconst UnkeyElements = () => {\n    const [key, setKey] = useState<string>('')\n    async function onCreate(formData: FormData) {\n        const res = await create(formData)\n        if(res) setKey(res.key?.key);\n    }\n    ...\n    <form action={onCreate}>\n          <CardContent>\n            <div className=\"grid w-full items-center gap-4\">\n              <div className=\"flex flex-col space-y-1.5\">\n                <Label htmlFor=\"name\">Give your key a name</Label>\n                <Input name=\"name\" placeholder=\"Key for next big thing\" />\n              </div>\n            </div>\n          </CardContent>\n          <CardFooter className=\"flex justify-between\">\n            <Button type=\"submit\">Create Key</Button>\n          </CardFooter>\n        </form>\n    ...\n```\n\nWhen we submit the form, we will get a key back that we can use to make requests to our API. If you give this a test, you can log out the key in the console to see it.\n\n### Displaying the key to the user\n\nIn this demo, we can display the key to our user and then show a button to request our API. Let's update our component to do this. Underneath our original card, we will add a new card that will display the key to the user. So we can copy the card component and update the content.\n\n```typescript\n{key && key.length > 0 && (\n                <>\n                <Card className=\"w-[350px] mt-8\">\n                <CardHeader>\n                    <CardTitle>API Key</CardTitle>\n                    <CardDescription>Here is your API key. Keep it safe!</CardDescription>\n                </CardHeader>\n                <CardContent>\n                    <div className=\"grid w-full items-center gap-4\">\n                        <div className=\"flex flex-col space-y-1.5\">\n                            <Label htmlFor=\"name\">API Key</Label>\n                            <Input name=\"name\" value={key} />\n                        </div>\n                    </div>\n                </CardContent>\n            </Card>\n```\n\n## Making a request to our API\n\nThe final step is to request our API. We are going to use the key we created to request our API. We are going to use Next.js router handler to make the request. We will create a new folder called `api` and inside that a folder called `secret` and a file called `route.ts`. Inside this file, we are going to add the following code.\n\n```typescript\nimport { verifyKey } from \"@unkey/api\";\nimport { NextResponse } from \"next/server\";\nexport async function GET(request: Request) {\n  const header = request.headers.get(\"Authorization\");\n  if (!header) {\n    return new Response(\"No Authorization header\", { status: 401 });\n  }\n  const token = header.replace(\"Bearer \", \"\");\n  const { result, error } = await verifyKey(token);\n\n  if (error) {\n    console.error(error.message);\n    return new Response(\"Internal Server Error\", { status: 500 });\n  }\n\n  if (!result.valid) {\n    // do not grant access\n    return new Response(\"Unauthorized\", { status: 401 });\n  }\n\n  // process request\n  return NextResponse.json({ result });\n}\n```\n\nUnkey makes it easy to make business decisions. We can verify the key and then return a response based on the result. In this example, we will return a 401 if the key is invalid. If the key is valid, we are going to return the results.\n\n### Updating our client component\n\nTechnically speaking, you could make a request from your favorite API client using `http://localhost:3000/api/secret` and add the Authorization header with the key. But we will add a button to our client component to make the request and display the response to keep everything in one place.\n\n```typescript\n<Card className=\"w-[350px] mt-8\">\n  <CardHeader>\n    <CardTitle>Get Secret Data </CardTitle>\n    <CardDescription>Retrieve secret data from API </CardDescription>\n  </CardHeader>\n  <CardContent>\n    <Button onClick={getData} variant=\"outline\">\n      Get Data\n    </Button>\n    <div className=\"grid w-full items-center gap-4\">\n      <div className=\"flex flex-col space-y-1.5\">\n        <Label htmlFor=\"name\">Secret Data</Label>\n        <Input name=\"name\" value={JSON.stringify(secret)} />\n      </div>\n    </div>\n  </CardContent>\n</Card>\n```\n\nWe need a function called `getData` to request our API. We will use the fetch and add a state to hold the returned data.\n\n```typescript\nconst [key, setKey] = useState<string>(\"\");\nconst [secret, setSecret] = useState<string>(\"\");\nasync function onCreate(formData: FormData) {\n  const res = await create(formData);\n  if (res) setKey(res.key?.key);\n}\nconst getData = async () => {\n  const res = await fetch(`/api/secret`, {\n    headers: {\n      Authorization: `Bearer ${key}`,\n    },\n  });\n  const data = await res.json();\n  setSecret(data.result);\n};\n```\n\nWhen we click the button, we will request our API and display the response. The entire component file should look like this.\n\n```typescript\n\"use client\";\n\nimport { Button } from \"@/components/ui/button\";\nimport {\n  Card,\n  CardContent,\n  CardDescription,\n  CardFooter,\n  CardHeader,\n  CardTitle,\n} from \"@/components/ui/card\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\nimport { create } from \"./create\";\nimport { useState } from \"react\";\n\nconst UnkeyElements = () => {\n  const [key, setKey] = useState<string>(\"\");\n  const [secret, setSecret] = useState<string>(\"\");\n  async function onCreate(formData: FormData) {\n    const res = await create(formData);\n    if (res) setKey(res.key?.key);\n  }\n  const getData = async () => {\n    const res = await fetch(`/api/secret`, {\n      headers: {\n        Authorization: `Bearer ${key}`,\n      },\n    });\n    const data = await res.json();\n    setSecret(data.result);\n  };\n  return (\n    <div className=\"mt-8\">\n      <Card className=\"w-[350px]\">\n        <CardHeader>\n          <CardTitle>Create API Key</CardTitle>\n          <CardDescription>\n            Create your API key so you can interact with our API.\n          </CardDescription>\n        </CardHeader>\n        <form action={onCreate}>\n          <CardContent>\n            <div className=\"grid w-full items-center gap-4\">\n              <div className=\"flex flex-col space-y-1.5\">\n                <Label htmlFor=\"name\">API Key Name</Label>\n                <Input name=\"name\" placeholder=\"My Awesome API \" />\n              </div>\n            </div>\n          </CardContent>\n          <CardFooter className=\"flex justify-between\">\n            <Button type=\"submit\">Create Key</Button>\n          </CardFooter>\n        </form>\n      </Card>\n      {key && key.length > 0 && (\n        <>\n          <Card className=\"w-[350px] mt-8\">\n            <CardHeader>\n              <CardTitle>API Key</CardTitle>\n              <CardDescription>\n                Here is your API key. Keep it safe!\n              </CardDescription>\n            </CardHeader>\n            <CardContent>\n              <div className=\"grid w-full items-center gap-4\">\n                <div className=\"flex flex-col space-y-1.5\">\n                  <Label htmlFor=\"name\">API Key</Label>\n                  <Input name=\"name\" value={key} />\n                </div>\n              </div>\n            </CardContent>\n          </Card>\n          <Card className=\"w-[350px] mt-8\">\n            <CardHeader>\n              <CardTitle>Get Secret Data </CardTitle>\n              <CardDescription>Retrieve secret data from API </CardDescription>\n            </CardHeader>\n            <CardContent>\n              <Button onClick={getData} variant=\"outline\">\n                Get Data\n              </Button>\n              <div className=\"grid w-full items-center gap-4\">\n                <div className=\"flex flex-col space-y-1.5\">\n                  <Label htmlFor=\"name\">Secret Data</Label>\n                  <Input name=\"name\" value={JSON.stringify(secret)} />\n                </div>\n              </div>\n            </CardContent>\n          </Card>\n        </>\n      )}\n    </div>\n  );\n};\n\nexport { UnkeyElements };\n```\n\nThe response from the API will look like this, and as you can see, we now associate the API key to a user.\n\n```json\n{\n  \"valid\": true,\n  \"ownerId\": \"user_2Vi5Z5c9tcZd6dfbgV6tEWDQYVf\"\n}\n```\n\nIn the dashboard for Unkey, you can see the key and the owner ID and the name associated with it\n\n<Image src=\"/images/blog-images/unkey-with-auth/dashboard-example.png\" alt =\"Unkey Dashboard\"/>\n\n## Conclusion\n\nIn this post, we have covered how to use Unkey with an auth provider to secure your API. We have covered how to associate a user with a key and then use that key to request our API. You can check out the code for this project here: [Example](https://github.com/unkeyed/examples/tree/main/unkey-clerk)",
    "title": "Using Unkey with your Authentication Provider",
    "description": "Learn how to use Unkey with an auth provider, to associate your keys with your users.",
    "author": "james",
    "date": "2023-09-21",
    "tags": [
      "tutorials"
    ],
    "image": "/images/blog-images/covers/unkey-auth-provider.png",
    "_meta": {
      "filePath": "using-unkey-with-auth.mdx",
      "fileName": "using-unkey-with-auth.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "using-unkey-with-auth"
    },
    "mdx": "var Component=(()=>{var h=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var k=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),g=(t,e)=>{for(var a in e)o(t,a,{get:e[a],enumerable:!0})},s=(t,e,a,i)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of m(e))!f.call(t,r)&&r!==a&&o(t,r,{get:()=>e[r],enumerable:!(i=p(e,r))||i.enumerable});return t};var w=(t,e,a)=>(a=t!=null?h(y(t)):{},s(e||!t||!t.__esModule?o(a,\"default\",{value:t,enumerable:!0}):a,t)),x=t=>s(o({},\"__esModule\",{value:!0}),t);var d=k((b,c)=>{c.exports=_jsx_runtime});var v={};g(v,{default:()=>u});var n=w(d());function l(t){let e={a:\"a\",code:\"code\",h2:\"h2\",h3:\"h3\",h4:\"h4\",li:\"li\",p:\"p\",pre:\"pre\",ul:\"ul\",...t.components},{Image:a}=e;return a||C(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"When working with your external facing API and having a client application, you need to identify which user owns an API Key. Having a way to identify the user allows you to understand their usage of your product better. This blog is going to cover how you can use your authentication provider to add a way to identify the user.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"what-is-unkey\",children:\"What is Unkey?\"}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey is an open source API management platform that helps developers secure, manage, and scale their APIs. Unkey has built-in features that can make it easier than ever to provide an API to your end users, including:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Per key rate limiting\"}),`\n`,(0,n.jsx)(e.li,{children:\"Limited usage keys\"}),`\n`,(0,n.jsx)(e.li,{children:\"Time-based keys\"}),`\n`,(0,n.jsx)(e.li,{children:\"Per key analytics\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"setting-up-our-project\",children:\"Setting up our project\"}),`\n`,(0,n.jsx)(e.p,{children:\"We will use my favorite authentication provider, Clerk, in this example. The concepts described below are agnostic, so feel free to use whatever provider works for you. We will also use Next.js for demo purposes, but it isn't a requirement.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"create-a-nextjs-application-and-install-dependencies\",children:\"Create a Next.js application and install dependencies.\"}),`\n`,(0,n.jsx)(e.p,{children:\"The first thing we want to do is create our Next.js application and install our dependencies.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`npx create-next-app@latest unkey-with-auth\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"We need Unkey's typescript library and Clerk's next.js package for dependencies.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`npm install @unkey/api @clerk/nextjs\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Then, finally, we are going to use Shadcn to speed up the styling. If you copy the two commands below, it will install everything you need.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`npx shadcn-ui@latest init\n\nnpx shadcn-ui@latest add button input label card\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Make sure you include your Clerk secret key and publishable key in your \",(0,n.jsx)(e.code,{children:\".env.local\"}),\" file. You can find these in your Clerk dashboard. You will also need an Unkey root key and API ID. You can find these in your Unkey dashboard.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_xxxxxxxxxxxxxx\nCLERK_SECRET_KEY=sk_test_xxxxxxxxxxxxxx\nUNKEY_API_ID=api_xxxxxxxxxxxxxx\nUNKEY_ROOT_KEY=unkey_xxxxxxxxxxxxxx\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"clerk-setup-optional\",children:\"Clerk setup (optional)\"}),`\n`,(0,n.jsx)(e.p,{children:\"You can skip this step if you aren't using Clerk as an auth provider. We only need to update our root layout file and add middleware.\"}),`\n`,(0,n.jsx)(e.h4,{id:\"root-layout\",children:\"Root layout\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import \"./globals.css\";\nimport { Inter } from \"next/font/google\";\nimport { ClerkProvider } from \"@clerk/nextjs\";\n\nconst inter = Inter({ subsets: [\"latin\"] });\n\nexport const metadata: Metadata = {\n  title: \"Create Next App\",\n\n  description: \"Generated by create next app\",\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <ClerkProvider>\n      <html lang=\"en\">\n        <body>{children}</body>\n      </html>\n    </ClerkProvider>\n  );\n}\n`})}),`\n`,(0,n.jsx)(e.h4,{id:\"middlewarets\",children:\"Middleware.ts\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Then, you need to add middleware.ts to the root of the project. This protects all pages and routes except \",(0,n.jsx)(e.code,{children:\"/api/secret\"}),\". More on that later.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { authMiddleware } from \"@clerk/nextjs\";\n\nexport default authMiddleware({\n  publicRoutes: \"/api/secret\",\n});\n\nexport const config = {\n  matcher: [\"/((?!.+\\\\\\\\.[\\\\\\\\w]+$|_next).*)\", \"/\", \"/(api|trpc)(.*)\"],\n};\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"creating-a-key-associated-with-a-user\",children:\"Creating a key associated with a user.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Unkey accepts an owner_id when creating a key that we can use to associate our auth provider's unique identifier, such as \",(0,n.jsx)(e.code,{children:\"user_id\"}),\". In our example application, we are going to use a server action to create the key.\"]}),`\n`,(0,n.jsx)(e.h3,{id:\"create-our-unkey-client-component\",children:\"Create our Unkey client component\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"We will create a client component that takes a name for an API. This API key name can make it easier to identify the critical self and not the owner in our demo, but it gives you an idea of how the flow would work. Create a folder called \",(0,n.jsx)(e.code,{children:\"keys\"}),\" and a \",(0,n.jsx)(e.code,{children:\"client.tsx\"}),\" file. Inside that file, add the following imports from our components from shadcn.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`\"use client\";\nimport { Button } from \"@/components/ui/button\";\nimport {\n  Card,\n  CardContent,\n  CardDescription,\n  CardFooter,\n  CardHeader,\n  CardTitle,\n} from \"@/components/ui/card\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Now, we can create our component, which we will name \",(0,n.jsx)(e.code,{children:\"UnkeyElements\"}),\" and use the card component to create an easy-to-use form.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const UnkeyElements = () => {\n  return (\n    <div className=\"mt-8\">\n      <Card className=\"w-[350px]\">\n        <CardHeader>\n          <CardTitle>Create API Key</CardTitle>\n          <CardDescription>\n            Create your API key so you can interact with our API.\n          </CardDescription>\n        </CardHeader>\n\n        <form>\n          <CardContent>\n            <div className=\"grid w-full items-center gap-4\">\n              <div className=\"flex flex-col space-y-1.5\">\n                <Label htmlFor=\"name\">Give your key a name</Label>\n                <Input name=\"name\" placeholder=\"Key for next big thing\" />\n              </div>\n            </div>\n          </CardContent>\n          <CardFooter className=\"flex justify-between\">\n            <Button type=\"submit\">Create Key</Button>\n          </CardFooter>\n        </form>\n      </Card>\n    </div>\n  );\n};\nexport { UnkeyElements };\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Make sure to import this into your \",(0,n.jsx)(e.code,{children:\"page.tsx\"}),\" file and add it to the page.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { UnkeyElements } from \"./keys/client\";\n\nexport default function Home() {\n  return (\n    <main className=\"flex min-h-screen flex-col items-center justify-between p-24\">\n      <div className=\"flex flex-col items-center justify-center\">\n        <h1 className=\"text-4xl font-bold\">\n          Welcome to the Unkey + Auth Provider\n        </h1>\n        <p className=\"text-xl mt-4\">\n          This is a demo of how you can use Unkey to secure your API with an\n          Auth Provider.\n        </p>\n        <UnkeyElements />\n      </div>\n    </main>\n  );\n}\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"adding-a-server-action\",children:\"Adding a server action\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Our server action will allow us to create a key in our application in the \",(0,n.jsx)(e.code,{children:\"keys\"}),\" folder, add a \",(0,n.jsx)(e.code,{children:\"create.ts\"}),\" file. Then, in this file, we will use our auth provider and Unkey together.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`\"use server\";\nimport { auth } from \"@clerk/nextjs\";\nimport { Unkey } from \"@unkey/api\";\nexport async function create(formData: FormData) {\n  \"use server\";\n  const { userId } = auth();\n  if (!userId) {\n    return null;\n  }\n  const token = process.env.UNKEY_ROOT_KEY;\n  const apiId = process.env.UNKEY_API_ID;\n\n  if (!token || !apiId) {\n    return null;\n  }\n\n  const name = (formData.get(\"name\") as string) ?? \"My Awesome API\";\n  const unkey = new Unkey({ token });\n  const key = await unkey.keys.create({\n    name: name,\n    ownerId: userId,\n    apiId,\n  });\n  return { key: key.result };\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"The key creation server action will check if the user is authenticated. If they are, it will create a key with the name provided and the user's ID. If the user isn't authenticated, it will return null. We now have a way to track which user owns which key.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"adding-our-creation-server-action-to-our-client-component\",children:\"Adding our creation server action to our client component\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Now, we have a way to create a key to add to our client component. In our \",(0,n.jsx)(e.code,{children:\"client.tsx\"}),\" file, we will add our server action import and \",(0,n.jsx)(e.code,{children:\"useState\"}),\" to handle the returned key.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { create } from \"./create\";\nimport { useState } from \"react\";\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Now we have the imports, we can add an \",(0,n.jsx)(e.code,{children:\"onCreate\"}),\" function to our component that will call our server action. We can now call that function when the form is submitted.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const UnkeyElements = () => {\n    const [key, setKey] = useState<string>('')\n    async function onCreate(formData: FormData) {\n        const res = await create(formData)\n        if(res) setKey(res.key?.key);\n    }\n    ...\n    <form action={onCreate}>\n          <CardContent>\n            <div className=\"grid w-full items-center gap-4\">\n              <div className=\"flex flex-col space-y-1.5\">\n                <Label htmlFor=\"name\">Give your key a name</Label>\n                <Input name=\"name\" placeholder=\"Key for next big thing\" />\n              </div>\n            </div>\n          </CardContent>\n          <CardFooter className=\"flex justify-between\">\n            <Button type=\"submit\">Create Key</Button>\n          </CardFooter>\n        </form>\n    ...\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"When we submit the form, we will get a key back that we can use to make requests to our API. If you give this a test, you can log out the key in the console to see it.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"displaying-the-key-to-the-user\",children:\"Displaying the key to the user\"}),`\n`,(0,n.jsx)(e.p,{children:\"In this demo, we can display the key to our user and then show a button to request our API. Let's update our component to do this. Underneath our original card, we will add a new card that will display the key to the user. So we can copy the card component and update the content.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`{key && key.length > 0 && (\n                <>\n                <Card className=\"w-[350px] mt-8\">\n                <CardHeader>\n                    <CardTitle>API Key</CardTitle>\n                    <CardDescription>Here is your API key. Keep it safe!</CardDescription>\n                </CardHeader>\n                <CardContent>\n                    <div className=\"grid w-full items-center gap-4\">\n                        <div className=\"flex flex-col space-y-1.5\">\n                            <Label htmlFor=\"name\">API Key</Label>\n                            <Input name=\"name\" value={key} />\n                        </div>\n                    </div>\n                </CardContent>\n            </Card>\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"making-a-request-to-our-api\",children:\"Making a request to our API\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The final step is to request our API. We are going to use the key we created to request our API. We are going to use Next.js router handler to make the request. We will create a new folder called \",(0,n.jsx)(e.code,{children:\"api\"}),\" and inside that a folder called \",(0,n.jsx)(e.code,{children:\"secret\"}),\" and a file called \",(0,n.jsx)(e.code,{children:\"route.ts\"}),\". Inside this file, we are going to add the following code.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { verifyKey } from \"@unkey/api\";\nimport { NextResponse } from \"next/server\";\nexport async function GET(request: Request) {\n  const header = request.headers.get(\"Authorization\");\n  if (!header) {\n    return new Response(\"No Authorization header\", { status: 401 });\n  }\n  const token = header.replace(\"Bearer \", \"\");\n  const { result, error } = await verifyKey(token);\n\n  if (error) {\n    console.error(error.message);\n    return new Response(\"Internal Server Error\", { status: 500 });\n  }\n\n  if (!result.valid) {\n    // do not grant access\n    return new Response(\"Unauthorized\", { status: 401 });\n  }\n\n  // process request\n  return NextResponse.json({ result });\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Unkey makes it easy to make business decisions. We can verify the key and then return a response based on the result. In this example, we will return a 401 if the key is invalid. If the key is valid, we are going to return the results.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"updating-our-client-component\",children:\"Updating our client component\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Technically speaking, you could make a request from your favorite API client using \",(0,n.jsx)(e.code,{children:\"http://localhost:3000/api/secret\"}),\" and add the Authorization header with the key. But we will add a button to our client component to make the request and display the response to keep everything in one place.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`<Card className=\"w-[350px] mt-8\">\n  <CardHeader>\n    <CardTitle>Get Secret Data </CardTitle>\n    <CardDescription>Retrieve secret data from API </CardDescription>\n  </CardHeader>\n  <CardContent>\n    <Button onClick={getData} variant=\"outline\">\n      Get Data\n    </Button>\n    <div className=\"grid w-full items-center gap-4\">\n      <div className=\"flex flex-col space-y-1.5\">\n        <Label htmlFor=\"name\">Secret Data</Label>\n        <Input name=\"name\" value={JSON.stringify(secret)} />\n      </div>\n    </div>\n  </CardContent>\n</Card>\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"We need a function called \",(0,n.jsx)(e.code,{children:\"getData\"}),\" to request our API. We will use the fetch and add a state to hold the returned data.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const [key, setKey] = useState<string>(\"\");\nconst [secret, setSecret] = useState<string>(\"\");\nasync function onCreate(formData: FormData) {\n  const res = await create(formData);\n  if (res) setKey(res.key?.key);\n}\nconst getData = async () => {\n  const res = await fetch(\\`/api/secret\\`, {\n    headers: {\n      Authorization: \\`Bearer \\${key}\\`,\n    },\n  });\n  const data = await res.json();\n  setSecret(data.result);\n};\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"When we click the button, we will request our API and display the response. The entire component file should look like this.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`\"use client\";\n\nimport { Button } from \"@/components/ui/button\";\nimport {\n  Card,\n  CardContent,\n  CardDescription,\n  CardFooter,\n  CardHeader,\n  CardTitle,\n} from \"@/components/ui/card\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\nimport { create } from \"./create\";\nimport { useState } from \"react\";\n\nconst UnkeyElements = () => {\n  const [key, setKey] = useState<string>(\"\");\n  const [secret, setSecret] = useState<string>(\"\");\n  async function onCreate(formData: FormData) {\n    const res = await create(formData);\n    if (res) setKey(res.key?.key);\n  }\n  const getData = async () => {\n    const res = await fetch(\\`/api/secret\\`, {\n      headers: {\n        Authorization: \\`Bearer \\${key}\\`,\n      },\n    });\n    const data = await res.json();\n    setSecret(data.result);\n  };\n  return (\n    <div className=\"mt-8\">\n      <Card className=\"w-[350px]\">\n        <CardHeader>\n          <CardTitle>Create API Key</CardTitle>\n          <CardDescription>\n            Create your API key so you can interact with our API.\n          </CardDescription>\n        </CardHeader>\n        <form action={onCreate}>\n          <CardContent>\n            <div className=\"grid w-full items-center gap-4\">\n              <div className=\"flex flex-col space-y-1.5\">\n                <Label htmlFor=\"name\">API Key Name</Label>\n                <Input name=\"name\" placeholder=\"My Awesome API \" />\n              </div>\n            </div>\n          </CardContent>\n          <CardFooter className=\"flex justify-between\">\n            <Button type=\"submit\">Create Key</Button>\n          </CardFooter>\n        </form>\n      </Card>\n      {key && key.length > 0 && (\n        <>\n          <Card className=\"w-[350px] mt-8\">\n            <CardHeader>\n              <CardTitle>API Key</CardTitle>\n              <CardDescription>\n                Here is your API key. Keep it safe!\n              </CardDescription>\n            </CardHeader>\n            <CardContent>\n              <div className=\"grid w-full items-center gap-4\">\n                <div className=\"flex flex-col space-y-1.5\">\n                  <Label htmlFor=\"name\">API Key</Label>\n                  <Input name=\"name\" value={key} />\n                </div>\n              </div>\n            </CardContent>\n          </Card>\n          <Card className=\"w-[350px] mt-8\">\n            <CardHeader>\n              <CardTitle>Get Secret Data </CardTitle>\n              <CardDescription>Retrieve secret data from API </CardDescription>\n            </CardHeader>\n            <CardContent>\n              <Button onClick={getData} variant=\"outline\">\n                Get Data\n              </Button>\n              <div className=\"grid w-full items-center gap-4\">\n                <div className=\"flex flex-col space-y-1.5\">\n                  <Label htmlFor=\"name\">Secret Data</Label>\n                  <Input name=\"name\" value={JSON.stringify(secret)} />\n                </div>\n              </div>\n            </CardContent>\n          </Card>\n        </>\n      )}\n    </div>\n  );\n};\n\nexport { UnkeyElements };\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"The response from the API will look like this, and as you can see, we now associate the API key to a user.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-json\",children:`{\n  \"valid\": true,\n  \"ownerId\": \"user_2Vi5Z5c9tcZd6dfbgV6tEWDQYVf\"\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"In the dashboard for Unkey, you can see the key and the owner ID and the name associated with it\"}),`\n`,(0,n.jsx)(a,{src:\"/images/blog-images/unkey-with-auth/dashboard-example.png\",alt:\"Unkey Dashboard\"}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"In this post, we have covered how to use Unkey with an auth provider to secure your API. We have covered how to associate a user with a key and then use that key to request our API. You can check out the code for this project here: \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/examples/tree/main/unkey-clerk\",children:\"Example\"})]})]})}function u(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(l,{...t})}):l(t)}function C(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return x(v);})();\n;return Component;",
    "slug": "using-unkey-with-auth",
    "url": "/blog/using-unkey-with-auth",
    "tableOfContents": [
      {
        "level": 2,
        "text": "What is Unkey?",
        "slug": "what-is-unkey"
      },
      {
        "level": 2,
        "text": "Setting up our project",
        "slug": "setting-up-our-project"
      },
      {
        "level": 3,
        "text": "Create a Next.js application and install dependencies.",
        "slug": "create-a-nextjs-application-and-install-dependencies"
      },
      {
        "level": 3,
        "text": "Clerk setup (optional)",
        "slug": "clerk-setup-optional"
      },
      {
        "level": 4,
        "text": "Root layout",
        "slug": "root-layout"
      },
      {
        "level": 4,
        "text": "Middleware.ts",
        "slug": "middlewarets"
      },
      {
        "level": 2,
        "text": "Creating a key associated with a user.",
        "slug": "creating-a-key-associated-with-a-user"
      },
      {
        "level": 3,
        "text": "Create our Unkey client component",
        "slug": "create-our-unkey-client-component"
      },
      {
        "level": 3,
        "text": "Adding a server action",
        "slug": "adding-a-server-action"
      },
      {
        "level": 3,
        "text": "Adding our creation server action to our client component",
        "slug": "adding-our-creation-server-action-to-our-client-component"
      },
      {
        "level": 3,
        "text": "Displaying the key to the user",
        "slug": "displaying-the-key-to-the-user"
      },
      {
        "level": 2,
        "text": "Making a request to our API",
        "slug": "making-a-request-to-our-api"
      },
      {
        "level": 3,
        "text": "Updating our client component",
        "slug": "updating-our-client-component"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  },
  {
    "content": "<p className=\"text-center\">\nTLDR: Please don't do this:\n</p>\n```bash\nhttps://company.com/resource/c6b10dd3-1dcf-416c-8ed8-ae561807fcaf\n```\n\n---\n\n## The baseline: Ensuring global uniqueness\n\nUnique identifiers are essential for distinguishing individual entities within a system. They provide a reliable way to ensure that each item, user, or piece of data has a unique identity. By maintaining uniqueness, applications can effectively manage and organize information, enabling efficient operations and facilitating data integrity.\n\nLets not pretend like we are Google or AWS who have special needs around this. Any securely generated UUID with 128 bits is more than enough for us. There are lots of libraries that generate one, or you could fall back to the standard library of your language of choice. In this blog, I'll be using Typescript examples, but the underlying ideas apply to any language.\n\n```typescript\nconst id = crypto.randomUUID();\n// '5727a4a4-9bba-41ae-b7fe-e69cf60bb0ab'\n```\n\nStopping here is an option, but let's take the opportunity to enhance the user experience with small yet effective iterative changes:\n\n1. Make them easy to copy\n2. Prefixing\n3. More efficient encoding\n4. Changing the length\n\n### Copying UUIDs is annoying\n\nTry copying this UUID by double-clicking on it:\n\n```bash\nc6b10dd3-1dcf-416c-8ed8-ae561807fcaf\n```\n\nIf you're lucky, you got the entire UUID but for most people, they got a single section. One way to enhance the usability of unique identifiers is by making them easily copyable. This can be achieved by removing the hyphens from the UUIDs, allowing users to simply double-click on the identifier to copy it. By eliminating the need for manual selection and copy-pasting, this small change can greatly improve the user experience when working with identifiers.\n\nRemoving the hyphens is probably trivial in all languages, heres how you can do it in js/ts:\n\n```typescript\nconst id = crypto.randomUUID().replace(/-/g, \"\");\n// fe4723eab07f408384a2c0f051696083\n```\n\nTry copying it now, its much nicer!\n\n### Prefixing\n\nHave you ever accidentally used a production API key in a development environment? I have, and its not fun.\nWe can help the user differentiate between different environments or resources within the system by adding a meaningful prefix. For example, Stripe uses prefixes like `sk_live_` for production environment secret keys or `cus_` for customer identifiers. By incorporating such prefixes, we can ensure clarity and reduce the chances of confusion, especially in complex systems where multiple environments coexist.\n\n```typescript\nconst id = `hello_${crypto.randomUUID().replace(/-/g, \"\")}`;\n// hello_1559debea64142f3b2d29f8b0f126041\n```\n\nNaming prefixes is an art just like naming variables. You want to be descriptive but be as short as possible. I'll share ours further down.\n\n### Encoding in base58\n\nInstead of using a hexadecimal representation for identifiers, we can also consider encoding them more efficiently, such as base58. Base58 encoding uses a larger character set and avoids ambiguous characters, such as upper case `I` and lower case `l` resulting in shorter identifier strings without compromising readability.\n\nAs an example, an 8-character long base58 string, can store roughly 30.000 times as many states as an 8-char hex string. And at 16 chars, the base58 string can store 889.054.070 as many combinations.\n\nYou can probably still do this with the standard library of your language but you could also use a library like [nanoid](https://github.com/ai/nanoid) which is available for most languages.\n\n```typescript\nimport { customAlphabet } from \"nanoid\";\nexport const nanoid = customAlphabet(\n  \"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\",\n);\n\nconst id = `prefix_${nanoid(22)}`;\n// prefix_KSPKGySWPqJWWWa37RqGaX\n```\n\nWe generated a 22 character long ID here, which can encode ~100x as many states as a UUID while being 10 characters shorter.\n\n|        | Characters | Length | Total States    |\n| ------ | ---------- | ------ | --------------- |\n| UUID   | 16         | 32     | 2^122 = 5.3e+36 |\n| Base58 | 58         | 22     | 58^22 = 6.2e+38 |\n\n_The more states, the higher your collision resistance is because it takes more generations to generate the same ID twice (on average and if your algorithm is truly random)_\n\n### Changing the entropy\n\nNot all identifiers need to have a high level of collision resistance. In some cases, shorter identifiers can be sufficient, depending on the specific requirements of the application. By reducing the entropy of the identifiers, we can generate shorter IDs while still maintaining an acceptable level of uniqueness.\n\nReducing the length of your IDs can be nice, but you need to be careful and ensure your system is protected against ID collissions. Fortunately, this is pretty easy to do in your database layer. In our MySQL database we use IDs mostly as primary key and the database protects us from collisions. In case an ID exists already, we just generate a new one and try again. If our collision rate would go up significantly, we could simply increase the length of all future IDs and wed be fine.\n\n| Length     | Example                          | Total States |\n| ---------- | -------------------------------- | ------------ |\n| nanoid(8)  | re6ZkUUV                         | 1.3e+14      |\n| nanoid(12) | pfpPYdZGbZvw                     | 1.4e+21      |\n| nanoid(16) | sFDUZScHfZTfkLwk                 | 1.6e+28      |\n| nanoid(24) | u7vzXJL9cGqUeabGPAZ5XUJ6         | 2.1e+42      |\n| nanoid(32) | qkvPDeH6JyAsRhaZ3X4ZLDPSLFP7MnJz | 2.7e+56      |\n\n## Conclusion\n\nBy implementing these improvements, we can enhance the usability and efficiency of unique identifiers in our applications. This will provide a better experience for both users and developers, as they interact with and manage various entities within the system. Whether it's copying identifiers with ease, differentiating between different environments, or achieving shorter and more readable identifier strings, these strategies can contribute to a more user-friendly and robust identification system.\n\n## IDs and keys at Unkey\n\nLastly, I'd like to share our implementation here and how we use it in our [codebase](https://github.com/unkeyed/unkey/blob/main/internal/id/src/index.ts). We use a simple function that takes a typed prefix and then generates the ID for us. This way we can ensure that we always use the same prefix for the same type of ID. This is especially useful when you have multiple types of IDs in your system.\n\n```typescript title=\"/internal/ids/src/index.ts\"\nimport { customAlphabet } from \"nanoid\";\nexport const nanoid = customAlphabet(\n  \"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\",\n);\n\nconst prefixes = {\n  key: \"key\",\n  api: \"api\",\n  policy: \"pol\",\n  request: \"req\",\n  workspace: \"ws\",\n  keyAuth: \"key_auth\", // <-- this is internal and does not need to be short or pretty\n  vercelBinding: \"vb\",\n  test: \"test\", // <-- for tests only\n} as const;\n\nexport function newId(prefix: keyof typeof prefixes): string {\n  return [prefixes[prefix], nanoid(16)].join(\"_\");\n}\n```\n\nAnd when we use it in our codebase, we can ensure that we always use the correct prefix for the correct type of id.\n\n```typescript title=\"somewhere.ts\"\nimport { newId } from \"@unkey/id\";\n\nconst id = newId(\"workspace\");\n// ws_dYuyGV3qMKvebjML\n\nconst id = newId(\"keyy\");\n// invalid because `keyy` is not a valid prefix name\n```\n\n---\n\nI've been mostly talking about identifiers here, but an api key really is just an identifier too. It's just a special kind of identifier that is used to authenticate requests. We use the same strategies for our api keys as we do for our identifiers. You can add a prefix to let your users know what kind of key they are looking at and you can specify the length of the key within reason.\nColissions for API keys are much more serious than ids, so we enforce secure limits.\n\nIt's quite common to prefix your API keys with something that identifies your company. For example [Resend](https://resend.com) are using `re_` and [OpenStatus](https://openstatus.dev) are using `os_` prefixes. This allows your users to quickly identify the key and know what it's used for.\n\n```typescript title=\"setting the key length and a prefix using @unkey/api\"\nconst key = await unkey.key.create({\n  apiId: \"api_dzeBEZDwJ18WyD7b\",\n  prefix: \"blog\",\n  byteLength: 16,\n  // ... omitted for brevity\n});\n\n// Created key:\n// blog_cLsvCvmY35kCfchi\n```",
    "title": "The UX of UUIDs",
    "description": "Unique identifiers play a crucial role in all applications, from user authentication to resource management. While using a standard UUID will satisfy all your security concerns, theres a lot we can improve for our users.",
    "author": "andreas",
    "date": "2023-12-07",
    "tags": [
      "engineering"
    ],
    "image": "/images/blog-images/covers/uuid-ux.png",
    "_meta": {
      "filePath": "uuid-ux.mdx",
      "fileName": "uuid-ux.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "uuid-ux"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var a=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var y=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var m=(i,e)=>()=>(e||i((e={exports:{}}).exports,e),e.exports),b=(i,e)=>{for(var t in e)a(i,t,{get:e[t],enumerable:!0})},o=(i,e,t,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of y(e))!g.call(i,r)&&r!==t&&a(i,r,{get:()=>e[r],enumerable:!(s=p(e,r))||s.enumerable});return i};var w=(i,e,t)=>(t=i!=null?u(f(i)):{},o(e||!i||!i.__esModule?a(t,\"default\",{value:i,enumerable:!0}):t,i)),k=i=>o(a({},\"__esModule\",{value:!0}),i);var d=m((I,c)=>{c.exports=_jsx_runtime});var x={};b(x,{default:()=>h});var n=w(d());function l(i){let e={a:\"a\",code:\"code\",em:\"em\",h2:\"h2\",h3:\"h3\",hr:\"hr\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",table:\"table\",tbody:\"tbody\",td:\"td\",th:\"th\",thead:\"thead\",tr:\"tr\",...i.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(\"p\",{className:\"text-center\",children:(0,n.jsx)(e.p,{children:\"TLDR: Please don't do this:\"})}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`https://company.com/resource/c6b10dd3-1dcf-416c-8ed8-ae561807fcaf\n`})}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsx)(e.h2,{id:\"the-baseline-ensuring-global-uniqueness\",children:\"The baseline: Ensuring global uniqueness\"}),`\n`,(0,n.jsx)(e.p,{children:\"Unique identifiers are essential for distinguishing individual entities within a system. They provide a reliable way to ensure that each item, user, or piece of data has a unique identity. By maintaining uniqueness, applications can effectively manage and organize information, enabling efficient operations and facilitating data integrity.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Let\\u2019s not pretend like we are Google or AWS who have special needs around this. Any securely generated UUID with 128 bits is more than enough for us. There are lots of libraries that generate one, or you could fall back to the standard library of your language of choice. In this blog, I'll be using Typescript examples, but the underlying ideas apply to any language.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const id = crypto.randomUUID();\n// '5727a4a4-9bba-41ae-b7fe-e69cf60bb0ab'\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Stopping here is an option, but let's take the opportunity to enhance the user experience with small yet effective iterative changes:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Make them easy to copy\"}),`\n`,(0,n.jsx)(e.li,{children:\"Prefixing\"}),`\n`,(0,n.jsx)(e.li,{children:\"More efficient encoding\"}),`\n`,(0,n.jsx)(e.li,{children:\"Changing the length\"}),`\n`]}),`\n`,(0,n.jsx)(e.h3,{id:\"copying-uuids-is-annoying\",children:\"Copying UUIDs is annoying\"}),`\n`,(0,n.jsx)(e.p,{children:\"Try copying this UUID by double-clicking on it:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`c6b10dd3-1dcf-416c-8ed8-ae561807fcaf\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"If you're lucky, you got the entire UUID but for most people, they got a single section. One way to enhance the usability of unique identifiers is by making them easily copyable. This can be achieved by removing the hyphens from the UUIDs, allowing users to simply double-click on the identifier to copy it. By eliminating the need for manual selection and copy-pasting, this small change can greatly improve the user experience when working with identifiers.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Removing the hyphens is probably trivial in all languages, here\\u2019s how you can do it in js/ts:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const id = crypto.randomUUID().replace(/-/g, \"\");\n// fe4723eab07f408384a2c0f051696083\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Try copying it now, it\\u2019s much nicer!\"}),`\n`,(0,n.jsx)(e.h3,{id:\"prefixing\",children:\"Prefixing\"}),`\n`,(0,n.jsxs)(e.p,{children:[`Have you ever accidentally used a production API key in a development environment? I have, and it\\u2019s not fun.\nWe can help the user differentiate between different environments or resources within the system by adding a meaningful prefix. For example, Stripe uses prefixes like `,(0,n.jsx)(e.code,{children:\"sk_live_\"}),\" for production environment secret keys or \",(0,n.jsx)(e.code,{children:\"cus_\"}),\" for customer identifiers. By incorporating such prefixes, we can ensure clarity and reduce the chances of confusion, especially in complex systems where multiple environments coexist.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:'const id = `hello_${crypto.randomUUID().replace(/-/g, \"\")}`;\\n// hello_1559debea64142f3b2d29f8b0f126041\\n'})}),`\n`,(0,n.jsx)(e.p,{children:\"Naming prefixes is an art just like naming variables. You want to be descriptive but be as short as possible. I'll share ours further down.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"encoding-in-base58\",children:\"Encoding in base58\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Instead of using a hexadecimal representation for identifiers, we can also consider encoding them more efficiently, such as base58. Base58 encoding uses a larger character set and avoids ambiguous characters, such as upper case \",(0,n.jsx)(e.code,{children:\"I\"}),\" and lower case \",(0,n.jsx)(e.code,{children:\"l\"}),\" resulting in shorter identifier strings without compromising readability.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"As an example, an 8-character long base58 string, can store roughly 30.000 times as many states as an 8-char hex string. And at 16 chars, the base58 string can store 889.054.070 as many combinations.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"You can probably still do this with the standard library of your language but you could also use a library like \",(0,n.jsx)(e.a,{href:\"https://github.com/ai/nanoid\",children:\"nanoid\"}),\" which is available for most languages.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { customAlphabet } from \"nanoid\";\nexport const nanoid = customAlphabet(\n  \"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\",\n);\n\nconst id = \\`prefix_\\${nanoid(22)}\\`;\n// prefix_KSPKGySWPqJWWWa37RqGaX\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"We generated a 22 character long ID here, which can encode ~100x as many states as a UUID while being 10 characters shorter.\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{}),(0,n.jsx)(e.th,{children:\"Characters\"}),(0,n.jsx)(e.th,{children:\"Length\"}),(0,n.jsx)(e.th,{children:\"Total States\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"UUID\"}),(0,n.jsx)(e.td,{children:\"16\"}),(0,n.jsx)(e.td,{children:\"32\"}),(0,n.jsx)(e.td,{children:\"2^122 = 5.3e+36\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"Base58\"}),(0,n.jsx)(e.td,{children:\"58\"}),(0,n.jsx)(e.td,{children:\"22\"}),(0,n.jsx)(e.td,{children:\"58^22 = 6.2e+38\"})]})]})]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.em,{children:\"The more states, the higher your collision resistance is because it takes more generations to generate the same ID twice (on average and if your algorithm is truly random)\"})}),`\n`,(0,n.jsx)(e.h3,{id:\"changing-the-entropy\",children:\"Changing the entropy\"}),`\n`,(0,n.jsx)(e.p,{children:\"Not all identifiers need to have a high level of collision resistance. In some cases, shorter identifiers can be sufficient, depending on the specific requirements of the application. By reducing the entropy of the identifiers, we can generate shorter IDs while still maintaining an acceptable level of uniqueness.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Reducing the length of your IDs can be nice, but you need to be careful and ensure your system is protected against ID collissions. Fortunately, this is pretty easy to do in your database layer. In our MySQL database we use IDs mostly as primary key and the database protects us from collisions. In case an ID exists already, we just generate a new one and try again. If our collision rate would go up significantly, we could simply increase the length of all future IDs and we\\u2019d be fine.\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Length\"}),(0,n.jsx)(e.th,{children:\"Example\"}),(0,n.jsx)(e.th,{children:\"Total States\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"nanoid(8)\"}),(0,n.jsx)(e.td,{children:\"re6ZkUUV\"}),(0,n.jsx)(e.td,{children:\"1.3e+14\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"nanoid(12)\"}),(0,n.jsx)(e.td,{children:\"pfpPYdZGbZvw\"}),(0,n.jsx)(e.td,{children:\"1.4e+21\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"nanoid(16)\"}),(0,n.jsx)(e.td,{children:\"sFDUZScHfZTfkLwk\"}),(0,n.jsx)(e.td,{children:\"1.6e+28\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"nanoid(24)\"}),(0,n.jsx)(e.td,{children:\"u7vzXJL9cGqUeabGPAZ5XUJ6\"}),(0,n.jsx)(e.td,{children:\"2.1e+42\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"nanoid(32)\"}),(0,n.jsx)(e.td,{children:\"qkvPDeH6JyAsRhaZ3X4ZLDPSLFP7MnJz\"}),(0,n.jsx)(e.td,{children:\"2.7e+56\"})]})]})]}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsx)(e.p,{children:\"By implementing these improvements, we can enhance the usability and efficiency of unique identifiers in our applications. This will provide a better experience for both users and developers, as they interact with and manage various entities within the system. Whether it's copying identifiers with ease, differentiating between different environments, or achieving shorter and more readable identifier strings, these strategies can contribute to a more user-friendly and robust identification system.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"ids-and-keys-at-unkey\",children:\"IDs and keys at Unkey\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Lastly, I'd like to share our implementation here and how we use it in our \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/unkey/blob/main/internal/id/src/index.ts\",children:\"codebase\"}),\". We use a simple function that takes a typed prefix and then generates the ID for us. This way we can ensure that we always use the same prefix for the same type of ID. This is especially useful when you have multiple types of IDs in your system.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { customAlphabet } from \"nanoid\";\nexport const nanoid = customAlphabet(\n  \"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\",\n);\n\nconst prefixes = {\n  key: \"key\",\n  api: \"api\",\n  policy: \"pol\",\n  request: \"req\",\n  workspace: \"ws\",\n  keyAuth: \"key_auth\", // <-- this is internal and does not need to be short or pretty\n  vercelBinding: \"vb\",\n  test: \"test\", // <-- for tests only\n} as const;\n\nexport function newId(prefix: keyof typeof prefixes): string {\n  return [prefixes[prefix], nanoid(16)].join(\"_\");\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"And when we use it in our codebase, we can ensure that we always use the correct prefix for the correct type of id.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`import { newId } from \"@unkey/id\";\n\nconst id = newId(\"workspace\");\n// ws_dYuyGV3qMKvebjML\n\nconst id = newId(\"keyy\");\n// invalid because \\`keyy\\` is not a valid prefix name\n`})}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsx)(e.p,{children:`I've been mostly talking about identifiers here, but an api key really is just an identifier too. It's just a special kind of identifier that is used to authenticate requests. We use the same strategies for our api keys as we do for our identifiers. You can add a prefix to let your users know what kind of key they are looking at and you can specify the length of the key within reason.\nColissions for API keys are much more serious than ids, so we enforce secure limits.`}),`\n`,(0,n.jsxs)(e.p,{children:[\"It's quite common to prefix your API keys with something that identifies your company. For example \",(0,n.jsx)(e.a,{href:\"https://resend.com\",children:\"Resend\"}),\" are using \",(0,n.jsx)(e.code,{children:\"re_\"}),\" and \",(0,n.jsx)(e.a,{href:\"https://openstatus.dev\",children:\"OpenStatus\"}),\" are using \",(0,n.jsx)(e.code,{children:\"os_\"}),\" prefixes. This allows your users to quickly identify the key and know what it's used for.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-typescript\",children:`const key = await unkey.key.create({\n  apiId: \"api_dzeBEZDwJ18WyD7b\",\n  prefix: \"blog\",\n  byteLength: 16,\n  // ... omitted for brevity\n});\n\n// Created key:\n// blog_cLsvCvmY35kCfchi\n`})})]})}function h(i={}){let{wrapper:e}=i.components||{};return e?(0,n.jsx)(e,{...i,children:(0,n.jsx)(l,{...i})}):l(i)}return k(x);})();\n;return Component;",
    "slug": "uuid-ux",
    "url": "/blog/uuid-ux",
    "tableOfContents": [
      {
        "level": 2,
        "text": "The baseline: Ensuring global uniqueness",
        "slug": "the-baseline-ensuring-global-uniqueness"
      },
      {
        "level": 3,
        "text": "Copying UUIDs is annoying",
        "slug": "copying-uuids-is-annoying"
      },
      {
        "level": 3,
        "text": "Prefixing",
        "slug": "prefixing"
      },
      {
        "level": 3,
        "text": "Encoding in base58",
        "slug": "encoding-in-base58"
      },
      {
        "level": 3,
        "text": "Changing the entropy",
        "slug": "changing-the-entropy"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      },
      {
        "level": 2,
        "text": "IDs and keys at Unkey",
        "slug": "ids-and-keys-at-unkey"
      }
    ]
  },
  {
    "content": "*The most requested feature for Unkey has finally arrived.*\n\nUntil now we only stored a one way hash of the key, enough to verify it, but nobody was able to show the original key again. Recovering the key, meaning showing the key after it was created, was not possible.\n\n\nThere are good reasons against making keys recoverable, the leading one being security. If an attacker gains access to database, they can see the hashes, but not the keys. But there are also good reasons for making keys recoverable:\n\n- API playgrounds/documentation that use real keys for demo purposes\n- Better DX for your users, it's annoying to create a new key and update it everywhere\n\n## Introducing Vault\n\nWe were hesitant to allow key recovery, but we've found a way to do it securely, and in combination with our permissioning system to limit the capabilities of keys, we're happy to roll it out for everyone.\n\nVault is our secure service for encrypting and decrypting secrets. We'll do an engineering deep dive on it soon, but for now, let's focus on how you can use it.\n\n## Recovering keys\nIf encryption is enabled for your API, you can now recover keys like so:\n\nBoth the [getKey](/docs/api-reference/keys/get) and [listKeys](/docs/api-reference/apis/list-keys) endpoints accept a `decrypt` query parameter. If you set this to `true`, the key will be decrypted and returned in the response as `plaintext`.\n\nWhen recovering keys, your root key must have permission to decrypt. Head over to the [dashboard](https://app.unkey.com/settings/root-keys) and make sure the `decrypt_key` permission is enabled.\n\n```shell\ncurl --request GET \\\n  --url https://api.unkey.dev/v1/keys.getKey?keyId={KEY_ID}&decrypt=true \\\n  --header 'Authorization: Bearer {ROOT_KEY}'\n\n{\n  \"ownerId\": \"ACME\",\n  \"plaintext\": \"your-key-here\",\n  // ...\n}\n```\n\nThis is also possible in our SDKs, but omitted here for brevity.\n\n\n## Opt in\n\nWe require you to opt in to key recovery. To opt in, follow these steps:\n\n1. **Root key permissions:**<br/>\nWhen creating new keys, your root key must have permission to encrypt. Head over to the dashboard and make sure the encrypt_key permission is enabled.\nDo not skip this step. Otherwise your root key will get rejected when trying to create new keys.\n\n2. **Contact us:**<br/>\nTo opt in to recovery, send us an email at support@unkey.dev. Send us the email from the email address associated with your workspace and include the API ID that you want to enable recovery for.\n\n\n## Documentation\n\nYou can find the documentation [here](https://www.unkey.com/docs/security/recovering-keys).\n\n## Support\n\nIf you have any questions about recovery, please reach out to us on [Discord](https://unkey.com/discord) or at [support@unkey.dev](mailto:support@unkey.dev). \n\nFor security concerns, please disclose them responsibly by emailing [security@unkey.dev](mailto:security@unkey.dev) instead.",
    "title": "Vault",
    "description": "Securely store and recover keys",
    "author": "andreas",
    "date": "2024-06-28",
    "tags": [
      "launchweek",
      "marketing"
    ],
    "image": "/images/blog-images/covers/vault.png",
    "_meta": {
      "filePath": "vault.mdx",
      "fileName": "vault.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "vault"
    },
    "mdx": "var Component=(()=>{var y=Object.create;var i=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var k=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var g=(r,e)=>()=>(e||r((e={exports:{}}).exports,e),e.exports),f=(r,e)=>{for(var t in e)i(r,t,{get:e[t],enumerable:!0})},a=(r,e,t,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let o of p(e))!m.call(r,o)&&o!==t&&i(r,o,{get:()=>e[o],enumerable:!(s=u(e,o))||s.enumerable});return r};var v=(r,e,t)=>(t=r!=null?y(k(r)):{},a(e||!r||!r.__esModule?i(t,\"default\",{value:r,enumerable:!0}):t,r)),w=r=>a(i({},\"__esModule\",{value:!0}),r);var d=g((_,c)=>{c.exports=_jsx_runtime});var b={};f(b,{default:()=>l});var n=v(d());function h(r){let e={a:\"a\",code:\"code\",em:\"em\",h2:\"h2\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",strong:\"strong\",ul:\"ul\",...r.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:(0,n.jsx)(e.em,{children:\"The most requested feature for Unkey has finally arrived.\"})}),`\n`,(0,n.jsx)(e.p,{children:\"Until now we only stored a one way hash of the key, enough to verify it, but nobody was able to show the original key again. Recovering the key, meaning showing the key after it was created, was not possible.\"}),`\n`,(0,n.jsx)(e.p,{children:\"There are good reasons against making keys recoverable, the leading one being security. If an attacker gains access to database, they can see the hashes, but not the keys. But there are also good reasons for making keys recoverable:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"API playgrounds/documentation that use real keys for demo purposes\"}),`\n`,(0,n.jsx)(e.li,{children:\"Better DX for your users, it's annoying to create a new key and update it everywhere\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"introducing-vault\",children:\"Introducing Vault\"}),`\n`,(0,n.jsx)(e.p,{children:\"We were hesitant to allow key recovery, but we've found a way to do it securely, and in combination with our permissioning system to limit the capabilities of keys, we're happy to roll it out for everyone.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Vault is our secure service for encrypting and decrypting secrets. We'll do an engineering deep dive on it soon, but for now, let's focus on how you can use it.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"recovering-keys\",children:\"Recovering keys\"}),`\n`,(0,n.jsx)(e.p,{children:\"If encryption is enabled for your API, you can now recover keys like so:\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Both the \",(0,n.jsx)(e.a,{href:\"/docs/api-reference/keys/get\",children:\"getKey\"}),\" and \",(0,n.jsx)(e.a,{href:\"/docs/api-reference/apis/list-keys\",children:\"listKeys\"}),\" endpoints accept a \",(0,n.jsx)(e.code,{children:\"decrypt\"}),\" query parameter. If you set this to \",(0,n.jsx)(e.code,{children:\"true\"}),\", the key will be decrypted and returned in the response as \",(0,n.jsx)(e.code,{children:\"plaintext\"}),\".\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"When recovering keys, your root key must have permission to decrypt. Head over to the \",(0,n.jsx)(e.a,{href:\"https://app.unkey.com/settings/root-keys\",children:\"dashboard\"}),\" and make sure the \",(0,n.jsx)(e.code,{children:\"decrypt_key\"}),\" permission is enabled.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-shell\",children:`curl --request GET \\\\\n  --url https://api.unkey.dev/v1/keys.getKey?keyId={KEY_ID}&decrypt=true \\\\\n  --header 'Authorization: Bearer {ROOT_KEY}'\n\n{\n  \"ownerId\": \"ACME\",\n  \"plaintext\": \"your-key-here\",\n  // ...\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"This is also possible in our SDKs, but omitted here for brevity.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"opt-in\",children:\"Opt in\"}),`\n`,(0,n.jsx)(e.p,{children:\"We require you to opt in to key recovery. To opt in, follow these steps:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Root key permissions:\"}),(0,n.jsx)(\"br\",{}),`\nWhen creating new keys, your root key must have permission to encrypt. Head over to the dashboard and make sure the encrypt_key permission is enabled.\nDo not skip this step. Otherwise your root key will get rejected when trying to create new keys.`]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Contact us:\"}),(0,n.jsx)(\"br\",{}),`\nTo opt in to recovery, send us an email at `,(0,n.jsx)(e.a,{href:\"mailto:support@unkey.dev\",children:\"support@unkey.dev\"}),\". Send us the email from the email address associated with your workspace and include the API ID that you want to enable recovery for.\"]}),`\n`]}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"documentation\",children:\"Documentation\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"You can find the documentation \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/security/recovering-keys\",children:\"here\"}),\".\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"support\",children:\"Support\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"If you have any questions about recovery, please reach out to us on \",(0,n.jsx)(e.a,{href:\"https://unkey.com/discord\",children:\"Discord\"}),\" or at \",(0,n.jsx)(e.a,{href:\"mailto:support@unkey.dev\",children:\"support@unkey.dev\"}),\".\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"For security concerns, please disclose them responsibly by emailing \",(0,n.jsx)(e.a,{href:\"mailto:security@unkey.dev\",children:\"security@unkey.dev\"}),\" instead.\"]})]})}function l(r={}){let{wrapper:e}=r.components||{};return e?(0,n.jsx)(e,{...r,children:(0,n.jsx)(h,{...r})}):h(r)}return w(b);})();\n;return Component;",
    "slug": "vault",
    "url": "/blog/vault",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Introducing Vault",
        "slug": "introducing-vault"
      },
      {
        "level": 2,
        "text": "Recovering keys",
        "slug": "recovering-keys"
      },
      {
        "level": 2,
        "text": "Opt in",
        "slug": "opt-in"
      },
      {
        "level": 2,
        "text": "Documentation",
        "slug": "documentation"
      },
      {
        "level": 2,
        "text": "Support",
        "slug": "support"
      }
    ]
  },
  {
    "content": "## What is Unkey?\n\nUnkey provides a way for you to create, manage and revoke API Keys that belong to your API. It's a simple concept, but one that we think is important. We built Unkey to layer it into your API so that you can issue keys, manage them and revoke them as needed. This means we need a simple and great DX and fast response times.\n\n## Why did we build it?\n\nWe built Unkey because we were tired of copying and pasting the same API management into a new codebase. Similar to authentication, you can do it yourself, but having a dedicated company that is working on improvements, and worrying about security and latency means you can focus on the business and core features.\n\n## What are the current features?\n\nUnkey provides the following features out of the box:\n\n- An admin dashboard to manage your APIs, issue keys, revoke keys and see usage stats.\n\n- A simple API with SDKs for typescript\n\n- Short-lived keys\n\n- Rate limited keys\n\n- Metadata attached to keys\n\n## Deep dive into the features\n\n### Admin dashboard\n\nOur admin dashboard gives you access to several features in a simple-to-use interface. You can create new APIs, issue keys, revoke keys and see usage stats. You can also invite other users to your account so that they can manage your APIs.\n\n<Image src=\"/images/blog-images/admin-dashboard.png\" alt=\"Admin dashboard\" width=\"1920\" height=\"1080\"/>\n\n### Simple API with SDKs\n\nWe wanted the DX for Unkey to be as simple as possible. We've built a simple API that you can use to create, manage and revoke keys. We wanted to make sure the API was easy to integrate and didn't take engineering time away.\n\nNo API is great without SDKs so we built a typescript one and our community also built an Elixir and Python SDK.\n\n### Short-lived keys\n\nWhen we started Unkey we wanted the ability to issue a short-lived key but we didn't want to restrict the period. We understand that each use case is different so you can pass us an expiration or select it in the UI.\n\nOnce the key expires, we revoke the key and the user can no longer access your content. This is great for audit teams, trials, or payment systems that give you access for some time.\n\n### Rate limited keys\n\nRate limiting is essential to all businesses that have an API. Unkey gives you the ability to set each key to a different rate limit. We handle the rate limiting for you, it's as simple as telling us the total amount of burstable requests, the refill rate, and how quickly they should be refilled.\n\nOnce you have the key with the limits, with each request we return the amount the request limit, how many remaining, and the reset time. Once a user hits the rate limit we will return `json \"valid\": false` alongside a code `RATE_LIMITED` if the rate limit has been hit, so you know that this user shouldn't be able to access your endpoints.\n\n### Metadata attached to keys\n\nWe wanted to give you the ability to attach metadata to your keys so you can easily make business decisions based on the data instead of having to look up the key in your database. You can include anything that you want to read on the server, for example:\n\n```json\n{\n  \"billingTier\": \"PRO\",\n  \"trialEnds\": \"2023-06-16T17:16:37.161Z\"\n}\n```\n\nThis allows you to pull less data from other systems in your infrastructure to make business decisions faster.\n\n## Built with speed in mind\n\nUnkey was built to have minimal impact on your API, we have our database in the United States but replicate this into other regions so that we can serve your requests as fast as possible. We have our API distributed across the world so that requests will go to the closest region to your user, process at the closet database, and then return the response. Unkey also automatically caches the key on creation, so that the first request is as fast as the second or third request.\n\nOn average our requests add less than 40ms to your requests, below are some of the latest requests we are monitoring through [Planetfall](https://planetfall.io)\n\n![Unkey latency](/images/blog-images/unkey-latency.png)",
    "title": "Why we built Unkey",
    "description": "Why we built Unkey, the open source API management tool and what features we have.",
    "author": "james",
    "date": "2023-07-04",
    "tags": [
      "product",
      "engineering"
    ],
    "image": "/images/blog-images/covers/why-unkey.png",
    "_meta": {
      "filePath": "why-we-built-unkey.mdx",
      "fileName": "why-we-built-unkey.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "why-we-built-unkey"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var s=Object.defineProperty;var y=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var w=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),k=(n,e)=>{for(var a in e)s(n,a,{get:e[a],enumerable:!0})},r=(n,e,a,o)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let i of m(e))!g.call(n,i)&&i!==a&&s(n,i,{get:()=>e[i],enumerable:!(o=y(e,i))||o.enumerable});return n};var b=(n,e,a)=>(a=n!=null?u(p(n)):{},r(e||!n||!n.__esModule?s(a,\"default\",{value:n,enumerable:!0}):a,n)),f=n=>r(s({},\"__esModule\",{value:!0}),n);var d=w((P,h)=>{h.exports=_jsx_runtime});var I={};k(I,{default:()=>c});var t=b(d());function l(n){let e={a:\"a\",code:\"code\",h2:\"h2\",h3:\"h3\",img:\"img\",li:\"li\",p:\"p\",pre:\"pre\",ul:\"ul\",...n.components},{Image:a}=e;return a||v(\"Image\",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h2,{id:\"what-is-unkey\",children:\"What is Unkey?\"}),`\n`,(0,t.jsx)(e.p,{children:\"Unkey provides a way for you to create, manage and revoke API Keys that belong to your API. It's a simple concept, but one that we think is important. We built Unkey to layer it into your API so that you can issue keys, manage them and revoke them as needed. This means we need a simple and great DX and fast response times.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"why-did-we-build-it\",children:\"Why did we build it?\"}),`\n`,(0,t.jsx)(e.p,{children:\"We built Unkey because we were tired of copying and pasting the same API management into a new codebase. Similar to authentication, you can do it yourself, but having a dedicated company that is working on improvements, and worrying about security and latency means you can focus on the business and core features.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"what-are-the-current-features\",children:\"What are the current features?\"}),`\n`,(0,t.jsx)(e.p,{children:\"Unkey provides the following features out of the box:\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsxs)(e.li,{children:[`\n`,(0,t.jsx)(e.p,{children:\"An admin dashboard to manage your APIs, issue keys, revoke keys and see usage stats.\"}),`\n`]}),`\n`,(0,t.jsxs)(e.li,{children:[`\n`,(0,t.jsx)(e.p,{children:\"A simple API with SDKs for typescript\"}),`\n`]}),`\n`,(0,t.jsxs)(e.li,{children:[`\n`,(0,t.jsx)(e.p,{children:\"Short-lived keys\"}),`\n`]}),`\n`,(0,t.jsxs)(e.li,{children:[`\n`,(0,t.jsx)(e.p,{children:\"Rate limited keys\"}),`\n`]}),`\n`,(0,t.jsxs)(e.li,{children:[`\n`,(0,t.jsx)(e.p,{children:\"Metadata attached to keys\"}),`\n`]}),`\n`]}),`\n`,(0,t.jsx)(e.h2,{id:\"deep-dive-into-the-features\",children:\"Deep dive into the features\"}),`\n`,(0,t.jsx)(e.h3,{id:\"admin-dashboard\",children:\"Admin dashboard\"}),`\n`,(0,t.jsx)(e.p,{children:\"Our admin dashboard gives you access to several features in a simple-to-use interface. You can create new APIs, issue keys, revoke keys and see usage stats. You can also invite other users to your account so that they can manage your APIs.\"}),`\n`,(0,t.jsx)(a,{src:\"/images/blog-images/admin-dashboard.png\",alt:\"Admin dashboard\",width:\"1920\",height:\"1080\"}),`\n`,(0,t.jsx)(e.h3,{id:\"simple-api-with-sdks\",children:\"Simple API with SDKs\"}),`\n`,(0,t.jsx)(e.p,{children:\"We wanted the DX for Unkey to be as simple as possible. We've built a simple API that you can use to create, manage and revoke keys. We wanted to make sure the API was easy to integrate and didn't take engineering time away.\"}),`\n`,(0,t.jsx)(e.p,{children:\"No API is great without SDKs so we built a typescript one and our community also built an Elixir and Python SDK.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"short-lived-keys\",children:\"Short-lived keys\"}),`\n`,(0,t.jsx)(e.p,{children:\"When we started Unkey we wanted the ability to issue a short-lived key but we didn't want to restrict the period. We understand that each use case is different so you can pass us an expiration or select it in the UI.\"}),`\n`,(0,t.jsx)(e.p,{children:\"Once the key expires, we revoke the key and the user can no longer access your content. This is great for audit teams, trials, or payment systems that give you access for some time.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"rate-limited-keys\",children:\"Rate limited keys\"}),`\n`,(0,t.jsx)(e.p,{children:\"Rate limiting is essential to all businesses that have an API. Unkey gives you the ability to set each key to a different rate limit. We handle the rate limiting for you, it's as simple as telling us the total amount of burstable requests, the refill rate, and how quickly they should be refilled.\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Once you have the key with the limits, with each request we return the amount the request limit, how many remaining, and the reset time. Once a user hits the rate limit we will return \",(0,t.jsx)(e.code,{children:'json \"valid\": false'}),\" alongside a code \",(0,t.jsx)(e.code,{children:\"RATE_LIMITED\"}),\" if the rate limit has been hit, so you know that this user shouldn't be able to access your endpoints.\"]}),`\n`,(0,t.jsx)(e.h3,{id:\"metadata-attached-to-keys\",children:\"Metadata attached to keys\"}),`\n`,(0,t.jsx)(e.p,{children:\"We wanted to give you the ability to attach metadata to your keys so you can easily make business decisions based on the data instead of having to look up the key in your database. You can include anything that you want to read on the server, for example:\"}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-json\",children:`{\n  \"billingTier\": \"PRO\",\n  \"trialEnds\": \"2023-06-16T17:16:37.161Z\"\n}\n`})}),`\n`,(0,t.jsx)(e.p,{children:\"This allows you to pull less data from other systems in your infrastructure to make business decisions faster.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"built-with-speed-in-mind\",children:\"Built with speed in mind\"}),`\n`,(0,t.jsx)(e.p,{children:\"Unkey was built to have minimal impact on your API, we have our database in the United States but replicate this into other regions so that we can serve your requests as fast as possible. We have our API distributed across the world so that requests will go to the closest region to your user, process at the closet database, and then return the response. Unkey also automatically caches the key on creation, so that the first request is as fast as the second or third request.\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"On average our requests add less than 40ms to your requests, below are some of the latest requests we are monitoring through \",(0,t.jsx)(e.a,{href:\"https://planetfall.io\",children:\"Planetfall\"})]}),`\n`,(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{src:\"/images/blog-images/unkey-latency.png\",alt:\"Unkey latency\"})})]})}function c(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(l,{...n})}):l(n)}function v(n,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+n+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return f(I);})();\n;return Component;",
    "slug": "why-we-built-unkey",
    "url": "/blog/why-we-built-unkey",
    "tableOfContents": [
      {
        "level": 2,
        "text": "Why did we build it?",
        "slug": "why-did-we-build-it"
      },
      {
        "level": 2,
        "text": "What are the current features?",
        "slug": "what-are-the-current-features"
      },
      {
        "level": 2,
        "text": "Deep dive into the features",
        "slug": "deep-dive-into-the-features"
      },
      {
        "level": 3,
        "text": "Admin dashboard",
        "slug": "admin-dashboard"
      },
      {
        "level": 3,
        "text": "Simple API with SDKs",
        "slug": "simple-api-with-sdks"
      },
      {
        "level": 3,
        "text": "Short-lived keys",
        "slug": "short-lived-keys"
      },
      {
        "level": 3,
        "text": "Rate limited keys",
        "slug": "rate-limited-keys"
      },
      {
        "level": 3,
        "text": "Metadata attached to keys",
        "slug": "metadata-attached-to-keys"
      },
      {
        "level": 2,
        "text": "Built with speed in mind",
        "slug": "built-with-speed-in-mind"
      }
    ]
  },
  {
    "content": "When we started migrating our API services from TypeScript to Go, we were looking for an HTTP framework that would provide a clean developer experience, offer precise control over middleware execution, and integrate seamlessly with OpenAPI for our SDK generation. After evaluating the popular frameworks in the Go ecosystem, we found that none quite matched our specific requirements.\n\nSo, we did what engineers do: we built our own. Enter Zen, a lightweight HTTP framework built directly on top of Go's standard library.\n\n## The Pain Points with Existing Frameworks\n\nOur journey began with our TypeScript API using Hono, which offered a fantastic developer experience with [Zod validations](https://github.com/samchungy/zod-openapi) and first-class OpenAPI support. When migrating to Go, we faced several challenges with existing frameworks:\n\n### Complex Middleware Execution Order\n\nMost frameworks enforce a rigid middleware execution pattern that didn't allow for our specific needs. The critical limitation we encountered was the inability to capture post-error-handling response detailsa fundamental requirement not just for our internal monitoring but also for our customer-facing analytics dashboard.\n\n- We needed an error handling middleware that could parse returned errors and construct properly typed problem+json responses\n- OpenAPI validation needed to run before our handler code but after error handling, to return nice validation responses\n- Most importantly, we needed logging middleware that could run *after* error handling was complete, to capture the final HTTP status code and response body that was actually sent to the client\n\nThis last point is crucial for both debugging and customer visibility. We store these responses and make them available to our customers in our dashboard, allowing them to inspect exactly what their API clients received. When an error occurs, customers need to see the precise HTTP status code and response payload their systems encountered, not just that an error happened somewhere in the pipeline.\n\nWhile we could have potentially achieved this with existing frameworks, doing so would have required embedding error handling and response logging logic directly into every handler function. This would mean handlers couldn't simply return Go errorsthey would need to know how to translate those errors into HTTP responses and also handle logging those responses. This approach would:\n\n1. Duplicate error handling logic across every endpoint\n2. Make handlers responsible for concerns beyond their core business logic\n\nOur goal was to keep handlers simple, allowing them to focus on business logic and return domain errors without worrying about HTTP status codes, response formatting, or logging..\n\nBy building Zen, we could ensure handlers remained clean and focused while still providing our customers with complete visibility into their API requestsincluding the exact error responses their systems encountered.\n\n### Poor OpenAPI Integration\n\nWhile frameworks like [huma.rocks](https://huma.rocks) offered OpenAPI generation from Go code, we preferred a schema-first approach. This approach gives us complete control over the spec quality and annotations. With our SDKs generated via [Speakeasy](https://www.speakeasy.com/) from this spec, we need to set the bar high to let them deliver the best SDK possible.\n\n### Dependency Bloat\n\nMany frameworks pull in dozens of dependencies, which adds maintenance, potential security risks and the possibility of supply chain attacks. We wanted something minimal that relied primarily on Go's standard library.\n\n### Inflexible Error Handling\n\nGo's error model is simple, but translating errors into HTTP responses (especially [RFC 7807](https://datatracker.ietf.org/doc/html/rfc7807) problem+json ones) requires special handling. Existing frameworks made it surprisingly difficult to map our domain errors to appropriate HTTP responses.\n\n## The Zen Philosophy\n\nRather than forcing an existing framework to fit our needs, we decided to build Zen with three core principles in mind:\n\n1. **Simplicity**: Focus on core HTTP handling with minimal abstractions\n2. **Clarity**: Maintain Go's idioms and stay close to net/http's mental model\n3. **Efficiency**: No unnecessary dependencies, with low overhead\n\nPut simply, Zen is a thin wrapper around Go's standard library that makes common HTTP tasks more ergonomic while providing precise control over request handling.\n\n## The Core Components of Zen\n\nZen consists of four primary components, each serving a specific purpose in the request lifecycle:\n\n### Sessions\n\nThe `Session` type encapsulates the HTTP request and response context, providing utility methods for common operations:\n\n```go\nroute := zen.NewRoute(\"GET\", \"/v2/liveness\",\n\tfunc(ctx context.Context, s *zen.Session) error {\n\t\tres := Response{\n\t\t\tMessage: \"we're cooking\",\n\t\t}\n\t\treturn s.JSON(http.StatusOK, res)\n\t},\n)\n```\n\nSessions are pooled and reused between requests to reduce memory allocations and GC pressure, a common performance concern in high-throughput API servers.\n\n### Routes\n\nThe `Route` interface represents an HTTP endpoint with its method, path, and handler function. Routes can be decorated with middleware chains:\n\n\n```go\nfunc main(){\n\t// ...\n\n\t// Create a route\n\troute := zen.NewRoute(\"POST\", \"/v2/ratelimit.limit\", handler)\n\n\t// Register with middleware\n\tserver.RegisterRoute(\n\t    []zen.Middleware{\n\t      zen.WithTracing(),\n\t      zen.WithMetrics(eventBuffer),\n\t      zen.WithLogging(logger),\n\t      zen.WithErrorHandling(logger),\n\t      zen.WithValidation(validator),\n\t    },\n\t    route,\n\t)\n}\n```\n### Middleware\n\nAt the core of Zen, middleware is just a function:\n\n```go\ntype Middleware func(handler HandleFunc) HandleFunc\n```\nBut this simple definition makes it so powerful. Each middleware gets a handler and returns a wrapped handler - that's it. No complex interfaces or lifecycle hooks to learn.\n\nWhat's special about this approach is that it lets us control exactly when each piece of middleware runs. For example, our logging middleware captures the final status code and response body:\n\n```go\nfunc WithLogging(logger logging.Logger) Middleware {\n    return func(next HandleFunc) HandleFunc {\n        return func(ctx context.Context, s *Session) error {\n            start := time.Now()\n\n            // Call the next handler in the chain\n            err := next(ctx, s)\n\n            // Log after handling is complete\n            logger.InfoContext(ctx, \"request\",\n                slog.String(\"method\", s.r.Method),\n                slog.String(\"path\", s.r.URL.Path),\n                slog.Int(\"status\", s.responseStatus), // Captured from response\n                slog.String(\"latency\", time.Since(start).String()),\n            )\n\n            return err\n        }\n    }\n}\n```\n\nTo understand our error handling middleware, it's important to first know how we tag errors in our application. We use a custom `fault` package that enables adding metadata to errors, including tags that categorize the error type and separate internal details from user-facing messages.\n\nIn our handlers or services, we can return tagged errors like this:\n\n```go\n// When a database query returns no results\nif errors.Is(err, sql.ErrNoRows) {\n    return fault.Wrap(err,\n        fault.WithTag(fault.NOT_FOUND),\n        fault.WithDesc(\n            fmt.Sprintf(\"namespace '%s' not found in database\", namespaceName),  // Internal details for logs\n            \"This namespace does not exist\"                                      // User-facing message\n        )\n    )\n}\n\n// When handling permission checks\nif !permissions.Valid {\n    return fault.New(\"insufficient permissions\",\n        \tfault.WithCode(codes.Auth.Authorization.InsufficientPermissions.URN()),\n        fault.WithDesc(\n            fmt.Sprintf(\"key '%s' lacks permission on resource '%s'\", auth.KeyID, namespace.ID),\n            permissions.Message  // User-friendly message from the permission system\n        )\n    )\n}\n```\n\nThe `WithDesc` function is crucial here - it maintains two separate messages:\n1. An internal message with technical details for logging and debugging\n2. A user-facing message that's safe to expose in API responses\n\nThis separation lets us provide detailed context for troubleshooting while ensuring we never leak sensitive implementation details to users.\n\nOur error handling middleware then examines these tags to determine the appropriate HTTP response:\n\n```go\nfunc WithErrorHandling(logger logging.Logger) Middleware {\n    return func(next HandleFunc) HandleFunc {\n        return func(ctx context.Context, s *Session) error {\n            err := next(ctx, s)\n            if err == nil {\n                return nil\n            }\n\n            // Convert domain errors to HTTP responses\n            switch fault.GetTag(err) {\n            case fault.NOT_FOUND:\n                return s.JSON(http.StatusNotFound, api.NotFoundError{\n                    Title:     \"Not Found\",\n                    Type:      \"https://unkey.com/docs/errors/not_found\",\n                    Detail:    fault.UserFacingMessage(err),\n                    RequestId: s.requestID,\n                    Status:    http.StatusNotFound,\n                    Instance:  nil,\n                })\n            case fault.BAD_REQUEST:\n                return s.JSON(http.StatusBadRequest, api.BadRequestError{\n                    Title:     \"Bad Request\",\n                    Type:      \"https://unkey.com/docs/api-reference/errors-v2/unkey/application/invalid_input\",\n                    Detail:    fault.UserFacingMessage(err),\n                    RequestId: s.requestID,\n                    Status:    http.StatusBadRequest,\n                    Instance:  nil,\n                    Errors:    []api.ValidationError{...},\n                })\n            // Additional cases...\n            }\n\n            // Default to 500 Internal Server Error\n            return s.JSON(http.StatusInternalServerError, api.InternalServerError{\n                Title:     \"Internal Server Error\",\n                Type:      \"https://unkey.com/docs/errors/internal_server_error\",\n                Detail:    fault.UserFacingMessage(err),\n                RequestId: s.requestID,\n                Status:    http.StatusInternalServerError,\n                Instance:  nil,\n            })\n        }\n    }\n}\n```\n\n### Server\n\nThe `Server` type manages HTTP server configuration, lifecycle, and route registration:\n\n```go\n// Initialize a server\nserver, err := zen.New(zen.Config{\n    Logger: logger,\n    // ...\n})\nif err != nil {\n    log.Fatalf(\"failed to create server: %v\", err)\n}\n\n// Register routes\nserver.RegisterRoute([]zen.Middleware{...}, route)\n\n// Start the server\nerr = server.Listen(ctx, \":8080\")\n```\n\nThe server handles graceful shutdown, goroutine management, and session pooling automatically.\n\n## OpenAPI Integration the Right Way\n\nUnlike frameworks that generate OpenAPI specs from code, we take a schema-first approach. Our OpenAPI spec is hand-crafted for precision and then used to generate Go types and validation logic:\n\n```go\n// OpenAPI validation middleware\nfunc WithValidation(validator *validation.Validator) Middleware {\n    return func(next HandleFunc) HandleFunc {\n        return func(ctx context.Context, s *Session) error {\n            err, valid := validator.Validate(s.r)\n            if !valid {\n                err.RequestId = s.requestID\n                return s.JSON(err.Status, err)\n            }\n            return next(ctx, s)\n        }\n    }\n}\n```\n\nOur validation package uses [`pb33f/libopenapi-validator`](https://github.com/pb33f/libopenapi-validator) which provides structural and semantic validation based on our OpenAPI spec. In an ideal world we wouldn't use a dependency for this, but it's way too much and too error prone to implement ourselves at this stage.\n\n## The Benefits of Building Zen\n\nCreating Zen has provided us with several key advantages:\n\n### Complete Middleware Control\n\nWe now have granular control over middleware execution, allowing us to capture metrics, logs, and errors exactly as needed. The middleware is simple to understand and compose, making it easy to add new functionality or modify existing behavior.\n\n### Schema-First API Design\n\nBy taking a schema-first approach to OpenAPI, we maintain full control over our API contract while still getting Go type safety through generated types. This ensures consistency across our SDKs and reduces the likelihood of API-breaking changes.\n\n### Minimal Dependencies\n\nZen relies almost entirely on the standard library, with only a few external dependencies for OpenAPI validation. This reduces our dependency footprint and makes the codebase easier to understand and maintain.\n\n### Idiomatic Go\n\nZen follows Go conventions and idioms, making it feel natural to Go developers. Handler functions receive a context as the first parameter and return an error, following common Go patterns.\n\n### Type Safety with Ergonomics\n\nThe Session methods for binding request bodies and query parameters into Go structs provide type safety without boilerplate. The error handling middleware gives structured, consistent error responses.\n\n## Real-World Example: Rate Limiting API\n\nHere's a complete handler from our rate-limiting API that shows how all these components work together:\n\n```go\npackage handler\n\nimport (...)\n\n// Reexporting to reuse in tests\ntype Request = spec.V2RatelimitSetOverrideRequestBody\ntype Response = spec.V2RatelimitSetOverrideResponseBody\n\n\n// Define the dependencies for this route. These are injected during route registration\ntype Services struct {\n\tLogger      logging.Logger\n\tDB          db.Database\n\tKeys        keys.KeyService\n\tPermissions permissions.PermissionService\n}\n\nfunc New(svc Services) zen.Route {\n\treturn zen.NewRoute(\"POST\", \"/v2/ratelimit.setOverride\", func(ctx context.Context, s *zen.Session) error {\n\n\t\tauth, err := svc.Keys.VerifyRootKey(ctx, s)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treq := Request{}\n\t\terr = s.BindBody(&req)\n\t\tif err != nil {\n\t\t\treturn err // already tagged\n\t\t}\n\n\t\tnamespace, err := getNamespace(ctx, svc, auth.AuthorizedWorkspaceID, req)\n\t\tif err != nil {\n\t\t\tif errors.Is(err, sql.ErrNoRows) {\n\t\t\t\treturn fault.Wrap(err,\n\t\t\t\t\tfault.WithTag(fault.NOT_FOUND),\n\t\t\t\t\tfault.WithDesc(\"namespace not found\", \"This namespace does not exist.\"),\n\t\t\t\t)\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\n\t\tif namespace.WorkspaceID != auth.AuthorizedWorkspaceID {\n\t\t\treturn fault.New(\"namespace not found\",\n\t\t\t\tfault.WithTag(fault.NOT_FOUND),\n\t\t\t\tfault.WithDesc(\"wrong workspace, masking as 404\", \"This namespace does not exist.\"),\n\t\t\t)\n\t\t}\n\n\t\tpermissions, err := svc.Permissions.Check(\n\t\t\tctx,\n\t\t\tauth.KeyID,\n\t\t\trbac.Or(\n\t\t\t\trbac.T(rbac.Tuple{\n\t\t\t\t\tResourceType: rbac.Ratelimit,\n\t\t\t\t\tResourceID:   namespace.ID,\n\t\t\t\t\tAction:       rbac.SetOverride,\n\t\t\t\t}),\n\t\t\t\trbac.T(rbac.Tuple{\n\t\t\t\t\tResourceType: rbac.Ratelimit,\n\t\t\t\t\tResourceID:   \"*\",\n\t\t\t\t\tAction:       rbac.SetOverride,\n\t\t\t\t}),\n\t\t\t),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn fault.Wrap(err,\n\t\t\t\tfault.WithTag(fault.INTERNAL_SERVER_ERROR),\n\t\t\t\tfault.WithDesc(\"unable to check permissions\", \"We're unable to check the permissions of your key.\"),\n\t\t\t)\n\t\t}\n\n\t\tif !permissions.Valid {\n\t\t\treturn fault.New(\"insufficient permissions\",\n\t\t\t\t\tfault.WithCode(codes.Auth.Authorization.InsufficientPermissions.URN()),\n\t\t\t\tfault.WithDesc(permissions.Message, permissions.Message),\n\t\t\t)\n\t\t}\n\n\t\toverrideID := uid.New(uid.RatelimitOverridePrefix)\n\t\terr = db.Query.InsertRatelimitOverride(ctx, svc.DB.RW(), db.InsertRatelimitOverrideParams{\n\t\t\tID:          overrideID,\n\t\t\tWorkspaceID: auth.AuthorizedWorkspaceID,\n\t\t\tNamespaceID: namespace.ID,\n\t\t\tIdentifier:  req.Identifier,\n\t\t\tLimit:       int32(req.Limit),    // nolint:gosec\n\t\t\tDuration:    int32(req.Duration), //nolint:gosec\n\t\t\tCreatedAt:   time.Now().UnixMilli(),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn fault.Wrap(err,\n\t\t\t\tfault.WithTag(fault.DATABASE_ERROR),\n\t\t\t\tfault.WithDesc(\"database failed\", \"The database is unavailable.\"),\n\t\t\t)\n\t\t}\n\n\t\treturn s.JSON(http.StatusOK, Response{\n\t\t\tOverrideId: overrideID,\n\t\t})\n\t})\n}\n\nfunc getNamespace(ctx context.Context, svc Services, workspaceID string, req Request) (db.RatelimitNamespace, error) {\n\n\tswitch {\n\tcase req.NamespaceId != nil:\n\t\t{\n\t\t\treturn db.Query.FindRatelimitNamespaceByID(ctx, svc.DB.RO(), *req.NamespaceId)\n\t\t}\n\tcase req.NamespaceName != nil:\n\t\t{\n\t\t\treturn db.Query.FindRatelimitNamespaceByName(ctx, svc.DB.RO(), db.FindRatelimitNamespaceByNameParams{\n\t\t\t\tWorkspaceID: workspaceID,\n\t\t\t\tName:        *req.NamespaceName,\n\t\t\t})\n\t\t}\n\t}\n\n\treturn db.RatelimitNamespace{}, fault.New(\"missing namespace id or name\",\n\t\tfault.WithTag(fault.BAD_REQUEST),\n\t\tfault.WithDesc(\"missing namespace id or name\", \"You must provide either a namespace ID or name.\"),\n\t)\n\n}\n\n```\n\nThe handler is just a function that returns an error, making it easy to test and reason about. All the HTTP-specific logic (authentication, validation, error handling, response formatting) is handled by middleware or injected services.\n\n## Testing Made Easy\n\nZen's simple design makes testing very easy, even our CEO loves it. Because routes are just functions that accept a context and session and return an error, they're easy to unit test:\n\n```go\npackage handler_test\n\nimport (...)\n\nfunc TestRatelimitEndpoint(t *testing.T) {\n    h := testutil.NewHarness(t)\n\n    route := handler.New(handler.Services{\n        DB:          h.DB,\n        Keys:        h.Keys,\n        Logger:      h.Logger,\n        Permissions: h.Permissions,\n    })\n\n    h.Register(route)\n\n    rootKey := h.CreateRootKey(h.Resources.UserWorkspace.ID)\n\n    headers := http.Header{\n        \"Content-Type\":  {\"application/json\"},\n        \"Authorization\": {fmt.Sprintf(\"Bearer %s\", rootKey)},\n    }\n\n    req := handler.Request{\n        Namespace:  \"test_namespace\",\n        Identifier: \"user_123\",\n        Limit:      100,\n        Duration:   60000,\n    }\n\n    res := testutil.CallRoute[handler.Request, handler.Response](h, route, headers, req)\n    require.Equal(t, 200, res.Status)\n    require.NotNil(t, res.Body)\n    require.True(t, res.Body.Success)\n    require.Equal(t, int64(100), res.Body.Limit)\n    require.Equal(t, int64(99), res.Body.Remaining)\n}\n```\n\nWe've built test utilities that make it easy to set up a test harness with database dependencies, register routes, and call them with typed requests and responses.\n\n## Zen is Open Source\n\nZen lives in our open source mono repo, so you can explore or even use it in your own projects. The full source code is available in our GitHub repository at [github.com/unkeyed/unkey/tree/main/go/pkg/zen](https://github.com/unkeyed/unkey/tree/main/go/pkg/zen).\n\nWhile we built Zen specifically for our needs, we recognize that other teams might face similar challenges with Go HTTP frameworks. You're welcome to:\n- Read through the implementation to understand our approach\n- Fork the code and adapt it to your own requirements\n- Use it directly in your projects if it fits your needs\n\n## Conclusion\n\nWhile the Go ecosystem offers many excellent HTTP frameworks, sometimes the best solution is a custom one tailored to your specific needs. A thin layer on top of Go's standard library can provide significant ergonomic benefits without sacrificing control or performance.\n\n\nAs our API continues to grow, the simplicity and extensibility of Zen will allow us to add new features and functionality without compromising on performance or developer experience. The best abstractions are those that solve real problems without introducing new ones, and by starting with Go's solid foundation and carefully adding only what we needed, we've created a framework that enables our team to build with confidence.",
    "title": "Zen",
    "description": "A Minimalist HTTP Library for Go",
    "author": "andreas",
    "date": "2025-03-13",
    "tags": [
      "engineering"
    ],
    "image": "/images/blog-images/covers/zen.png",
    "_meta": {
      "filePath": "zen.mdx",
      "fileName": "zen.mdx",
      "directory": ".",
      "extension": "mdx",
      "path": "zen"
    },
    "mdx": "var Component=(()=>{var u=Object.create;var a=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var w=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),y=(t,e)=>{for(var r in e)a(t,r,{get:e[r],enumerable:!0})},o=(t,e,r,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let i of m(e))!f.call(t,i)&&i!==r&&a(t,i,{get:()=>e[i],enumerable:!(s=p(e,i))||s.enumerable});return t};var v=(t,e,r)=>(r=t!=null?u(g(t)):{},o(e||!t||!t.__esModule?a(r,\"default\",{value:t,enumerable:!0}):r,t)),b=t=>o(a({},\"__esModule\",{value:!0}),t);var d=w((I,l)=>{l.exports=_jsx_runtime});var T={};y(T,{default:()=>h});var n=v(d());function c(t){let e={a:\"a\",code:\"code\",em:\"em\",h2:\"h2\",h3:\"h3\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",strong:\"strong\",ul:\"ul\",...t.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"When we started migrating our API services from TypeScript to Go, we were looking for an HTTP framework that would provide a clean developer experience, offer precise control over middleware execution, and integrate seamlessly with OpenAPI for our SDK generation. After evaluating the popular frameworks in the Go ecosystem, we found that none quite matched our specific requirements.\"}),`\n`,(0,n.jsx)(e.p,{children:\"So, we did what engineers do: we built our own. Enter Zen, a lightweight HTTP framework built directly on top of Go's standard library.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"the-pain-points-with-existing-frameworks\",children:\"The Pain Points with Existing Frameworks\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Our journey began with our TypeScript API using Hono, which offered a fantastic developer experience with \",(0,n.jsx)(e.a,{href:\"https://github.com/samchungy/zod-openapi\",children:\"Zod validations\"}),\" and first-class OpenAPI support. When migrating to Go, we faced several challenges with existing frameworks:\"]}),`\n`,(0,n.jsx)(e.h3,{id:\"complex-middleware-execution-order\",children:\"Complex Middleware Execution Order\"}),`\n`,(0,n.jsx)(e.p,{children:\"Most frameworks enforce a rigid middleware execution pattern that didn't allow for our specific needs. The critical limitation we encountered was the inability to capture post-error-handling response details\\u2014a fundamental requirement not just for our internal monitoring but also for our customer-facing analytics dashboard.\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"We needed an error handling middleware that could parse returned errors and construct properly typed problem+json responses\"}),`\n`,(0,n.jsx)(e.li,{children:\"OpenAPI validation needed to run before our handler code but after error handling, to return nice validation responses\"}),`\n`,(0,n.jsxs)(e.li,{children:[\"Most importantly, we needed logging middleware that could run \",(0,n.jsx)(e.em,{children:\"after\"}),\" error handling was complete, to capture the final HTTP status code and response body that was actually sent to the client\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"This last point is crucial for both debugging and customer visibility. We store these responses and make them available to our customers in our dashboard, allowing them to inspect exactly what their API clients received. When an error occurs, customers need to see the precise HTTP status code and response payload their systems encountered, not just that an error happened somewhere in the pipeline.\"}),`\n`,(0,n.jsx)(e.p,{children:\"While we could have potentially achieved this with existing frameworks, doing so would have required embedding error handling and response logging logic directly into every handler function. This would mean handlers couldn't simply return Go errors\\u2014they would need to know how to translate those errors into HTTP responses and also handle logging those responses. This approach would:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Duplicate error handling logic across every endpoint\"}),`\n`,(0,n.jsx)(e.li,{children:\"Make handlers responsible for concerns beyond their core business logic\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Our goal was to keep handlers simple, allowing them to focus on business logic and return domain errors without worrying about HTTP status codes, response formatting, or logging..\"}),`\n`,(0,n.jsx)(e.p,{children:\"By building Zen, we could ensure handlers remained clean and focused while still providing our customers with complete visibility into their API requests\\u2014including the exact error responses their systems encountered.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"poor-openapi-integration\",children:\"Poor OpenAPI Integration\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"While frameworks like \",(0,n.jsx)(e.a,{href:\"https://huma.rocks\",children:\"huma.rocks\"}),\" offered OpenAPI generation from Go code, we preferred a schema-first approach. This approach gives us complete control over the spec quality and annotations. With our SDKs generated via \",(0,n.jsx)(e.a,{href:\"https://www.speakeasy.com/\",children:\"Speakeasy\"}),\" from this spec, we need to set the bar high to let them deliver the best SDK possible.\"]}),`\n`,(0,n.jsx)(e.h3,{id:\"dependency-bloat\",children:\"Dependency Bloat\"}),`\n`,(0,n.jsx)(e.p,{children:\"Many frameworks pull in dozens of dependencies, which adds maintenance, potential security risks and the possibility of supply chain attacks. We wanted something minimal that relied primarily on Go's standard library.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"inflexible-error-handling\",children:\"Inflexible Error Handling\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Go's error model is simple, but translating errors into HTTP responses (especially \",(0,n.jsx)(e.a,{href:\"https://datatracker.ietf.org/doc/html/rfc7807\",children:\"RFC 7807\"}),\" problem+json ones) requires special handling. Existing frameworks made it surprisingly difficult to map our domain errors to appropriate HTTP responses.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"the-zen-philosophy\",children:\"The Zen Philosophy\"}),`\n`,(0,n.jsx)(e.p,{children:\"Rather than forcing an existing framework to fit our needs, we decided to build Zen with three core principles in mind:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Simplicity\"}),\": Focus on core HTTP handling with minimal abstractions\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Clarity\"}),\": Maintain Go's idioms and stay close to net/http's mental model\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Efficiency\"}),\": No unnecessary dependencies, with low overhead\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Put simply, Zen is a thin wrapper around Go's standard library that makes common HTTP tasks more ergonomic while providing precise control over request handling.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"the-core-components-of-zen\",children:\"The Core Components of Zen\"}),`\n`,(0,n.jsx)(e.p,{children:\"Zen consists of four primary components, each serving a specific purpose in the request lifecycle:\"}),`\n`,(0,n.jsx)(e.h3,{id:\"sessions\",children:\"Sessions\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The \",(0,n.jsx)(e.code,{children:\"Session\"}),\" type encapsulates the HTTP request and response context, providing utility methods for common operations:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-go\",children:`route := zen.NewRoute(\"GET\", \"/v2/liveness\",\n\tfunc(ctx context.Context, s *zen.Session) error {\n\t\tres := Response{\n\t\t\tMessage: \"we're cooking\",\n\t\t}\n\t\treturn s.JSON(http.StatusOK, res)\n\t},\n)\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Sessions are pooled and reused between requests to reduce memory allocations and GC pressure, a common performance concern in high-throughput API servers.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"routes\",children:\"Routes\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The \",(0,n.jsx)(e.code,{children:\"Route\"}),\" interface represents an HTTP endpoint with its method, path, and handler function. Routes can be decorated with middleware chains:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-go\",children:`func main(){\n\t// ...\n\n\t// Create a route\n\troute := zen.NewRoute(\"POST\", \"/v2/ratelimit.limit\", handler)\n\n\t// Register with middleware\n\tserver.RegisterRoute(\n\t    []zen.Middleware{\n\t      zen.WithTracing(),\n\t      zen.WithMetrics(eventBuffer),\n\t      zen.WithLogging(logger),\n\t      zen.WithErrorHandling(logger),\n\t      zen.WithValidation(validator),\n\t    },\n\t    route,\n\t)\n}\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"middleware\",children:\"Middleware\"}),`\n`,(0,n.jsx)(e.p,{children:\"At the core of Zen, middleware is just a function:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-go\",children:`type Middleware func(handler HandleFunc) HandleFunc\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"But this simple definition makes it so powerful. Each middleware gets a handler and returns a wrapped handler - that's it. No complex interfaces or lifecycle hooks to learn.\"}),`\n`,(0,n.jsx)(e.p,{children:\"What's special about this approach is that it lets us control exactly when each piece of middleware runs. For example, our logging middleware captures the final status code and response body:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-go\",children:`func WithLogging(logger logging.Logger) Middleware {\n    return func(next HandleFunc) HandleFunc {\n        return func(ctx context.Context, s *Session) error {\n            start := time.Now()\n\n            // Call the next handler in the chain\n            err := next(ctx, s)\n\n            // Log after handling is complete\n            logger.InfoContext(ctx, \"request\",\n                slog.String(\"method\", s.r.Method),\n                slog.String(\"path\", s.r.URL.Path),\n                slog.Int(\"status\", s.responseStatus), // Captured from response\n                slog.String(\"latency\", time.Since(start).String()),\n            )\n\n            return err\n        }\n    }\n}\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"To understand our error handling middleware, it's important to first know how we tag errors in our application. We use a custom \",(0,n.jsx)(e.code,{children:\"fault\"}),\" package that enables adding metadata to errors, including tags that categorize the error type and separate internal details from user-facing messages.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"In our handlers or services, we can return tagged errors like this:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-go\",children:`// When a database query returns no results\nif errors.Is(err, sql.ErrNoRows) {\n    return fault.Wrap(err,\n        fault.WithTag(fault.NOT_FOUND),\n        fault.WithDesc(\n            fmt.Sprintf(\"namespace '%s' not found in database\", namespaceName),  // Internal details for logs\n            \"This namespace does not exist\"                                      // User-facing message\n        )\n    )\n}\n\n// When handling permission checks\nif !permissions.Valid {\n    return fault.New(\"insufficient permissions\",\n        \tfault.WithCode(codes.Auth.Authorization.InsufficientPermissions.URN()),\n        fault.WithDesc(\n            fmt.Sprintf(\"key '%s' lacks permission on resource '%s'\", auth.KeyID, namespace.ID),\n            permissions.Message  // User-friendly message from the permission system\n        )\n    )\n}\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"The \",(0,n.jsx)(e.code,{children:\"WithDesc\"}),\" function is crucial here - it maintains two separate messages:\"]}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:\"An internal message with technical details for logging and debugging\"}),`\n`,(0,n.jsx)(e.li,{children:\"A user-facing message that's safe to expose in API responses\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"This separation lets us provide detailed context for troubleshooting while ensuring we never leak sensitive implementation details to users.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Our error handling middleware then examines these tags to determine the appropriate HTTP response:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-go\",children:`func WithErrorHandling(logger logging.Logger) Middleware {\n    return func(next HandleFunc) HandleFunc {\n        return func(ctx context.Context, s *Session) error {\n            err := next(ctx, s)\n            if err == nil {\n                return nil\n            }\n\n            // Convert domain errors to HTTP responses\n            switch fault.GetTag(err) {\n            case fault.NOT_FOUND:\n                return s.JSON(http.StatusNotFound, api.NotFoundError{\n                    Title:     \"Not Found\",\n                    Type:      \"https://unkey.com/docs/errors/not_found\",\n                    Detail:    fault.UserFacingMessage(err),\n                    RequestId: s.requestID,\n                    Status:    http.StatusNotFound,\n                    Instance:  nil,\n                })\n            case fault.BAD_REQUEST:\n                return s.JSON(http.StatusBadRequest, api.BadRequestError{\n                    Title:     \"Bad Request\",\n                    Type:      \"https://unkey.com/docs/api-reference/errors-v2/unkey/application/invalid_input\",\n                    Detail:    fault.UserFacingMessage(err),\n                    RequestId: s.requestID,\n                    Status:    http.StatusBadRequest,\n                    Instance:  nil,\n                    Errors:    []api.ValidationError{...},\n                })\n            // Additional cases...\n            }\n\n            // Default to 500 Internal Server Error\n            return s.JSON(http.StatusInternalServerError, api.InternalServerError{\n                Title:     \"Internal Server Error\",\n                Type:      \"https://unkey.com/docs/errors/internal_server_error\",\n                Detail:    fault.UserFacingMessage(err),\n                RequestId: s.requestID,\n                Status:    http.StatusInternalServerError,\n                Instance:  nil,\n            })\n        }\n    }\n}\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"server\",children:\"Server\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The \",(0,n.jsx)(e.code,{children:\"Server\"}),\" type manages HTTP server configuration, lifecycle, and route registration:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-go\",children:`// Initialize a server\nserver, err := zen.New(zen.Config{\n    Logger: logger,\n    // ...\n})\nif err != nil {\n    log.Fatalf(\"failed to create server: %v\", err)\n}\n\n// Register routes\nserver.RegisterRoute([]zen.Middleware{...}, route)\n\n// Start the server\nerr = server.Listen(ctx, \":8080\")\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"The server handles graceful shutdown, goroutine management, and session pooling automatically.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"openapi-integration-the-right-way\",children:\"OpenAPI Integration the Right Way\"}),`\n`,(0,n.jsx)(e.p,{children:\"Unlike frameworks that generate OpenAPI specs from code, we take a schema-first approach. Our OpenAPI spec is hand-crafted for precision and then used to generate Go types and validation logic:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-go\",children:`// OpenAPI validation middleware\nfunc WithValidation(validator *validation.Validator) Middleware {\n    return func(next HandleFunc) HandleFunc {\n        return func(ctx context.Context, s *Session) error {\n            err, valid := validator.Validate(s.r)\n            if !valid {\n                err.RequestId = s.requestID\n                return s.JSON(err.Status, err)\n            }\n            return next(ctx, s)\n        }\n    }\n}\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Our validation package uses \",(0,n.jsx)(e.a,{href:\"https://github.com/pb33f/libopenapi-validator\",children:(0,n.jsx)(e.code,{children:\"pb33f/libopenapi-validator\"})}),\" which provides structural and semantic validation based on our OpenAPI spec. In an ideal world we wouldn't use a dependency for this, but it's way too much and too error prone to implement ourselves at this stage.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"the-benefits-of-building-zen\",children:\"The Benefits of Building Zen\"}),`\n`,(0,n.jsx)(e.p,{children:\"Creating Zen has provided us with several key advantages:\"}),`\n`,(0,n.jsx)(e.h3,{id:\"complete-middleware-control\",children:\"Complete Middleware Control\"}),`\n`,(0,n.jsx)(e.p,{children:\"We now have granular control over middleware execution, allowing us to capture metrics, logs, and errors exactly as needed. The middleware is simple to understand and compose, making it easy to add new functionality or modify existing behavior.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"schema-first-api-design\",children:\"Schema-First API Design\"}),`\n`,(0,n.jsx)(e.p,{children:\"By taking a schema-first approach to OpenAPI, we maintain full control over our API contract while still getting Go type safety through generated types. This ensures consistency across our SDKs and reduces the likelihood of API-breaking changes.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"minimal-dependencies\",children:\"Minimal Dependencies\"}),`\n`,(0,n.jsx)(e.p,{children:\"Zen relies almost entirely on the standard library, with only a few external dependencies for OpenAPI validation. This reduces our dependency footprint and makes the codebase easier to understand and maintain.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"idiomatic-go\",children:\"Idiomatic Go\"}),`\n`,(0,n.jsx)(e.p,{children:\"Zen follows Go conventions and idioms, making it feel natural to Go developers. Handler functions receive a context as the first parameter and return an error, following common Go patterns.\"}),`\n`,(0,n.jsx)(e.h3,{id:\"type-safety-with-ergonomics\",children:\"Type Safety with Ergonomics\"}),`\n`,(0,n.jsx)(e.p,{children:\"The Session methods for binding request bodies and query parameters into Go structs provide type safety without boilerplate. The error handling middleware gives structured, consistent error responses.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"real-world-example-rate-limiting-api\",children:\"Real-World Example: Rate Limiting API\"}),`\n`,(0,n.jsx)(e.p,{children:\"Here's a complete handler from our rate-limiting API that shows how all these components work together:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-go\",children:`package handler\n\nimport (...)\n\n// Reexporting to reuse in tests\ntype Request = spec.V2RatelimitSetOverrideRequestBody\ntype Response = spec.V2RatelimitSetOverrideResponseBody\n\n\n// Define the dependencies for this route. These are injected during route registration\ntype Services struct {\n\tLogger      logging.Logger\n\tDB          db.Database\n\tKeys        keys.KeyService\n\tPermissions permissions.PermissionService\n}\n\nfunc New(svc Services) zen.Route {\n\treturn zen.NewRoute(\"POST\", \"/v2/ratelimit.setOverride\", func(ctx context.Context, s *zen.Session) error {\n\n\t\tauth, err := svc.Keys.VerifyRootKey(ctx, s)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treq := Request{}\n\t\terr = s.BindBody(&req)\n\t\tif err != nil {\n\t\t\treturn err // already tagged\n\t\t}\n\n\t\tnamespace, err := getNamespace(ctx, svc, auth.AuthorizedWorkspaceID, req)\n\t\tif err != nil {\n\t\t\tif errors.Is(err, sql.ErrNoRows) {\n\t\t\t\treturn fault.Wrap(err,\n\t\t\t\t\tfault.WithTag(fault.NOT_FOUND),\n\t\t\t\t\tfault.WithDesc(\"namespace not found\", \"This namespace does not exist.\"),\n\t\t\t\t)\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\n\t\tif namespace.WorkspaceID != auth.AuthorizedWorkspaceID {\n\t\t\treturn fault.New(\"namespace not found\",\n\t\t\t\tfault.WithTag(fault.NOT_FOUND),\n\t\t\t\tfault.WithDesc(\"wrong workspace, masking as 404\", \"This namespace does not exist.\"),\n\t\t\t)\n\t\t}\n\n\t\tpermissions, err := svc.Permissions.Check(\n\t\t\tctx,\n\t\t\tauth.KeyID,\n\t\t\trbac.Or(\n\t\t\t\trbac.T(rbac.Tuple{\n\t\t\t\t\tResourceType: rbac.Ratelimit,\n\t\t\t\t\tResourceID:   namespace.ID,\n\t\t\t\t\tAction:       rbac.SetOverride,\n\t\t\t\t}),\n\t\t\t\trbac.T(rbac.Tuple{\n\t\t\t\t\tResourceType: rbac.Ratelimit,\n\t\t\t\t\tResourceID:   \"*\",\n\t\t\t\t\tAction:       rbac.SetOverride,\n\t\t\t\t}),\n\t\t\t),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn fault.Wrap(err,\n\t\t\t\tfault.WithTag(fault.INTERNAL_SERVER_ERROR),\n\t\t\t\tfault.WithDesc(\"unable to check permissions\", \"We're unable to check the permissions of your key.\"),\n\t\t\t)\n\t\t}\n\n\t\tif !permissions.Valid {\n\t\t\treturn fault.New(\"insufficient permissions\",\n\t\t\t\t\tfault.WithCode(codes.Auth.Authorization.InsufficientPermissions.URN()),\n\t\t\t\tfault.WithDesc(permissions.Message, permissions.Message),\n\t\t\t)\n\t\t}\n\n\t\toverrideID := uid.New(uid.RatelimitOverridePrefix)\n\t\terr = db.Query.InsertRatelimitOverride(ctx, svc.DB.RW(), db.InsertRatelimitOverrideParams{\n\t\t\tID:          overrideID,\n\t\t\tWorkspaceID: auth.AuthorizedWorkspaceID,\n\t\t\tNamespaceID: namespace.ID,\n\t\t\tIdentifier:  req.Identifier,\n\t\t\tLimit:       int32(req.Limit),    // nolint:gosec\n\t\t\tDuration:    int32(req.Duration), //nolint:gosec\n\t\t\tCreatedAt:   time.Now().UnixMilli(),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn fault.Wrap(err,\n\t\t\t\tfault.WithTag(fault.DATABASE_ERROR),\n\t\t\t\tfault.WithDesc(\"database failed\", \"The database is unavailable.\"),\n\t\t\t)\n\t\t}\n\n\t\treturn s.JSON(http.StatusOK, Response{\n\t\t\tOverrideId: overrideID,\n\t\t})\n\t})\n}\n\nfunc getNamespace(ctx context.Context, svc Services, workspaceID string, req Request) (db.RatelimitNamespace, error) {\n\n\tswitch {\n\tcase req.NamespaceId != nil:\n\t\t{\n\t\t\treturn db.Query.FindRatelimitNamespaceByID(ctx, svc.DB.RO(), *req.NamespaceId)\n\t\t}\n\tcase req.NamespaceName != nil:\n\t\t{\n\t\t\treturn db.Query.FindRatelimitNamespaceByName(ctx, svc.DB.RO(), db.FindRatelimitNamespaceByNameParams{\n\t\t\t\tWorkspaceID: workspaceID,\n\t\t\t\tName:        *req.NamespaceName,\n\t\t\t})\n\t\t}\n\t}\n\n\treturn db.RatelimitNamespace{}, fault.New(\"missing namespace id or name\",\n\t\tfault.WithTag(fault.BAD_REQUEST),\n\t\tfault.WithDesc(\"missing namespace id or name\", \"You must provide either a namespace ID or name.\"),\n\t)\n\n}\n\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"The handler is just a function that returns an error, making it easy to test and reason about. All the HTTP-specific logic (authentication, validation, error handling, response formatting) is handled by middleware or injected services.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"testing-made-easy\",children:\"Testing Made Easy\"}),`\n`,(0,n.jsx)(e.p,{children:\"Zen's simple design makes testing very easy, even our CEO loves it. Because routes are just functions that accept a context and session and return an error, they're easy to unit test:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-go\",children:`package handler_test\n\nimport (...)\n\nfunc TestRatelimitEndpoint(t *testing.T) {\n    h := testutil.NewHarness(t)\n\n    route := handler.New(handler.Services{\n        DB:          h.DB,\n        Keys:        h.Keys,\n        Logger:      h.Logger,\n        Permissions: h.Permissions,\n    })\n\n    h.Register(route)\n\n    rootKey := h.CreateRootKey(h.Resources.UserWorkspace.ID)\n\n    headers := http.Header{\n        \"Content-Type\":  {\"application/json\"},\n        \"Authorization\": {fmt.Sprintf(\"Bearer %s\", rootKey)},\n    }\n\n    req := handler.Request{\n        Namespace:  \"test_namespace\",\n        Identifier: \"user_123\",\n        Limit:      100,\n        Duration:   60000,\n    }\n\n    res := testutil.CallRoute[handler.Request, handler.Response](h, route, headers, req)\n    require.Equal(t, 200, res.Status)\n    require.NotNil(t, res.Body)\n    require.True(t, res.Body.Success)\n    require.Equal(t, int64(100), res.Body.Limit)\n    require.Equal(t, int64(99), res.Body.Remaining)\n}\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"We've built test utilities that make it easy to set up a test harness with database dependencies, register routes, and call them with typed requests and responses.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"zen-is-open-source\",children:\"Zen is Open Source\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Zen lives in our open source mono repo, so you can explore or even use it in your own projects. The full source code is available in our GitHub repository at \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/unkey/tree/main/go/pkg/zen\",children:\"github.com/unkeyed/unkey/tree/main/go/pkg/zen\"}),\".\"]}),`\n`,(0,n.jsx)(e.p,{children:\"While we built Zen specifically for our needs, we recognize that other teams might face similar challenges with Go HTTP frameworks. You're welcome to:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Read through the implementation to understand our approach\"}),`\n`,(0,n.jsx)(e.li,{children:\"Fork the code and adapt it to your own requirements\"}),`\n`,(0,n.jsx)(e.li,{children:\"Use it directly in your projects if it fits your needs\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsx)(e.p,{children:\"While the Go ecosystem offers many excellent HTTP frameworks, sometimes the best solution is a custom one tailored to your specific needs. A thin layer on top of Go's standard library can provide significant ergonomic benefits without sacrificing control or performance.\"}),`\n`,(0,n.jsx)(e.p,{children:\"As our API continues to grow, the simplicity and extensibility of Zen will allow us to add new features and functionality without compromising on performance or developer experience. The best abstractions are those that solve real problems without introducing new ones, and by starting with Go's solid foundation and carefully adding only what we needed, we've created a framework that enables our team to build with confidence.\"})]})}function h(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(c,{...t})}):c(t)}return b(T);})();\n;return Component;",
    "slug": "zen",
    "url": "/blog/zen",
    "tableOfContents": [
      {
        "level": 2,
        "text": "The Pain Points with Existing Frameworks",
        "slug": "the-pain-points-with-existing-frameworks"
      },
      {
        "level": 3,
        "text": "Complex Middleware Execution Order",
        "slug": "complex-middleware-execution-order"
      },
      {
        "level": 3,
        "text": "Poor OpenAPI Integration",
        "slug": "poor-openapi-integration"
      },
      {
        "level": 3,
        "text": "Dependency Bloat",
        "slug": "dependency-bloat"
      },
      {
        "level": 3,
        "text": "Inflexible Error Handling",
        "slug": "inflexible-error-handling"
      },
      {
        "level": 2,
        "text": "The Zen Philosophy",
        "slug": "the-zen-philosophy"
      },
      {
        "level": 2,
        "text": "The Core Components of Zen",
        "slug": "the-core-components-of-zen"
      },
      {
        "level": 3,
        "text": "Sessions",
        "slug": "sessions"
      },
      {
        "level": 3,
        "text": "Routes",
        "slug": "routes"
      },
      {
        "level": 3,
        "text": "Middleware",
        "slug": "middleware"
      },
      {
        "level": 3,
        "text": "Server",
        "slug": "server"
      },
      {
        "level": 2,
        "text": "OpenAPI Integration the Right Way",
        "slug": "openapi-integration-the-right-way"
      },
      {
        "level": 2,
        "text": "The Benefits of Building Zen",
        "slug": "the-benefits-of-building-zen"
      },
      {
        "level": 3,
        "text": "Complete Middleware Control",
        "slug": "complete-middleware-control"
      },
      {
        "level": 3,
        "text": "Schema-First API Design",
        "slug": "schema-first-api-design"
      },
      {
        "level": 3,
        "text": "Minimal Dependencies",
        "slug": "minimal-dependencies"
      },
      {
        "level": 3,
        "text": "Idiomatic Go",
        "slug": "idiomatic-go"
      },
      {
        "level": 3,
        "text": "Type Safety with Ergonomics",
        "slug": "type-safety-with-ergonomics"
      },
      {
        "level": 2,
        "text": "Real-World Example: Rate Limiting API",
        "slug": "real-world-example-rate-limiting-api"
      },
      {
        "level": 2,
        "text": "Testing Made Easy",
        "slug": "testing-made-easy"
      },
      {
        "level": 2,
        "text": "Zen is Open Source",
        "slug": "zen-is-open-source"
      },
      {
        "level": 2,
        "text": "Conclusion",
        "slug": "conclusion"
      }
    ]
  }
];