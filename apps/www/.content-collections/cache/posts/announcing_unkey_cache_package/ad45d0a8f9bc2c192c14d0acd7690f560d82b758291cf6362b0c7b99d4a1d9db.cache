"var Component=(()=>{var u=Object.create;var i=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var w=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),g=(t,e)=>{for(var a in e)i(t,a,{get:e[a],enumerable:!0})},s=(t,e,a,c)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of p(e))!y.call(t,r)&&r!==a&&i(t,r,{get:()=>e[r],enumerable:!(c=m(e,r))||c.enumerable});return t};var b=(t,e,a)=>(a=t!=null?u(w(t)):{},s(e||!t||!t.__esModule?i(a,\"default\",{value:t,enumerable:!0}):a,t)),k=t=>s(i({},\"__esModule\",{value:!0}),t);var l=f((M,o)=>{o.exports=_jsx_runtime});var C={};g(C,{default:()=>d});var n=b(l());function h(t){let e={a:\"a\",code:\"code\",em:\"em\",h2:\"h2\",h3:\"h3\",li:\"li\",p:\"p\",pre:\"pre\",strong:\"strong\",ul:\"ul\",...t.components},{Image:a}=e;return a||v(\"Image\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\"We are excited to introduce our latest library, \",(0,n.jsx)(e.code,{children:\"@unkey/cache\"}),\", designed to make caching in serverless applications easy and enjoyable.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"the-challenges-of-caching-in-cloudflare-workers\",children:\"The challenges of caching in Cloudflare Workers\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Our journey with caching on Cloudflare Workers highlighted several challenges. The most significant issue was the lack of persistent memory, which meant that each request could start with a cold cache. Additionally, Cloudflare KV, while nice to use, proved to be too slow for our needs: The p99 was 560ms (\",(0,n.jsx)(e.a,{href:\"https://upstash.com/blog/edgecaching-benchmark\",children:\"source\"}),\").\"]}),`\n`,(0,n.jsx)(e.p,{children:\"To mitigate these issues, we implemented a tiered caching strategy. By utilizing an in-memory store as the first tier and Cloudflare's CDN cache as the fallback, we achieved the best of both worlds, latency and decent hit rate.\"}),`\n`,(0,n.jsx)(a,{src:\"/images/blog-images/announcing-unkey-cache-package/cache-hits.png\",alt:\"Cache hit ratio\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"The ~27% memory hit rate might not be the most impressive, but it's free and does not add any latency. Unfortunately there's little we can do to increase it, as Cloudflare may evict a worker instance at any moment. However as traffic grows, the hit rate will increase too.\"}),`\n`,(0,n.jsx)(e.p,{children:\"If a memory cache miss occurs, the Cloudflare cache will be checked, which adds some latency but is still faster than any other alternative we found.\"}),`\n`,(0,n.jsx)(a,{src:\"/images/blog-images/announcing-unkey-cache-package/cache-latency.png\",alt:\"Cache latency\",width:\"1920\",height:\"1080\"}),`\n`,(0,n.jsx)(e.p,{children:\"This performed well, but the developer experience left something to be desired.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"the-problem-with-existing-solutions\",children:\"The problem with existing solutions\"}),`\n`,(0,n.jsx)(e.p,{children:\"Caching is a common requirement in many applications, but traditional approaches often fall short. Here's a typical example of what developers have to deal with:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-ts\",children:`const cache = new Some3rdPartyCache(...)\n\ntype User = { email: string };\n\nlet user = await cache.get(\"chronark\") as User | undefined | null;\nif (!user) {\n  user = await db.query.users.findFirst({\n    where: (table, { eq }) => eq(table.id, \"chronark\"),\n  });\n  await cache.set(\"chronark\", user, Date.now() + 60_000)\n}\n\n// use user\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\"@unkey/cache\"}),\" abstracts all the boilerplate away and gives you a clean API that is fully type-safe:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-ts\",children:`const user = await cache.user.swr(\"chronark\", async (id) => {\n  return await db.query.users.findFirst({\n    where: (table, { eq }) => eq(table.id, id),\n  });\n});\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"key-features\",children:\"Key features\"}),`\n`,(0,n.jsxs)(e.p,{children:['The \"u\" in \"unkey\" stands for \"batteries included\"! ',(0,n.jsx)(e.em,{children:\"(English may not be my first language)\"})]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"E2E Typesafe\"}),\": Fully type-safe, clean and intuitive API with intellisense autocomplete.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Tiered Cache\"}),\": Chain multiple caches together for fast and reliable caching.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Stale-While-Revalidate\"}),\": Most 3rd party caches support setting a time-to-live, but you needed to handle SWR yourself, until now. Just configure \",(0,n.jsx)(e.code,{children:\"fresh\"}),\" and \",(0,n.jsx)(e.code,{children:\"stale\"}),\" times and let the cache handle the rest.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Metrics Collection\"}),\": Middleware for gathering metrics to monitor and debug your cache usage.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Encryption\"}),\": Middleware for automatic encryption of cache values, protecting your data at rest.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Composable Design\"}),\": Mix and match \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/libraries/ts/cache/overview#primitives\",children:\"primitives\"}),\" to build exactly what you need.\"]}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"getting-started\",children:\"Getting Started\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Install \",(0,n.jsx)(e.code,{children:\"@unkey/cache\"}),\":\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`npm install @unkey/cache\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"basic-cache\",children:\"Basic cache\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-ts\",children:`import { createCache, DefaultStatefulContext, Namespace } from \"@unkey/cache\";\nimport { MemoryStore } from \"@unkey/cache/stores\";\n\n/**\n * Let's say we have two types, \\`User\\` and \\`Project\\`:\n */\ntype User = { id: string; email: string };\ntype Project = { name: string; description: string };\n\n/**\n * Next we'll be creating a store. A store is really just a small abstraction \n * over a key-value database.\n */\nconst memory = new MemoryStore({ persistentMap: new Map() });\n\n/**\n * We'll create a cache instance with our two types, \\`User\\` and \\`Project\\`, and\n * configure the cache to use the memory store. We'll also set the \\`fresh\\` and\n * \\`stale\\` times for each type.\n * The \\`ctx\\` object is provided in the request handler and allows us to do some\n * background work without blocking the request.\n */\nconst cache = createCache({ \n    user: new Namespace<User>(ctx, {\n      stores: [memory],\n      fresh: 60_000,\n      stale: 300_000,\n    }),\n    project: new Namespace<Project>(ctx, {\n      stores: [memory],\n      fresh: 300_000,\n      stale: 900_000,\n    })\n});\n\n/**\n * That's it! Now we can use the cache like this:\n */\nawait cache.user.set(\"userId\", { id: \"userId\", email: \"user@email.com\" });\nconst user = await cache.user.get(\"userId\");\nconsole.log(user);\n\n\n/**\n * To make full use of the SWR capabilities, we can use the \\`swr\\` method, which\n * will automatically handle the cache misses and cache updates for us.\n * This will check all stores for the value, and if it's not found, it will \n * call the provided function to get the value and cache it automatically.\n */\nconst user = await cache.user.swr(\"userId\", async () => {\n  return await database.get(...)\n});\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"tiered-caching\",children:\"Tiered caching\"}),`\n`,(0,n.jsx)(e.p,{children:\"Tiered caching is a powerful feature that allows you to chain multiple caches together. This is useful when you want to use a fast, in-memory cache as the first tier and a slower, more persistent cache as the second tier.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-ts\",children:`import { createCache, DefaultStatefulContext, Namespace } from \"@unkey/cache\";\nimport { CloudflareStore, MemoryStore } from \"@unkey/cache/stores\";\n\ntype User = { id: string; email: string };\n\nconst memory = new MemoryStore({ persistentMap: new Map() });\nconst cloudflare = new CloudflareStore({\n  domain: \"cache.unkey.dev\",\n  zoneId: process.env.CLOUDFLARE_ZONE_ID!,\n  cloudflareApiKey: process.env.CLOUDFLARE_API_KEY!,\n});\n\nconst cache = createCache({ \n  user: new Namespace<User>(ctx, {\n    // memory is checked first, then cloudflare if memory misses\n    stores: [memory, cloudflare],\n    fresh: 60_000,\n    stale: 300_000,\n  })\n});\n\nawait cache.user.set(\"userId\", { id: \"userId\", email: \"user@email.com\" });\nconst user = await cache.user.get(\"userId\");\nconsole.log(user);\n`})}),`\n`,(0,n.jsx)(e.h3,{id:\"middleware\",children:\"Middleware\"}),`\n`,(0,n.jsx)(e.p,{children:\"There are two middlewares available out of the box:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Metrics\"}),\": Collects and forwards metrics on cache hits, misses, latency and evictions.\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:'import { withMetrics } from \"@unkey/cache/middleware\";'})}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Encryption\"}),\": Automatically encrypts and decrypts cache values.\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:'import { withEncryption } from \"@unkey/cache/middleware\";'})}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Please refer to the \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/libraries/ts/cache/overview#middlewares\",children:\"documentation\"}),\" for more information on how to use middlewares.\"]}),`\n`,(0,n.jsx)(e.h2,{id:\"conclusion\",children:\"Conclusion\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"At launch we ship with a memory store and a Cloudflare store, but everything is built to be \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/libraries/ts/cache/interface/store\",children:\"easily extensible\"}),`. We can add more stores and middlewares as needed, let us know what you'd want to see!\nWhether you're dealing with the limitations of serverless functions or simply need a nice caching abstraction, `,(0,n.jsx)(e.code,{children:\"@unkey/cache\"}),\" has you covered.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"As usual, everything is open source, check out our \",(0,n.jsx)(e.a,{href:\"https://github.com/unkeyed/unkey/tree/main/packages/cache\",children:\"GitHub repository\"}),\" and our \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/docs/libraries/ts/cache/overview\",children:\"documentation\"}),\" for more information. We can't wait to see what you build with it!\"]})]})}function d(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(h,{...t})}):h(t)}function v(t,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return k(C);})();\n;return Component;"