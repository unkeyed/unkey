"var Component=(()=>{var u=Object.create;var r=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,w=Object.prototype.hasOwnProperty;var k=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),f=(t,e)=>{for(var a in e)r(t,a,{get:e[a],enumerable:!0})},i=(t,e,a,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let o of m(e))!w.call(t,o)&&o!==a&&r(t,o,{get:()=>e[o],enumerable:!(s=p(e,o))||s.enumerable});return t};var g=(t,e,a)=>(a=t!=null?u(y(t)):{},i(e||!t||!t.__esModule?r(a,\"default\",{value:t,enumerable:!0}):a,t)),L=t=>i(r({},\"__esModule\",{value:!0}),t);var d=k((N,c)=>{c.exports=_jsx_runtime});var A={};f(A,{default:()=>l});var n=g(d());function h(t){let e={a:\"a\",code:\"code\",h2:\"h2\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",...t.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"Unkey allows users to create an unlimited number of API keys for their applications. Counting these for our dashboard or API has become a growing issue for us.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Most APIs have fewer than a thousand keys, however some of our larger customers have hundreds of thousands. And those customers are also the ones hitting our API the most.\"}),`\n`,(0,n.jsx)(e.h2,{id:\"schema\",children:\"Schema\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sql\",children:\"\\nCREATE TABLE `key_space` (\\n\t`id` varchar(256) NOT NULL,\\n\t`workspace_id` varchar(256) NOT NULL,\\n\t# ... omitted\\n)\\n\\nCREATE TABLE `keys` (\\n\t`id` varchar(256) NOT NULL,\\n\t`hash` varchar(256) NOT NULL,\\n\t`workspace_id` varchar(256) NOT NULL,\\n\t`key_space_id` varchar(256) NOT NULL,\\n\t# ... omitted\\n)\\n\"})}),`\n`,(0,n.jsxs)(e.p,{children:[\"As you can see, many \",(0,n.jsx)(e.code,{children:\"keys\"}),\" belong to a single \",(0,n.jsx)(e.code,{children:\"key_space\"}),\" and out query in question is:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sql\",children:`SELECT count(*) FROM keys WHERE key_space_id = ?\n`})}),`\n`,(0,n.jsx)(e.h2,{id:\"options\",children:\"Options\"}),`\n`,(0,n.jsx)(e.p,{children:\"We were looking at a few options how to fix this:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Caching the count as part of a larger query\"}),`\n`,(0,n.jsxs)(e.li,{children:[\"Caching the \",(0,n.jsx)(e.code,{children:\"count(*)\"}),\" query separately in our \",(0,n.jsx)(e.a,{href:\"https://www.unkey.com/blog/announcing-unkey-cache-package\",children:\"tiered cache\"}),\" using SWR semantics.\"]}),`\n`,(0,n.jsx)(e.li,{children:\"Adding two new columns for storing approximated counts.\"}),`\n`]}),`\n`,(0,n.jsx)(e.h2,{id:\"solution\",children:\"Solution\"}),`\n`,(0,n.jsx)(e.p,{children:\"We went with the 3rd option, mainly because we would never run into a cold cache, where we don't have a value at all, nor does it depend on another component. We can use this in our dashboard just as easily as in our API and it behaves the same.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Adding these two columns, one for storing the approximated count and one for storing a timestamp of when we last updated the count.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-sql\",children:\"ALTER TABLE `key_space`\\n  ADD COLUMN `size_approx` int NOT NULL DEFAULT '0',\\n  ADD COLUMN `size_last_updated_at` bigint NOT NULL DEFAULT '0'\\n\"})}),`\n`,(0,n.jsxs)(e.p,{children:[\"By storing the count on the \",(0,n.jsx)(e.code,{children:\"key_space\"}),` table, we get the count for free cause we're not doing an extra query.\nTo keep it up to date, we check the `,(0,n.jsx)(e.code,{children:\"size_last_updated_at\"}),\" timestamp after every read and if it's too old (60s in our case), we refresh it asynchronously.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Here's how we do it in drizzle:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-ts\",children:`\n\nconst keySpace = await db.query.keySpace.findFirst({where: ...})\nif (keySpace.sizeLastUpdatedAt < Date.now() - 60_000) {\n  const count = await db\n    .select({ count: sql<string>\\`count(*)\\` })\n    .from(schema.keys)\n    .where(and(eq(schema.keys.keySpaceId, keySpace.id), isNull(schema.keys.deletedAtM)));\n\n  keySpace.sizeApprox = Number.parseInt(count?.at(0)?.count ?? \"0\");\n  keySpace.sizeLastUpdatedAt = Date.now();\n\n  c.executionCtx.waitUntil(\n    db.primary\n      .update(schema.keySpace)\n      .set({\n        sizeApprox: keySpace.sizeApprox,\n        sizeLastUpdatedAt: keySpace.sizeLastUpdatedAt,\n      })\n      .where(eq(schema.keySpace.id, keySpace.id)),\n  );\n}\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"We first load the \",(0,n.jsx)(e.code,{children:\"keySpace\"}),` and if the data is too old, we kick off a second query to count all keys.\nPotentially this might kick off many queries to refresh if a lot of requests come in at the same time, but that's also the case for our current system, where we always count all rows.`]}),`\n`,(0,n.jsx)(e.p,{children:\"In the future we might want to run a cron job to refresh counts in the background and remove the manual refresh, but we haven't needed that yet.\"})]})}function l(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,{...t,children:(0,n.jsx)(h,{...t})}):h(t)}return L(A);})();\n;return Component;"