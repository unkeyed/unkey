---
title: Pull-Based Provisioning
description: Sequence-based infrastructure synchronization with autonomous agents, polling-based updates, and eventual consistency
---

import { Mermaid } from "@/app/components/mermaid";

Unkey's infrastructure orchestration implements a pull-based model where autonomous Krane instances poll the control plane for state changes and continuously reconcile desired state with actual state. This architecture follows the Kubernetes List+Watch pattern, using a monotonically increasing sequence number to track changes and enable efficient incremental synchronization.

The architecture's core principle is to enable autonomous reconciliation and self-healing without requiring the control plane to track connected clients or push events.

## Architecture

<Mermaid
  chart="
sequenceDiagram
    autonumber
    participant U as User
    participant DB as Database
    participant CP as Control Plane (Ctrl)
    participant K1 as Krane Agent (Region A)
    participant K8s as Kubernetes API
    
    K1->>CP: Sync(region=a, sequence=0)
    Note over K1,CP: Bootstrap: stream full state
    CP->>K1: Stream all deployments/sentinels
    Note over K1: Stream closes, last seq=42
    
    U->>CP: Create deployment
    CP->>DB: Store deployment topology
    CP->>DB: Insert state_change(seq=43)
    
    Note over K1: Polling every 1-5s
    K1->>CP: (stream polls for changes)
    CP->>K1: Stream State(seq=43, deploy)
    
    K1->>K8s: Apply deployment
    K8s-->>K1: Pod status change
    K1->>CP: UpdateInstance(status=running)
    CP->>DB: Upsert Instance table"
/>

## Sync Protocol

The synchronization protocol uses a single `Sync` RPC that handles both initial bootstrap and incremental updates. This design eliminates the complexity of managing separate "synthetic" and "live" modes, and removes the need for the control plane to track connected clients in memory.

### Sequence Numbers

Every state change (deployment created, sentinel updated, resource deleted) is recorded in the `state_changes` table with a monotonically increasing sequence number per region. Krane tracks its last-seen sequence and resumes from that point on reconnect, enabling efficient incremental sync without missing events.

### Bootstrap Phase

When Krane connects with `sequence=0` (fresh start or after data loss), the control plane streams the complete desired state for the region. Each message contains a sequence number. Krane tracks the highest sequence seen and uses it for subsequent polls. Stream close signals bootstrap completion.

### Watch Phase

After bootstrap, the stream enters watch mode. The control plane polls the `state_changes` table every 250ms for new entries after Krane's last-seen sequence. When changes are found, they're streamed to Krane with their sequence numbers. Krane processes each change and updates its sequence watermark.

### Reconnection

If the connection drops, Krane reconnects with its last-seen sequence. If this sequence is still within the retention window (changes are kept for 7 days), sync resumes incrementally. If the sequence is too old, the control plane returns `FailedPrecondition` and Krane must perform a full bootstrap by reconnecting with `sequence=0`.

## Krane Agent

Krane agents act as autonomous controllers that reconcile desired state with actual Kubernetes resources in their respective regions. Each Kubernetes cluster runs a single Krane agent.

<Mermaid
  chart="
graph TB
    subgraph 'Control Plane'
        CP[ClusterService]
        SC[(state_changes)]
    end
    subgraph 'Krane Agent'
        W[Watcher]
        R[Reconciler]
        DC[Deployment Controller]
        GC[Sentinel Controller]
        
        W -->|HandleState| R
        R --> DC
        R --> GC
    end
    
    subgraph Kubernetes
        K8s[K8s API Server]
    end
    
    W -.->|Sync stream| CP
    CP -.->|poll| SC
    DC -->|Apply/Delete| K8s
    GC -->|Apply/Delete| K8s
    K8s -->|Watch Events| DC
    DC -->|UpdateInstance| CP
    GC -->|UpdateSentinel| CP"
/>

The Watcher maintains the Sync stream, reconnecting with jittered backoff (1-5 seconds) on failure. It passes received `State` messages to the Reconciler, which dispatches to the appropriate controller based on resource type. The Reconciler tracks `sequenceLastSeen` and updates it after successfully processing each state change.

Status updates flow back to the control plane through unary RPCs (`UpdateDeploymentState`, `UpdateSentinelState`) with buffering, retries, and circuit breakers for reliability.

## Deployment Workflow

<Mermaid
  chart="
sequenceDiagram
    participant User
    participant API
    participant Workflow as Deploy Workflow
    participant DB
    participant Krane
    participant K8s as Kubernetes
    
    User->>API: Deploy request
    API->>Workflow: Start deployment
    
    Workflow->>DB: Create deployment
    Workflow->>DB: Create topology entries
    Workflow->>DB: Insert state_changes
    
    Note over Krane: Polls state_changes via Sync
    Krane->>Krane: Receive State(Apply)
    
    Krane->>K8s: Apply deployment
    K8s-->>Krane: Pod created
    
    Krane->>DB: UpdateInstance(pending)
    
    loop Poll for completion
        Workflow->>DB: Check instance status
        alt All instances running
            Workflow->>DB: Update deployment status=ready
            Workflow-->>API: Success
        else Timeout or failed
            Workflow->>DB: Update deployment status=failed
            Workflow-->>API: Failure
        end
    end
    
    K8s-->>Krane: Pod running
    Krane->>DB: UpdateInstance(running)"
/>

The deploy workflow writes desired state to the database and inserts corresponding `state_change` records. It does not push events directly to Krane. The workflow then polls the `instances` table waiting for Krane to report that pods are running, with a timeout for failure handling.

## Why Polling Over Push

We chose polling-based synchronization over push-based event streaming for several reasons.

The control plane becomes stateless with respect to connected clients. It doesn't need to track which Krane instances are connected, buffer events during disconnections, or handle the complexity of fan-out to multiple subscribers. This simplifies horizontal scaling and eliminates a class of bugs around connection state management.

Polling naturally handles backpressure. If Krane falls behind processing, it simply polls less frequently. With push-based streaming, the control plane would need to implement flow control or risk overwhelming slow clients.

The sequence-based approach provides exactly-once delivery semantics. Each change has a unique sequence number, and Krane's watermark ensures no changes are missed or processed twice, even across restarts.

The tradeoff is latency. With 1-5 second polling intervals, there's a delay between a state change and Krane receiving it. For our use case (infrastructure provisioning measured in seconds to minutes), this latency is acceptable.

## Database Schema

The `state_changes` table is the changelog that drives synchronization. Each row represents a create, update, or delete operation on a deployment or sentinel. The `sequence` column is an auto-incrementing primary key that provides ordering. Rows are indexed by `(region, sequence)` for efficient polling and retained for 7 days before cleanup.

The `deployment_topology` table defines desired state for multi-region deployments. Each row specifies the desired replica count for a deployment in a specific region. When this table is modified, a corresponding `state_change` row is inserted.

The `instances` table tracks actual state reported by Krane. We only write to it in response to Kubernetes events. The workflow polls this table to determine when deployments are ready.

The `sentinels` table combines desired and actual state. Desired fields (cpu, memory, replicas) are set by the control plane; actual fields (available_replicas, health) are updated by Krane.
