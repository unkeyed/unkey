name: Bazel
on:
  workflow_call:
permissions:
  contents: read
jobs:
  build:
    name: Build and Test
    runs-on: depot-ubuntu-24.04-8
    steps:
      - uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4
      - uses: bazel-contrib/setup-bazel@083175551ceeceebc757ebee2127fde78840ca77 # 0.18.0
        with:
          # Avoid downloading Bazel every time.
          bazelisk-cache: true
          # Store build cache per workflow.
          disk-cache: false # we're already using depots remote cache
          # Share repository cache between workflows.
          repository-cache: true
          bazelrc: |
            common --remote_cache=https://cache.depot.dev
            common --remote_header=authorization=${{ secrets.DEPOT_BAZEL_CACHE_AUTHORIZATION }}
            common --remote_local_fallback

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 # v3.11.1
        with:
          install: true

      - name: Build
        run: bazel build //...

      # Running containers is temporary until we moved them inside of bazel,
      # at that point they are only created if they are actually needed
      - name: Start containers
        run: |
          echo "UNKEY_DEPOT_TOKEN=fake" >> ./dev/.env.depot
          echo "UNKEY_BUILD_S3_URL=fake" >> ./dev/.env.depot
          echo "UNKEY_BUILD_S3_ACCESS_KEY_ID=fake" >> ./dev/.env.depot
          echo "UNKEY_BUILD_S3_ACCESS_KEY_SECRET=fake" >> ./dev/.env.depot
          echo "UNKEY_REGISTRY_PASSWORD=fake" >> ./dev/.env.depot

          docker compose -f ./dev/docker-compose.yaml up s3 clickhouse kafka mysql ctrl-api ctrl-worker restate -d --wait
      - name: Run tests
        run: bazel test //... --test_output=errors
